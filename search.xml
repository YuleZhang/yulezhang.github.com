<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>刻意练习读书笔记（更新中）</title>
    <url>/2020/09/30/39DelibratePractice/</url>
    <content><![CDATA[<p>训练时长和训练方法</p>
<p>训练方法可能是间断性调整的（往往在当前方法遇到瓶颈，无法提高时）</p>
<p><strong>在任何行业或者领域中，最有效和最强大的那类联系，都通过充分利用人类的身体与大脑的适应能力，来逐步的塑造和提升他们的技能，以做到一些过去不可能的事情。</strong></p>
<a id="more"></a>
<p>我们在学习任何一项技能时，从烘焙饼干到写一段说明文，我们全都遵循相同的模式。首先，一般性的了解我们想做些什么，从导师、教练、书籍或网站上获得一些指导，然后一直练习，直到达到我们可以接受的水平，接下来让这种技能变成自动的、自然而然的。<strong>当我们的水平达到这个地步，我们就遇到了我们第一个瓶颈</strong>，那就是无论我们重复多少次，我们都很难再有大的提升。</p>
<p>但是人们经常错误的理解这种现象，认为开了20多年的司机一定比开了5年的司机更擅长开车；行医二十年的医生，一定会纸币行医5年的医生更加优秀；教了20年书的老师，一定会比只教了5年书的老师能力更强。</p>
<p>但是现实并不是这样。研究表明，一旦某个人的表现达到了“可接受”的水平，那么再多练习几年，也不会再有什么进步。原因在于，<strong>如果没有刻意的去思考如何提高，这些自动化的能力会缓缓退化</strong>。</p>
<h2 id="9月23日-更新-第二章：大脑的适应能力"><a href="#9月23日-更新-第二章：大脑的适应能力" class="headerlink" title="9月23日 更新 第二章：大脑的适应能力"></a>9月23日 更新 第二章：大脑的适应能力</h2><p>这一章主要是分析了刻意练习产生效果的内在科学依据。我们在运动或者健身时，通过一次次的练习，能够明显的看到或感受到肱二头肌、肱三头肌这些肌肉的变化。然而在进行一些复杂的脑力活动或者训练时，我们很难直观的看到自身的变化，我们的脑袋不会变大、变硬，也不会长出犄角。但这不意味着它是一成不变的，当我们进行<strong>记忆数字、数算等复杂脑力活动</strong>时，神经元及组织之间的链接是会发生<strong>强弱变化</strong>的。</p>
<p>研究表明，伦敦司机大脑的<strong>海马体</strong>要比普通人大一些，当然这并不意味着这是<strong>幸存者偏差</strong>导致的，一组关于伦敦司机培训前后海马体的比较能够说明这一点。这一点与发过生物学家“拉马克”的“<strong>用进废退</strong>”思路比较一致，通过不断地走出舒适区，我们大脑能够逐渐<strong>适应新的、更加复杂的神经元回路</strong>，就能实现逐步提高的结果。</p>
<p>刻意练习与传统的练习方式不同之处在于，传统练习刚刚离开舒适区，更多的倾向于找到我们身体的潜能。而刻意练习的思路意味着，我们通过训练可以做到任何其他人可以完成的事情（例如长跑、俯卧撑、记忆数字等等）。</p>
<p>当然我们总是希望我们热爱或者从事的任何一件事情都能通过<strong>刻意练习</strong>来提高，但是有两点情况你需要知道</p>
<ol>
<li>通过刻意练习强化某一部分神经元的同时，相同区域的负责其他功能的神经元可能退化（当然这一点是正常的， 任何不重复、不提高的区域都会逐渐退化）。</li>
<li>每一次的刻意训练都需要全身贯注，经常性的反思（但我们的注意力是有限的）</li>
</ol>
<p>因此，想真正的将其应用于生活，或许应该首先关注<strong>我们每天都要做的、非常重要</strong>的事情，不断地走出舒适区，不断地挑战自我，直到这方面技能达到一个<strong>令你满意</strong>、且<strong>适应而不费力</strong>的地步。</p>
<h2 id="9月24日更新-第三章：心理表征"><a href="#9月24日更新-第三章：心理表征" class="headerlink" title="9月24日更新 第三章：心理表征"></a>9月24日更新 第三章：心理表征</h2><p>在这一章作者列举了大量的例子来帮助我们去理解<strong>心理表征</strong>的<strong>定义、作用、训练方式</strong>等等。用我自己的话而言，心理表征就是一个人在某个领域的<strong>知识</strong>、<strong>技能</strong>、<strong>经验</strong>、<strong>直觉</strong>、<strong>判断</strong>等一系列内容的整合。</p>
<p>就像<strong>国际象棋</strong>的棋手阿廖欣的故事一样，他能够同时下25局盲棋，并且获得惊人的战绩，同时他也是多届国际象棋的冠军。对于一盘正在下的象棋，象棋大师能够在短短的几步之内迅速记住<strong>整个棋局的布局和关键棋子</strong>，而新手只能记住很少一部分。这难道是因为象棋大师有超高的记忆力么？哈哈，显然不是，当他们和普通选手同时记忆一堆杂乱无序的棋子时，他们的表现并没有比正常人强多少。这说明问题的关键不在于记忆力，而在于象棋大师具有复杂、精细的<strong>心理表征</strong>，大师对象棋的心理表征基于<strong>规则、局势、关键路数</strong>等，他们能将这些信息整合到一起，从而能够快速的记忆和回忆棋局。</p>
<p>再举一个例子，足球运动员，在我们观众看来，那么大的足球场，足球员的跑步的方向、步伐杂乱无章，球场一片混乱。可在足球高手看来，每个人都有自己的位置和负责的区域，并且他们的运动都是以球为中心。并且每个球员的传球方式、动作等在足球高手眼里都是非常有用的信息，他们能够知道谁在帮他们拦截、他们的<strong>最佳射球点位置、传球方式、几种进球方案</strong>等等，越熟练的高手越能在极短的时间做出判断，并采取行动。这在比赛中，能赢得更多的时间，也能提高射球准确率。上述的这些反应、预判、思考都是足球高手进行长期的训练和有监督的指导所形成的<strong>心里表征</strong>。</p>
<p>当然书中还列举了医生、体操运动员等不同领域的专业人士的心里表征的具体体现，心里表征能够帮助我们<strong>预判未来</strong>、<strong>制定计划</strong>、<strong>找出规律</strong>、<strong>高效学习</strong>。就像做数学题，高手怎么做呢，根据题目的条件迅速列举可实施的几种方法，根据时间、答题情况等综合考虑选择的方法是<strong>快速求解</strong>、还是<strong>稳健易算</strong>等，这都是在平时多次总结、积累、训练得到的。心理表征随着我们能力的提高会进一步发挥作用。</p>
<h2 id="9月28日更新-第四章-黄金标准"><a href="#9月28日更新-第四章-黄金标准" class="headerlink" title="9月28日更新 第四章 黄金标准"></a>9月28日更新 第四章 黄金标准</h2><p>刻意练习的定义非常严格，你需要一位导师或者教练来教你练习的方法，来帮助你提高特定的技能。这个行业或者领域本身必须拥有一套高度发达的技能，可以用来教给业内人士。符合这些所有条件的领域很少，仅包括音乐表演、国际象棋、芭蕾、体操以及一些行业或领域。</p>
<p>但是就像史蒂夫记忆数字一样，他一样没有人指导，他的提高是通过反复实验来想办法提高的。当参赛者找不到导师来帮助设计训练课程时，他们能从以前的专家那里获取建议、那些专家的事迹，<font color='red'><strong>要么可从书上找到，要么可以从媒体的采访中获得</strong></font>，如果在你所处的领域中<strong>刻意练习</strong>原则可以实行，那么采用它进行训练；如果不是，就要尽量采用刻意练习的原则，实践中分为以下几个步骤：</p>
<ol>
<li>辨别杰出人物：要有不含偏见的客观、不要比时间长、可以请教身边给专业人士提供帮助的人（不禁要问谁厉害，还要问他们是如何判断的）。关键是<strong>客观的、可复制</strong>的指标</li>
<li>找杰出人物和其他人的差别：思考他们做了什么、有什么练习方法，自己要不断调整。同时找到优秀的导师，最重要的是从他那里得到反馈。</li>
<li>训练方法</li>
<li>坚持练习</li>
</ol>
<h2 id="9月30日更新-第五章-在工作中运用刻意练习的原则"><a href="#9月30日更新-第五章-在工作中运用刻意练习的原则" class="headerlink" title="9月30日更新 第五章 在工作中运用刻意练习的原则"></a>9月30日更新 第五章 在工作中运用刻意练习的原则</h2><p>医生和护士的讲座或者研讨会没有反馈，没有复杂的现实环境。</p>
<p>专业学院着重于知识，而不是技能。人们一般认为有了知识，就能掌握技能。但是很多领域例如医学并没有这样的套件</p>
<p>所以有效的方法是<strong>制定改进技能的培训方法</strong>，强调实干，而不是知晓</p>
<p>外科与其他专科的不同，例如血管破裂组织损伤，能够立马暴露出来，即使反馈，知道哪错了。</p>
<p>杰出医生做好计划、监控手术、准备临场应变。有有效的心理表征</p>
<h2 id="10月2日更新-第六章-在生活中运用刻意练习原则"><a href="#10月2日更新-第六章-在生活中运用刻意练习原则" class="headerlink" title="10月2日更新  第六章 在生活中运用刻意练习原则"></a>10月2日更新  第六章 在生活中运用刻意练习原则</h2><p><strong>刻意练习针对每一个有梦想的人</strong></p>
<p>首先，找一位好导师，你可以看视频、参加团体课，但无论看多少遍示范，但你依然会注意不到或者理解错某些细节，有时甚至还忽略了并不细微的事情。而且即使你发现自己的缺陷，也无法想出最好的方法来弥补。尤其是，你的心理表征将存在问题。</p>
<p>导师的选择也有一定的要求，不是越优秀、杰出的导师越好，要看其他人对老师的评价、老师的熟练度和经验。导师最重要的事情是帮助你建立<strong>心理表征</strong>，以便能够检测和纠正自己的表现。<strong>当自己改变了时，可能需要更换导师。</strong></p>
<p>要记住：如果你在走神，或者你很放松，并且只为了好玩，你可能不会进步。</p>
<p>没有导师怎么办、富兰克林的例子、要自己设计练习方法。。为了提高，我们必须自己创造机会</p>
<p><strong>遇到瓶颈怎么处理？</strong></p>
<p>尝试做不同的事情，而非更难的事情.</p>
<p>有目的练习的特点</p>
<ol>
<li>有定义明确的特定目标</li>
<li>专注于任务</li>
<li>包含反馈</li>
<li>走出舒适区</li>
</ol>
<p>相关链接</p>
<p><a href="https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9880086237340105012%22%7D&amp;n_type=0&amp;p_from=1"><em>孙光宇—应届硕士被建议破格授予博士学位</em></a></p>
<p><a href="https://baike.baidu.com/item/%E9%87%91%E8%B4%A4%E6%95%8F"><em>金贤敏</em></a></p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>刻意练习</tag>
      </tags>
  </entry>
  <entry>
    <title>HTN-Experiment</title>
    <url>/2020/09/30/38Study-Report(0928-1004)/</url>
    <content><![CDATA[<p>本周主要工作是尝试不同的数据集、不同的方案、对比分析不同的效果及产生的原因</p>
<a id="more"></a>
<h2 id="HTN-Experiment"><a href="#HTN-Experiment" class="headerlink" title="HTN-Experiment"></a>HTN-Experiment</h2><p>Github项目地址：<a href="https://github.com/YuleZhang/Hybrid-Tensor-Network">这里</a>，欢迎大家多多关注！</p>
<h3 id="On-MNIST-amp-fashion-MNIST"><a href="#On-MNIST-amp-fashion-MNIST" class="headerlink" title="On MNIST&amp;fashion-MNIST"></a>On MNIST&amp;fashion-MNIST</h3><p>上周设计好HTN网络之后，就想跑一跑看看效果，谁知道在多个机子上均出现了<strong>内存溢出</strong></font>的问题。起初我以为是电脑不行，换了一圈，甚至都找到了Google的计算平台<strong>Colab</strong>（一个免费的在线GPU算力平台，TeslaP4），内存还是溢出了。</p>
<p>观察代码的执行情况，我发现程序在运行过程中，内存占比持续增高，最终填满内存，然后崩溃，这说明程序有些中间执行过程资源没有释放。经过查阅资料（Releated Links3），发现<strong>loss里的tensor不断地放进内存，最终导致溢出</strong>。获取损失函数的计算结果用<code>loss.item()</code>而尽量避免直接用loss，其他内存优化的知识见<u>链接内容4</u>。</p>
<p>下图是验证论文HTN在MNIST数据集上的效果，计算经过41个epochs（耗时19小时34分）的完整过程，并用<a href="https://w1ww.tensorflow.org/tensorboard">Tensorboard</a>详细的记录训练过程如下图所示。</p>
<p><img src="/assets/160138.png" alt="img"></p>
<p>从图中可以看出，Accuracy最高到达99.2%，之后没有很大涨幅，基本已经收敛。loss也在不断地降低最后收敛于0.04这样一个值，已经非常小了。至此，HTN论文在MNIST和fashion-MNIST上已经得到验证。</p>
<p>相比之下，设计含卷积层的网络已经迭代到epoch 77，仅用了不到10个小时，可见GPU加速的效果。相比于原先的两个线性层，CNN的引入并没有很大幅度的提升准确率，收敛结果在92%左右徘徊，只能说比线性层的90%好了一点点。</p>
<p>对于上述实验，数据集采用的是MNIST的60000张图片，只能从<strong>数据预处理</strong>、<strong>算法模型调优</strong>、<strong>算法参数调优</strong>几个角度来尝试提高准确率，因此在新的算法模型<a href="https://github.com/YuleZhang/Hybrid-Tensor-Network/blob/master/HTN_MNIST_CNN_V4.py">HTN_MNIST_CNN_V4.py</a>中引入了Dropout、Leakly relu进行优化，如果效果不佳，下一步将尝试NASnet、AlexNet等其他神经网络。</p>
<h3 id="On-COVID-19-Datasets"><a href="#On-COVID-19-Datasets" class="headerlink" title="On COVID-19 Datasets"></a>On COVID-19 Datasets</h3><p>另一方面，同时为了将模型和这次疫情相结合，找到了这篇文章<a href="https://www.sciencedirect.com/science/article/pii/S0010482520301621?via%3Dihub"><strong>Automated detection of COVID-19 cases using deep neural networks with X-ray images</strong></a>，包含了数据集以及卷积CNN训练的例子，我尝试将它改造成我们上面提到的HTN网络进行训练，以期望能够出现更好的效果。这篇文章的数据源是一些感冒或者发烧患者的<strong>胸部X射线照片</strong>图片（如下图），它们共分为三类，即<strong>肺炎</strong>、<strong>正常</strong>、<strong>COVID-19</strong>。</p>
<p><img src="/assets/1601799444853.png" width="80%"></p>
<p>并且<a href="https://github.com/muhammedtalo/COVID-19">COVID-19项目中</a>给出了一些已经经过诊断的分好类的图片，用这些图片来训练我们构造的神经网络模型参数，最终就能构建对未知图片的预测能力。当然该项目代码中也缺少一部分数据读取处理的过程，经过不断地查询和调试，最终可以通过以下代码补全</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line">kf = KFold(n_splits=<span class="number">5</span>)</span><br><span class="line">skf=StratifiedKFold(n_splits=<span class="number">5</span>)</span><br><span class="line">path = <span class="string">&quot;COVID-19/X-Ray Image DataSet&quot;</span></span><br><span class="line">data= (ImageList.from_folder(path)</span><br><span class="line">.split_none()</span><br><span class="line">.label_from_folder()</span><br><span class="line">.transform(size=(<span class="number">256</span>,<span class="number">256</span>))</span><br><span class="line">.databunch()).normalize(imagenet_stats)</span><br><span class="line"></span><br><span class="line">df=data.to_df()</span><br><span class="line">split_data = <span class="literal">None</span></span><br><span class="line"><span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> skf.split(df.index, df[<span class="string">&#x27;y&#x27;</span>]): <span class="comment"># 划分数据集</span></span><br><span class="line">  print(len(train_index), len(test_index))</span><br><span class="line">  print((train_index), (test_index))</span><br><span class="line">  d = (ImageList.from_folder(path)</span><br><span class="line">          .split_by_idxs(train_index, test_index)</span><br><span class="line">          .label_from_folder()</span><br><span class="line">          .transform(size = (<span class="number">256</span>,<span class="number">256</span>))</span><br><span class="line">          .databunch(num_workers =<span class="number">0</span>)).normalize(imagenet_stats)</span><br><span class="line">  split_data = d</span><br><span class="line">  <span class="keyword">break</span></span><br><span class="line">data = split_data</span><br></pre></td></tr></table></figure>
<p>传统的train-test分割方式容易浪费数据，并且容易过拟合。因此这里采用了<strong>交叉验证</strong>的分割方式，一般应用于样本数量不足的情况。它的原理是<strong>将数据集A随机分为k个包，每次将其中一个包作为测试集，剩下k-1个包作为训练集进行训练</strong>。部分训练过程如下图所示<img src="/assets/1601802574535.png" alt="1601802574535"></p>
<p>这个神经网络结构相当复杂，大概有50多层，而且图片的尺寸比较特殊，基于HTN的网络还在设计中，计划先把原论文中的结果验证之后，再跑修改后的HTN网络。</p>
<h2 id="Knowledges-in-Neural-Network"><a href="#Knowledges-in-Neural-Network" class="headerlink" title="Knowledges in Neural Network"></a>Knowledges in Neural Network</h2><h3 id="How-to-improve-our-accuracy"><a href="#How-to-improve-our-accuracy" class="headerlink" title="How to improve our accuracy"></a>How to improve our accuracy</h3><p>四个角度去提高模型的准确率，详细见<u>相关链接5</u></p>
<ol>
<li>从数据上提升性能：<strong>数据预处理、特征提取、特征选择</strong>等</li>
<li>从算法上提升性能：<strong>算法框架</strong>CNN、RNN、GAN？要考虑算法的结构和特点</li>
<li>从算法调优上提升性能：参数是否合理？Grid Searching？Batch Learning？</li>
<li>从模型融合上提升性能：集成方式<strong>Voting</strong>？<strong>Bagging</strong>？<strong>Boosting</strong>？</li>
</ol>
<h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h3><blockquote>
<p>According to <a href="https://en.wikipedia.org/wiki/Dropout_(neural_networks">Wikipedia</a>) —</p>
<p>The term “dropout” refers to dropping out units (both hidden and visible) in a neural network.</p>
</blockquote>
<p>总的来说，dropout就是在随机选择神经元的训练阶段忽略某些单元，同时也意味着在<strong>向前或者向后</strong>传播过程中不考虑这些单位。从神经网络的细节上来看，在每个训练阶段，单个节点要么以$1-p$的概率从网络中退出，要么以概率$p$的形式被保留，从而留下一个简化的网络（节点的输入和输出边也将被删除）。</p>
<p><strong>So what’s the reason why we need dropout?</strong></p>
<p><strong>The answer to these questions is “to prevent over-fitting”.</strong></p>
<p>全连接层占据了大部分的参数，因此神经元在训练过程中彼此之间发展了相互依赖性，这抑制了每个神经元的个体力量，导致训练数据过拟合，当然增大数据量也是一个不错的方法。</p>
<h3 id="ReLU-in-CNN"><a href="#ReLU-in-CNN" class="headerlink" title="ReLU in CNN"></a>ReLU in CNN</h3><blockquote>
<p>According to <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks">Wikipedia</a>&gt;) —</p>
<p>The  ReLU is an <a href="https://en.wikipedia.org/wiki/Activation_function">activation function</a> defined as the positive part of its argument:</p>
<p>$f(x) = max(0,x)$</p>
<p>where <em>x</em> is the input to a neuron.</p>
</blockquote>
<p><strong>ReLU是目前世界上使用最广的激活函数，除此之外，常见的激活函数还有Softmax、tanh、Sigmoid等等。</strong>激活函数是<strong>神经网络或深度学习</strong>中一个非常重要的模块，它一般用来对layer的output进行激活（例如放缩到0-1之间，分成两类等等），经过不同函数的激活，连续的数据可以变为离散的数据，数据的分布也会发生变化。</p>
<p><img src='/assets/1601783272663.png' width="70%"></p>
<p>ReLU和sigmoid的图像如上图所示，可以看出它的取值范围是0到无穷，且处处可导（梯度传播会用到）。此外，为了处理不同场景的数据，ReLU函数还有很多的变体，例如Leaky ReLU、ELU、PReLU等等</p>
<p>在CNN中，ReLU的使用有助于<strong>防止操作神经网络所需的计算量呈指数增长</strong>。如果CNN缩放，添加额外ReLU的计算成本将线性增加。ReLU还可以防止出现所谓的“<strong>消失梯度</strong>”问题，这在使用S型函数时很常见。这个问题指的是对于Higher Input，神经元的梯度趋于接近零的趋势。</p>
<h2 id="华为2020开发者大会和量子计算软件创新大赛"><a href="#华为2020开发者大会和量子计算软件创新大赛" class="headerlink" title="华为2020开发者大会和量子计算软件创新大赛"></a><a href="https://m.koushare.com/lives/room/621135">华为2020开发者大会</a>和<a href="https://zhibo.sina.com.cn/news/ty40018557">量子计算软件创新大赛</a></h2><h3 id="华为2020开发者大会"><a href="#华为2020开发者大会" class="headerlink" title="华为2020开发者大会"></a>华为2020开发者大会</h3><p>听完报告收获还是蛮大的，尤其是中科院计算所孙晓明对量子计算梳理，让我思路清晰了很多。</p>
<ul>
<li>首先就是量子计算时借助<strong>量子力学特性（纠缠、叠加）</strong>来获得加速。</li>
<li>量子算法：在<strong>量子图灵机</strong>上运行<strong>量子算法</strong></li>
<li>从可计算性的角度上：量子图灵机=经典图灵机</li>
<li>当然量子计算机也不是万能的，有一些经典计算机无法解决的问题（如<strong>停机问题</strong>），量子计算机也无法解决，量子计算机只是在<strong>一些问题</strong>上比经典算法有<font color='red'>效率提升</font>。</li>
<li>那么关键就在于找到可以优化可以加速的哪些问题，逐渐找到边界</li>
<li>傅里叶算法相当于找到了周期（量子态可以同时表示一个周期的各个值）</li>
</ul>
<p><strong>量子查询模型</strong></p>
<p>量子计算只能进行<strong>酉操作（可逆变换）</strong>，Toffoli门可以实现任何可逆布尔函数（通用门），这就意味着凡是能用经典计算机解决的问题，量子计算机也能解决，并且在某些方面能够加速。</p>
<p><strong>常见算法</strong></p>
<p>Deutsch-Jozsa算法(傅里叶变换)、Shor算法大整数分解（指数加速）、Grover算法（开平方加速、应用更广）、振幅放大算法。</p>
<p><strong>解决问题</strong></p>
<p>局部搜索、求解线性方程组、有先验知识的量子搜索、体积估计问题、量子群测试算法、子团查找（社区发现）问题。</p>
<h3 id="方向和挑战"><a href="#方向和挑战" class="headerlink" title="方向和挑战"></a>方向和挑战</h3><ul>
<li>量子计算能否在多项式时间解决<font color='red'>（NP-难的）组合优化问题</font>？</li>
<li>量子计算能否加速困难组合优化问题的<font color='red'>近似算法</font>？</li>
<li>新型量子优化算法框架设计？</li>
</ul>
<p><img src='/assets/1601360428005.png' algin='center' width='70%'></p>
<h3 id="量子计算软件创新大赛感悟"><a href="#量子计算软件创新大赛感悟" class="headerlink" title="量子计算软件创新大赛感悟"></a>量子计算软件创新大赛感悟</h3><p>这次决赛的队伍是来自南大、中科大、上大、清华、北大、南方科大的六个团队，这些学校都是实力派强校。它们的作品也是经过层层选拔之后剩下来的。</p>
<p>他们的答辩都非常的精彩，能从他们的讲解中看出他们的强大的基础和自信，并且设计的方案也都非常的贴近实际场景，比如<strong>量子计算开源框架Mizore、北大的路线规划、DWBA</strong>等等，它们的思路都是将经典的方式方法迁移到量子机器上去，从而期望创造更多的商业价值。然而，这还不是最令我吃惊的地方。最让我印象深刻的是视频中前面那两位老师的问题，简直切中要害、非常犀利。这些问题让我更清晰地了解了这些团队得工作。</p>
<p>下面这些问题我印象深刻</p>
<ul>
<li><p>你这个项目用量子计算机来做有什么优势？有没有和经典方式的一个比较？</p>
</li>
<li><p>在处理过程中，有没有考虑噪声问题？</p>
</li>
<li><p>如果问题场景更加复杂，算法是否有效等？</p>
</li>
<li><p>怎么样进行梯度求导的，你的Loss function是什么？</p>
</li>
</ul>
<p>这些问题真的很宝贵，也带给了我很多思考。并且我发现，PPT答辩人都有一大堆的原因去解释，可总感觉他们没讲到点子上，还要争着抢着表达观点。有些功能没有就是没有，未来可以再加上呀，接过话筒就开始绕。这点我就比较欣赏清华的团队，很坦诚，有什么就是什么，有些功能就是没考虑到，后续可以进行完善。</p>
<p>还有一点感受就是他们的大部分项目没有突出自己的<strong>量子优势</strong>和<strong>算法复杂度</strong>，比如北大的交通网络设计，几个量子比特可以清晰的体现量子计算方面的优势呢？这时如果有个对比的图像或者表格那就完美了。还有DWBA，尽管我是第一次听区块链方面的内容，可是我总感觉他题目范围定的太大了。将拜占庭共识问题用量子计算解决是一个不错的思路，但是他没有用详细的公式去支撑他们的观点，直接就上很多涉及范围很广的结论，总之我半信半疑。</p>
<p>最后就是这些团队的方案基于经典理论，即使他们运用了量子计算的一些特点，但还是无可避免的与经典有千丝万缕的关系。也就是说他们的实现<strong>并不是完全基于量子的</strong>，而是将<strong>两者混合起来</strong>，例如先用经典计算机进行<strong>预计算</strong>，随后再将处理好的输入送入HIQ进行<strong>量子计算</strong>。总之，在这次高手们激烈角逐的过程中我学到了很多知识，有一些是概念性的比如<strong>最优容忍界</strong>、<strong>FLP不可能定理、Aharonov态、异步分布式系统、流守恒</strong>等等，还有一些就是怎样去表达观点和回答问题。</p>
<h2 id="Releated-Links"><a href="#Releated-Links" class="headerlink" title="Releated Links"></a>Releated Links</h2><p><a href="https://blog.csdn.net/github_37228709/article/details/107541005"><em>1. Colab、矩池云、mistGPU几个云GPU使用心得</em></a></p>
<p><a href="https://blog.csdn.net/jinyuan7708/article/details/89948938?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param"><em>2. Deep Learning时代最好用的云GPU——Google Colab</em></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/54389036"><strong><em>3. Google lab使用心得</em></strong></a></p>
<p><a href="https://blog.csdn.net/qq_36401512/article/details/96163940"><em>4. pytorch 关于显存增长原因以及显存占用优化</em></a></p>
<p><a href="https://blog.csdn.net/heyc861221/article/details/80125471"><em>5. 深度学习性能提升的诀窍</em></a></p>
<p><a href="https://stackoverflow.com/questions/61254168/prevent-a-google-colab-process-from-being-disconnected"><em>6. prevent-a-google-colab-process-from-being-disconnected</em></a></p>
<p><a href="https://www.sciencedirect.com/science/article/pii/S0010482520301621?via%3Dihub"><em>7. Automated detection of COVID-19 cases using deep neural networks with X-ray images</em></a></p>
<p><a href="https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5"><em>8. Dropout in (Deep) Machine learning</em></a></p>
<p><a href="https://docs.fast.ai/vision.data"><em>9. Vision Data</em></a></p>
]]></content>
      <categories>
        <category>周汇报</category>
      </categories>
      <tags>
        <tag>HTN</tag>
      </tags>
  </entry>
  <entry>
    <title>Tensor Operation in Python</title>
    <url>/2020/09/28/37Study-Report(0921-0927)/</url>
    <content><![CDATA[<h2 id="Tensor-Contracted"><a href="#Tensor-Contracted" class="headerlink" title="Tensor Contracted"></a>Tensor Contracted</h2><p>我们都知道诸如MPS、TTN、PEPS这些常见张量网络，那么相信你对张量缩并一定不陌生。<a href="https://blog.csdn.net/qq_45777142/article/details/107499465">刘紫豪同学的博客</a>里详细的介绍了张量之间的各种运算和应用。那么体现到代码里是什么样子的呢？其实，张量的缩并操作在python语言中有各种各样的表达方式，在<strong>numpy、tensorflow以及Pytorch</strong>中都提供了<strong><a href="https://numpy.org/doc/stable/reference/generated/numpy.einsum.html">einsum</a>,<a href="https://numpy.org/doc/stable/reference/generated/numpy.matmul.html">matmul</a>,<a href="https://numpy.org/doc/stable/reference/generated/numpy.tensordot.html">tensordot</a></strong>这三种方式用于计算张量的缩并。</p>
<a id="more"></a>
<p>举一个例子来说，假设A是一个3阶张量（三个指标维度为i,j,k），而B是一个4阶张量（j,k,m,n）。假如我们现在要将A张量的j,k两个指标和B张量的j,k两个指标进行缩并，得到一个<code>i*m*n</code>的三阶张量C，来看看代码里是怎么样的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">C = np.einsum(<span class="string">&#x27;ijk,jkmn-&gt;imn&#x27;</span>, A, B)</span><br><span class="line">C = np.matmul(tf.expand_dims(A,<span class="number">1</span>), B)</span><br><span class="line">C = np.tensordot(A, B, [[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">0</span>,<span class="number">1</span>]])</span><br></pre></td></tr></table></figure>
<p>在性能方面三个函数没有很大的差异，当然对于较小的矩阵<strong>np.matmul</strong>可能更加有效，因为它将生成一个更简单的<strong>张量流图</strong>，操作更少，因此每个操作的调用成本更低。在循环或含条件参数的地方，可以通过tensordot进行<strong>动态缩并</strong>。当然也有一些developer为了方便，开发了专门的张量运算库例如<strong><a href="https://github.com/andrewdarmawan/tncontract">tncontract</a>、<a href="https://github.com/google/TensorNetwork">TensorNetwork</a>(Google开发)，<a href="https://github.com/torch/torch7">Pytorch</a></strong>里也封装了各种各样的张量运算，在这里不仅能张量缩并，还能几句话实现非常复杂的<strong>张量参数反向迭代更新</strong>，降低了张量的操作难度。</p>
<p>总之，各界大佬早已经定义好了各种张量网络运算的工具，适当了解对开发是非常有帮助的。当然，选择一种自己顺手的工具要方便的多，对其他的方法也得了解。</p>
<blockquote>
<p>PS：<strong>SVD分解中，U是左奇异矩阵，可以用于行数的压缩，V是右奇异矩阵，可以用于列数的降维</strong></p>
</blockquote>
<h1 id="Learning-of-Pytorch"><a href="#Learning-of-Pytorch" class="headerlink" title="Learning of Pytorch"></a>Learning of Pytorch</h1><p><a href="https://github.com/dingliu0305/Hybrid-Tensor-Network">论文HTN代码</a>基于pytorch深度学习框架，而这个框架下有很多的方法和理论基础，于是在Coursera上在线学习<a href="https://www.coursera.org/learn/deep-neural-networks-with-pytorch/home/welcome">Deep Neural Networks with PyTorch</a>课程。这个课程非常详细的从基本数据结构Tensor开始讲起，每节视频3-10分钟，配套有视频代码，都可以在线运行、查看输出和讲解，每节视频都有配套的<strong>代码练习</strong>（这一点是至关重要的），而且不会很难，就是简单需要改几处，然后慢慢的增加难度。非常推荐对pytorch感兴趣的人去学习。</p>
<p>一边学着pytorch，一边我又多次去尝试读代码，思路慢慢理清楚了，程序的设计思路和方式，每一步的输出格式、内容也通过一次次调试弄明白了。中间遇到的那个问题，即代码中没有包含计算Accuracy部分已经补充完整，在output1计算出之后，通过以下代码计算每个batch_size的准确率</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pred_y = torch.max(output1, <span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">sum = int(torch.sum(pred_y == b_y))</span><br><span class="line">accuracy = sum / BATCH_SIZE</span><br></pre></td></tr></table></figure>
<p>还有一个坑就是，程序在开始运行的时候准确率只有10%，训练了好几个batch_size也没有明显的提升，于是就一步步追根溯源去查看backward更新函数，各种调试，最后发现人家写的还是对的。</p>
<p>那么问题出在哪里了呢，我在调试过程中发现，在反向传播BP更新参数那部分很复杂，每一层都有相当多的参数（尤其是张量网络层），例如最上一层是<code>16*16*3*3*3*3*3</code>，然后是<code>8*8*3*3*3*3*3</code>就是按照TTN的结构以此类推。参数这么多我估计得训练很多轮，于是就只能先跑几轮看看效果，不看不知道，一看吓一跳</p>
<p><img src="/assets/1601029097250_meitu_1.jpg" alt="1601029097250"></p>
<p>仅仅经过两轮就整体上看到了test acc的增长，尽管每次的幅度很小（这意味着学习率很低）。上述仅仅2个epoch就耗费了大约两个小时的时间，因此我将更高的epoch次数（50+）放到了服务器上，以便于能昼夜不停地尽快得到最好的结果，目前fashion-mnist最高准确率达到90%，跟论文中的描述一致，40-50epoch基本没有变化，可能参数已经接近收敛了，重新设计网络或许能改善效果。</p>
<p>对于上述方案，可以改进的参数和设计还有很多，例如<strong>学习率的大小</strong>，<strong>张量网络层</strong>和神经网络层的结构都可以进行调整。代码中神经网络层部分仅仅用了<strong>两个线性层</strong>作为补充，而诸如<strong>CNN、RNN</strong>等神经网络结构也可以一定程度上提高准确率。这篇论文代码只给了fashion-MNIST的代码，MNIST的代码已经在跑了，同时我还在尝试修改网络的结构，以达到更好的效果。</p>
<p>经过一晚上的设计，终于研究出了以下（含卷积层）的混合神经网络，下面将在MNIST上训练并查看这种设计的效果。</p>
<p><img src="/assets/1601211309856.png" alt="1601211309856"></p>
<p>还有一些tensorboard和torch库的基本知识，内容比较多，就不再一一列举啦，以上就是本周的汇报。</p>
<h2 id="Releated-Links"><a href="#Releated-Links" class="headerlink" title="Releated Links:"></a>Releated Links:</h2><p><a href="https://stackoverflow.com/questions/37987839/how-can-i-run-tensorboard-on-a-remote-server#comment83193829_40413202"><em>1. How can I run Tensorboard on a remote server?</em></a></p>
<p><a href="https://blog.csdn.net/qq_24739717/article/details/103068009"><em>2. 学习笔记|Pytorch使用教程20(TensorBoard使用（一）</em></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/101157166"><strong><em>3. einsum初探</em></strong></a></p>
<p><a href="https://pytorch.org/docs/stable/tensorboard.html"><em>4. TORCH.UTILS.TENSORBOARD</em></a></p>
<p><a href="tensorflow.org/tensorboard/graphs"><em>5. Pytorch官方文档</em></a></p>
<p><a href="https://blog.csdn.net/out_of_memory_error/article/details/81434907"><em>6. pytorch在MNIST上采用CNN的例子</em></a></p>
]]></content>
      <categories>
        <category>周汇报</category>
      </categories>
      <tags>
        <tag>张量基础</tag>
      </tags>
  </entry>
  <entry>
    <title>《张量网络基础课程》第六章</title>
    <url>/2020/09/13/36Study-Report(0907-0913)/</url>
    <content><![CDATA[<p><img src="/images/AI_Map.png" alt="cover"></p>
<a id="more"></a>
<h3 id="6-1-张量网络机器学习基本思想"><a href="#6-1-张量网络机器学习基本思想" class="headerlink" title="6.1 张量网络机器学习基本思想"></a>6.1 张量网络机器学习基本思想</h3><p>张量网络机器学习的实质就是，利用张量网络建立输入到输出的映射，并使用张量网络算法实现变分参数的更新。</p>
<p>张量网络机器学习的基本步骤：将数据编码/嵌入到希尔伯特空间；利用张量网络在该空间进行<strong>映射</strong>获得输出。</p>
<p><img src="/assets/48c45ff003d2ea9baa1099701d9e64a7.png" alt=""></p>
<p>表达非常清晰的一张图，说明了<strong>机器学习</strong>和<strong>张量网络学习</strong>的过程，并很好地体现了两者的差别，即张量网络学习多了<strong>特征映射</strong>这一步，随后通过张量网络而非神经网络进行训练。</p>
<p>张量网络的优点是，它能在<strong>可解释性</strong>和<strong>准确率</strong>上达到一个较好地平衡点，但它的效率和准确度不如神经网络。神经网络的优点是准确率高，但它的可解释性不强。</p>
<h3 id="6-2-特征映射、希尔伯特空间与量子概率"><a href="#6-2-特征映射、希尔伯特空间与量子概率" class="headerlink" title="6.2 特征映射、希尔伯特空间与量子概率"></a>6.2 特征映射、希尔伯特空间与量子概率</h3><p>特征映射的基本思想是，通过<strong>特征映射</strong>，将一个样本映射成L个qubit的直积态（L为特征的个数），以图像为例设第n张图片的第个像素值为($x_i^{[n]}(0&lt;x_i^{[n]}&lt;1)$)，将其映射成为单qubit态</p>
<p>$$<br>|x_i^{|n|}  ⟩=cos (x_i^{[n]} π)/2 |0⟩+sin (x_i^{[n]} π)/2 |1⟩<br>$$</p>
<p>通过这种映射就能将<strong>一整张图片映射成为</strong>由个qubit构成的直积态，如下所示</p>
<p>$$<br>|X^{[n]}  ⟩=∏_{⊗l=1}^L[|x_l^{[n]}⟩]<br>$$</p>
<p>那么对于具备L个像素的图片集而言，假设其联合概率分布由L个qubit构成的多体态（记为）描述，满足</p>
<p>$$<br>P(y_1,…,y_L )=[(∏_{⊗l=1}^L[|(y_i |ψ)|])]^2<br>$$</p>
<p>$P(y_1,…,y_L )$表示该概率分布给出的样本出现的概率，用张量网络图可以表示为</p>
<p><img src="/assets/4d93aea728f4e369603bae5159025271.png" alt=""></p>
<p>这里还有一个比较重要的性质，<strong>如果局域量子空间的维数等于特征取值个数d=D（例如黑白图与d=2映射），则不同样本对应的量子态将完全正交，有</strong></p>
<p>$$<br>⟨X^{[m]} │X^{[n]}  ⟩=0<br>$$</p>
<p>这意味着，其中一张图片量子态对应的概率分布中，出现与之不同的图片的概率为0。但是视频中提到此处的正交性意义不大，即使特征取值个数d\&lt;D，此时各个样本的概率和会大于1，<strong>概率归一性被违背，</strong>但结果与单位矩阵仅相差一个<strong>归一化因子。</strong>更详细的解释可以看论文《Phys. Rev. X 8, 031012 (2018)》和《Phys. Rev. B101,,075135 (2020)》</p>
<h3 id="6-3-等概率假设和量子懒惰学习"><a href="#6-3-等概率假设和量子懒惰学习" class="headerlink" title="6.3 等概率假设和量子懒惰学习"></a>6.3 等概率假设和量子懒惰学习</h3><p>对于一大类图片，例如0到9的手写字体，可以训练量子态，使得该类中每一张图片出现的概率非零且相等，即</p>
<p>$$<br>P(X)=[(∏_{⊗l=1}^L[|(x_i |ψ)|])]^2=const.<br>$$</p>
<p>等概率假设：当上式成立时，我们认为给出的联合概率分布接近该类图片给出的像素的联合分布。要想满足同类中图片出现的概率<strong>非零且相等，</strong>一种可行的方案如下</p>
<p>$$<br>|ψ^{lazy}⟩=1/√(|X|) ∑<em>(X∝x)∏</em>{⊗l=1}^L|x_i⟩<br>$$</p>
<p>其中$|X|$代表$X$中的图片数量，上态称之为<strong>lazy态</strong>。我觉得之所以将其称为lazy态，是因为这个量子态不需要经过训练，而是直接能根据图片特征映射得到，是一个通用的模板，因此通过lazy态实现机器学习任务被称为<strong>量子懒惰学习(quantum lazy learning)</strong>。</p>
<p>上面是以一个类别进行举例，那么将其用于MNIST数据集，就是10个lazy态${[|ψ]_k^{lazy}⟩}$，那么就可以<strong>根据量子概率定义，估计任意图片（记为Y）出现在第k类的概率</strong></p>
<p>$$<br>P_k (Y)=[|⟨Y|ψ_k^{lazy}⟩|]^2<br>$$</p>
<p>显然，通过就能得到概率最大的那个类，这个类就是分类器${[|ψ]_k^{lazy}⟩}$给出的该图片的分类预测，这种非参数的方法可以给出不错的分类结果：<strong>MNIST– 97%</strong>，<strong>fashion-MNIST –85%</strong>。<strong>量子懒惰学习</strong>的表现不如神经网络，但是超过了SVM、NB等传统机器学习算法。</p>
<p>上述算法，是核心，但其<strong>参数复杂度会随着特征个数L指数上升</strong>，那么用张量网络表示它就能使参数复杂度降低到<strong>多项式级</strong>，在给定N个训练集样本后，我们可以训练量子态，使其满足<strong>等概率假设</strong>$P(x^[1]  )= P(x^[2]  )=⋯​$，这被称为<strong>MPS非监督机器学习</strong>。那么如何能够构建<strong>等概率假设</strong>的条件呢，<strong>交叉熵损失函数</strong>正好解决了这个问题，它的公式如下</p>
<p>$$<br>f({x^{[n]}})=-1/N∑<em>1^N[ln⁡[(∏</em>{⊗l=1}^L[|⟨x_l^{[n]}|ψ⟩|])]^2]<br>$$</p>
<p>损失函数f取极小时正好能满足等概率假设的条件（之前的汇报里证明过）。</p>
<h3 id="6-4-监督-非监督张量网络机器学习"><a href="#6-4-监督-非监督张量网络机器学习" class="headerlink" title="6.4 监督/非监督张量网络机器学习"></a>6.4 监督/非监督张量网络机器学习</h3><p>通过梯度更新方法，更新张量网络中的张量，使得损失函数在一次次迭代中降到极低，梯度更新公式为</p>
<p>$$<br>A^{(L)}⟵A^{(L)} -η ∂f/(∂A^((l)) )<br>$$</p>
<p>其中$η$为学习率</p>
<p>使用MPS表示$|ψ⟩$时，可利用<strong>MPS中心正交形式，</strong>逐个更新各个张量，步骤如下</p>
<ol>
<li><p>更新第$l$个张量$A^{(L)}$时，将正交中心移动到该张量</p>
</li>
<li><p>利用张量网络微分法则，求出损失函数关于$A^{(L)}$的梯度（见下图）</p>
</li>
</ol>
<p><img src="/assets/df8a1b3f70359821d91233956c4241dd.png" alt=""></p>
<h3 id="6-5-张量网络图片生成与压缩"><a href="#6-5-张量网络图片生成与压缩" class="headerlink" title="6.5 张量网络图片生成与压缩"></a>6.5 张量网络图片生成与压缩</h3><p>获得量子态后，不但可以求出像素的联合概率密度，还可以计算条件概率，具体内容为，考虑已知与图片中的部分像素（记为$[{x]_m^{[A]}}$），则剩余位置像素（记为${[x]_n^{[B]}}$）的概率分布可由如下条件概率给出<br>$$<br>P([{x]_n^{[B]}  }|[{x]<em>m^{[A]} })=[(∏</em>{⊗n}[⟨x_n^{[B]}  |ψ]⟩)]^2<br>$$</p>
<p>量子态为通过对的投影测量获得<br>$$<br>|ψ ̌  ⟩=1/Z ∏_{⊗m}[⟨x_m^{[A]}  |ψ⟩]<br>$$</p>
<p>其中Z为归一化系数，上述式子用张量网络可表示为</p>
<p><img src="/assets/db62224d0c6fbfd70ccba899759c295b.png" alt=""></p>
<p><img src="/assets/be109937fe04cba8d4ecbc490ed20ada.png" alt=""></p>
<h3 id="6-6-监督张量网络机器学习"><a href="#6-6-监督张量网络机器学习" class="headerlink" title="6.6 监督张量网络机器学习"></a>6.6 监督张量网络机器学习</h3><p><strong>监督性张量网络机器学习可以看做是非监督的自然推广</strong>，这点是不同于神经网络等非概率机器学习模型的，因为神经网络模型的非线性映射是不可逆的。以分类任务为例，需要使用张量网络建立从<strong>数据</strong>到<strong>分类标签的函数映射，</strong>而对于概率模型而言，该映射可以由<strong>条件概率P</strong>给出：<br>$$<br>f:{x}→κ ⇒P(κ|{x})<br>$$</p>
<p>那么可以考虑<strong>用张量网络建立该条件概率，</strong>一种常用的方法<strong>采用非监督学习的方法先获得并计算联合概率分布，再通过投影计算获得条件概率。</strong></p>
<p>中含有（L+1）个qubit，其中L个qubit是图片像素的映射，一个qubit对应于分类的标签；因此，MPS表示中含有（L+1）个物理指标。</p>
<p><img src="/assets/429b7d3778600a0102c691c3ccc195ec.png" alt=""></p>
<p><strong>进行监督性学习的具体方法是：</strong></p>
<ol>
<li><p>将分类标签也当做是特征量，利用训练集进行非监督机器学习，训练量子态；</p>
</li>
<li><p><strong>利用投影计算条件概率</strong>$P(κ│{x} )=[(|ψ ̌ ⟩ ∑_{⊗n}[⟨x_n |ψ ̌ ]⟩)]^2$，分类结果即为最概然的标签值$[argmax]_k P(κ|{x})$</p>
</li>
</ol>
<p>当然，非监督张量网络的机器学习，并不一定要按照条件建立概率映射，例如当矩阵乘积态<strong>不满足量子态对应的归一化条件</strong>时，张量网络量子概率的<strong>可解释性</strong>也就受到影响，上面的算法就失效了，此时可以直接用<strong>梯度下降法</strong>训练模型（自动微分技术）</p>
<h3 id="6-7-张量网络与经典概率模型"><a href="#6-7-张量网络与经典概率模型" class="headerlink" title="6.7 张量网络与经典概率模型"></a>6.7 张量网络与经典概率模型</h3><p>张量网络不仅可以作为非概率性的映射进行监督机器学习，也可以作为<strong>量子概率性机器学习</strong>，还可以作为经典概率模型进行概率性机器学习，其中两个例子为受限玻尔兹曼机和贝叶斯张量网络。</p>
<p><img src="/assets/047d4dab88950fe3a1a8f5be3fc364b6.png" alt=""></p>
<h2 id="论文《Deep-convolutioanl-tensor-network》"><a href="#论文《Deep-convolutioanl-tensor-network》" class="headerlink" title="论文《Deep convolutioanl tensor network》"></a>论文《Deep convolutioanl tensor network》</h2><p>论文中主要完成的工作：</p>
<ol>
<li><p>提出了一个基于张量网络的新张量模型，该模型基于张量网络组成（称为EPS（Enquetted<br>Plaquette状态）），可以满足<strong>参数共享、局域性和深度</strong>的需求</p>
</li>
<li><p>展示了EPS如何实现<strong>向后传播的功能层，</strong>这可以用于神经网络或者其他基于向后传播的模型</p>
</li>
<li><p>使用常用的技术训练深度神经网络，并在FashionMNIST上训练并评估模型。我们发现，虽然基于一个EPS的浅层模型在<strong>精度和参数数目</strong>方面与DCNN具有竞争性，但使其更深会导致更多的<strong>过拟合</strong>，从而<strong>导致精度降低</strong></p>
</li>
<li><p>展示了各种超参数如何影响模型的优化和概括</p>
</li>
</ol>
<p>这篇论文首先介绍了一个张量网络中的<strong>copy操作</strong>，能够copy输入或者输出向量，一个比较形象的例子如下，在用箭头表示的输入边处用红点标记，输出边用另一种方式标记，这种copy操作等价于两个相同的input向量与张量网络进行收缩，如下图所示</p>
<p><img src="/assets/18ea6993cb04558672d68c0a9087e3ea.png" alt=""></p>
<p>对于输入数据，仍然同之前的论文一样，将各个像素或样本映射到<strong>归一化的向量上</strong>，用它们的张量积表示系统量子态，如下图所示，图中表示了20个张量的<strong>张量积。</strong></p>
<p><img src="/assets/85f3a3e31312757bd400b9c9ede4c195.png" alt=""></p>
<p>这篇文章采用的映射函数为：<br>$$<br>ψ(x)=ν[(〖cos〗^2 (π/2 x)@〖sin〗^2 (π/2 x))]<br>$$</p>
<p>随后，文章中又讲解了EPS态的原理，它定义了kernel<br>size(这一点非常类似于卷积神经网络CNN中的kernel)，通过这一层EPS得处理，就能将参数化为一个的张量，其中为输入，1为输出。一个3*3矩阵的EPS处理示例如下</p>
<p><img src="/assets/b757062c28739a24519117c7d68b495a.png" alt=""></p>
<p>然而一张图片可以有很多个3*3或者2*2这样的子矩阵，因此就可以对这些局部采用EPS进行处理，以一张4*3的图片为例，它的EPS核可以按照下图的方式收缩，可以看到每个2*2的子矩阵收缩成了一个EPS张量。</p>
<p><img src="/assets/47ebf778f8bfa6ef796df8b1af78998c.png" alt=""></p>
<p>对于图片的处理流程可以表示如下，即先<strong>对图片进行映射</strong>，其次采用<strong>N层EPS</strong>进行参数化。随后用一个矩阵A和向量b线性层进行映射，<strong>softmax激活层进行激活</strong>，整体的模型可以用如下的等式进行定义<br>$$<br>x_0 (h,w)=φ(X(h,w)) \<br>X_1=eps(E_1,X_0)\<br>X_2=eps(E_2,X_0)\<br>…\<br>X_N=eps(E_N,X_0)\<br>lnp ̂(y=l│X)=[(A∙vec(X_N )+b)]_l\<br>$$</p>
<p>上述公式非常清晰的阐明了EPS完整的网络结构，可以通过下图展示EPS网络来训练输入张量的过程</p>
<p><img src="/assets/fffe44bec8eeae579243846fe3aabab0.png" alt=""></p>
<p>再来一个对4*4图片采用两层EPS的张量网络展示，从这个图中可以看到，每一层EPS都有单独的Kernel<br>size，收缩单位都是上一层EPS的输出张量。</p>
<p><img src="/assets/8756acf6fa5aae0d1d99950ed79e60c3.png" alt=""></p>
<p>在文章的最后，还介绍了一些EPS网络参数优化的方法，并且通过实验验证了EPS的效果，类似于DCTN(deep convolutional tensor network），在<strong>参数共享、局域性和深度</strong>方面都有较好的表现。但是另一方面，多层的EPS网络很容易导致过拟合造成较差的结果，因此文中建议就是可以将EPS仅作为神经网络中的一层操作。详细代码见<a href="https://github.com/philip-bl/dctn">Github</a>.</p>
<p>这个代码我下载下来看了一下，基于python3.7和深度学习框架torch，代码整体非常规范，项目比较大，看起来比较吃力。远比之前TTN网络训练MNIST要复杂。而HTN论文中缺少代码，正在编码想复现HTN这篇网络。卢陈玉学长的代码中，将tucker和cp分解处理后的图片和卷积神经网络结合起来，可以作为HTN中神经网络层的参考。因此HTN论文复现的关键就在于<strong>通过TTN网络压缩图片(</strong>两篇论文的TTN略有不同<strong>)，</strong>将其<strong>作为后续深度学习网络的输入。</strong></p>
<p>结尾附上赖老师赠送给我的一张量子计算的层次结构图，非常清晰。就不需要再纠结上面论文中的算法如何设计成<strong>量子线路了</strong>（其实本身也是一头雾水。。。），只需要关注如何将复杂的张量网络机器学习算法如何用量子态进行表示和处理就OK了。</p>
<p><img src="/assets/2b048be34aa9e4cb940526d22646ca2b.jpg" alt=""></p>
<p>下面这张图也很useful,浅水区域表示了人工智能已经比较成熟的领域。陆地上的是正在热门解决的问题，高山上的是比较棘手复杂的AI问题，例如AI设计、写书、科学研究等。</p>
<p><img src="/assets/a9ff7d12cb7bbe00703a592e95337ed7.png" alt=""></p>
]]></content>
      <categories>
        <category>周汇报</category>
      </categories>
      <tags>
        <tag>张量基础</tag>
      </tags>
  </entry>
  <entry>
    <title>HTN Paper</title>
    <url>/2020/09/06/35Study-Report(0831-0906)/</url>
    <content><![CDATA[<h2 id="小程序"><a href="#小程序" class="headerlink" title="小程序"></a>小程序</h2><p>小程序的开发用了较长的时间，一方面经验不足，一方面是小程序的开发组件还有待完善。</p>
<ul>
<li><p>如何唯一标识用户(_openId)</p>
<p>即使用户没有对小程序授权，小程序也可以获取每个访问用户的唯一标识（openId），可以通过云函数进行获取。</p>
<a id="more"></a>
</li>
<li><p>如何表示矩阵、公式？</p>
<p>小程序目前的渲染功能还比较有限，不支持Latex、MathType，并且这类公式在存储到数据库中时也十分的不方便，因此采用图片的形式，将题目保存成图片，随后读取出来，只要位置大小安排合理，能够正常显示。</p>
</li>
<li><p>控件和布局可以用现成的框架Weui，Vant等等，开发起来事半功倍。当然要是能熟练运用flex布局，那也是妥妥的</p>
</li>
</ul>
<h2 id="Quantum-Classical-Machine-learning-by-Hybrid-Tensor-Networks"><a href="#Quantum-Classical-Machine-learning-by-Hybrid-Tensor-Networks" class="headerlink" title="Quantum-Classical Machine learning by Hybrid Tensor Networks"></a>Quantum-Classical Machine learning by Hybrid Tensor Networks</h2><h3 id="3-1-介绍"><a href="#3-1-介绍" class="headerlink" title="3.1 介绍"></a>3.1 介绍</h3><p>这篇文章结合<strong>传统张量网络</strong>和<strong>深度学习</strong>提出了一种<strong>量子经典混合张量网络</strong>，能够有效的克服传统张量网络的缺点。这样的<strong>混合张量网络</strong>能够以深度学习的方式与BP、SGD等算法结合，并且论文中还提到，这样一种网络能够作为一种新型的<strong>深度学习算法框架</strong>，如下图</p>
<p><img src="/assets/879be0a02961a360ce311a4bb024b0be.png" alt=""></p>
<h3 id="3-2-张量网络机器学习的局限性"><a href="#3-2-张量网络机器学习的局限性" class="headerlink" title="3.2 张量网络机器学习的局限性"></a>3.2 张量网络机器学习的局限性</h3><p>同时文中还介绍了<strong>正则张量网络</strong>的一些限制，如下</p>
<ol>
<li>表示能力</li>
</ol>
<p>张量网络是一个线性函数并且遵从量子力学的叠加原理，这是量子多体系统中张量网络的固有特性，但同时也是建立<strong>强大的机器学习通用分类器的障碍</strong>，所以在处理时一般都通过非线性函数映射成到Hilbert空间，因此<strong>特征映射函数</strong>是张量网络机器学习的一个关键点(类比SVM)。张量网络机器学习TTN需要比经典模型(CNN、FCN等)更多的参数，而文中的<strong>量子经典混合张量网络</strong>需要的参数比TTN还要少的多！参数的比较见下图</p>
<p><img src="/assets/4a4d245e651e1944d8cd321820cbb1fb.png" alt=""></p>
<ol>
<li>体系结构的可扩展性</li>
</ol>
<p><img src="/assets/4505f794f327f2c207b568ef4019e4f2.png" alt=""></p>
<p>图(a)表示的是神经网络，可以看到<strong>输出神经元权重数目</strong>要大于<strong>输入神经元权重数(</strong>例如全连接层<strong>)</strong>，这使得神经网络能够实现一对多的映射关系。相反图(b)和图(c)表示的张量网络，只是进行一对一的张量的收缩关系，因此对于单个张量，无法将输入数据映射到多组输出方向上，这一点就<strong>极大的限制了张量网络的可扩展性。</strong></p>
<h3 id="3-3-混合神经网络"><a href="#3-3-混合神经网络" class="headerlink" title="3.3 混合神经网络"></a>3.3 混合神经网络</h3><p>为了解决张量网络的局限性，一个基本的想法就是通过将<strong>张量网络和神经网络</strong>结合起来，从而引入非线性。而训练HTN的方式则可以采用BP或者SGD算法，那么以BP算法为例，计算第i张量网络层的偏导数的公式如下。</p>
<p><img src="/assets/cefc9d2c3a147e42cd4123c01846f821.png" alt=""></p>
<p>而张量网络中张量的收缩过程可以用如下公式表示：</p>
<p><img src="/assets/16d5f4701d4230f5c3194c0f68e8b259.png" alt=""></p>
<p>其中表示i+1层的第k个张量，所以(2)式推导为：</p>
<p><img src="/assets/a45b75d8c0b8fe6b1f987fa2feaf49f3.png" alt=""></p>
<p>其中表示第i层的第j个张量，随后用梯度下降更新张量</p>
<p><img src="/assets/b6ff5f61c6f7ebc9deabc271f410a07d.png" alt=""></p>
<p>其中表示学习率，用这样的方式可以逐步更新HTN中的各个张量</p>
<h4 id="3-4-量子态分类和量子分类自编码"><a href="#3-4-量子态分类和量子分类自编码" class="headerlink" title="3.4 量子态分类和量子分类自编码"></a>3.4 <strong>量子态分类和量子分类自编码</strong></h4><p>分类的思路也比较容易理解，首先是将图片的像素映射成量子态，单个像素的映射如下</p>
<p><img src="/assets/b48a49d4b30470aecc5f6635740abbfc.png" alt=""></p>
<p>随后将像素表示成矩阵成绩态，如下</p>
<p><img src="/assets/f953a9ebb0bc7aba45d3a39fe43a85bd.png" alt=""></p>
<p>将作为输入，与现成的张量网络进行收缩，将输入表示成低维的中间态，即对应如下的公式</p>
<p><img src="/assets/eb158b15460bf6bc3dd007b7a4442eda.png" alt=""></p>
<p>那么中间态(也就是后面神经网络的输入)就可以表示为</p>
<p><img src="/assets/407e6a5eb3d6730d5238c3d0629af7c7.png" alt=""></p>
<p>其中M表示测量操作，随后通过神经网络层将输入分成对应的十个类别，训练过程如下图</p>
<p><img src="/assets/0968f4a2730b423b10c47be88cc5f44d.png" alt=""></p>
<p>量子分类器自编码就是将输入的量子态压缩成低维的中间态，将损失函数换位MSE，同时使用PSNR来对比图片压缩前后的差异，对MNIST数据的压缩如下所示。</p>
<p><img src="/assets/db1f021ee86472ba575412e96e484a49.png" alt=""></p>
]]></content>
      <categories>
        <category>周汇报</category>
      </categories>
      <tags>
        <tag>HTN</tag>
      </tags>
  </entry>
  <entry>
    <title>Unsupervised Learning TNCS</title>
    <url>/2020/08/30/34Study-Report(0824-0830)/</url>
    <content><![CDATA[<p>简单看了一下这篇论文，它介绍了一种TNCS（Tensor network compressed sensing）算法来进行<strong>图片压缩</strong>。算法的思路是这样的：首先通过TN机器学习算法来将信息（或像素）投影到（也被称为波恩机）上，然后可以将它传递给对方，对方再进行解码还可以恢复到原本的整体数据，整个算法过程如下</p>
<a id="more"></a>
<p><img src="/assets/89d7e4f039c1c94af9cf1de864d45c8f.png" alt=""></p>
<p>算法能够将所有的像素存在量子概率分布中：</p>
<p><img src="/assets/36001ac220e62d57d384f28923e7c20e.png" alt=""></p>
<p>从上图可以看出，仅传递40个像素，就能将这个图片传递的差不多了，极大的减小了传输开销。</p>
<h2 id="二、FRQI算法代码"><a href="#二、FRQI算法代码" class="headerlink" title="二、FRQI算法代码"></a>二、FRQI算法代码</h2><p>FRQI算法代码以彩色图像为列，进行量子态映射，代码的整体过程是这样的。第一步，先对图片的每一个像素进行rgb三元素映射（映射公式如下所示）<br>$$<br>θ=π/2(r/16+g/16^2 +b/16^3 )<br>$$<br>其次，将表示像素的作为量子电路中cu3门的输入进行处理，设计的电路如下所示</p>
<p><img src="./assets/a864474058bd4a7467b531c0c1b362a5.png" alt=""></p>
<p>其中，cu3门的算符代入参数后可以表示为</p>
<p><img src="./assets/b9ce1569a30435e126a329006d9d8103.png" alt=""></p>
<p>经过对这个电路的局部验证，最终能够与论文中提到的公式达成一致。我通过这次验证，也是较为清楚的理解了电路设计和实现的核心思想，从熊珏婵那里学到很多知识，验证过程如下：</p>
<p><img src="/assets/ea6a532f5e1bdb07e546a057192cfae6.jpg" alt=""></p>
<p>可以看到这部分电路是基本组成，依次对各个套用这样的门电路处理，最终就能得到如下结果，即将图片的n个像素映射成为级别的qubit量子态来表示，极大的节省了空间，提高了处理效率</p>
<p><img src="/assets/2f57100375956817987171f350a51125.png" alt=""></p>
<p>随之而来的一个问题就是，通过这样像素的映射，将对像素的操作转移到量子电路上来，能够对像素进行并行计算。<strong>那么在将该映射方法套用到张量网络处理MNIST数据集时，如何将张量网络设计成处理电路？</strong>这是一个比较重要的问题，一个关于将张量网络和量子态结合的问题。在tree<br>TN那篇文献的附加代码中，张量网络仍是基于传统电路的串行处理模式进行处理，接下来会继续回顾《Towards<br>quantum machine learning with tensor networks》这篇文章。</p>
<p>TTN那部分代码的测试集准确率仍比较低，最高达到90%，各种方法都尝试了，例如划分数据集、修改评估函数等，结果没有显著上升。我觉得能解决高维辅助指标的表示问题，或许能有所改善。</p>
<h2 id="三、张量网络基础课程"><a href="#三、张量网络基础课程" class="headerlink" title="三、张量网络基础课程"></a>三、张量网络基础课程</h2><p>3.1 张量网络的基本定义</p>
<p>张量网络其实表示一个大的张量，这个大张量的指标其实就是<strong>张量网络中的物理指标</strong>。一个高阶张量可以被表示成不同的张量网络，如下图</p>
<p><img src="/assets/c7cdf2421f0cdd9292912bff35386933.png" alt=""></p>
<p>闭合张量网络：将张量网络中的所有几何指标求和之后表示一个标量，这类网络可以用来表示一大类问题，例如格点模型的配分函数，量子多体态的观测量等</p>
<p>3.2 张量网络的低秩近似</p>
<p>解决如下问题：<strong>在如下给定的张量网络中，如何裁减某一个几何指标的维数，使得裁减前后的误差极小？</strong></p>
<p><img src="/assets/07f507c32930243a7439401534795471.png" alt=""></p>
<p>一种可行的方案就是，将将张量网络reshape成一个大矩阵，矩阵的横向是s1,s2指标，纵向是s3,s4,s5指标，然后进行SVD分解（这样可能会改变网络结构）</p>
<p>另一种方案是引入非方的裁减矩阵（），与连接待裁减指标的张量进行收缩，实现该指标的维数裁减。</p>
<p><img src="/assets/f265967f011972618d633ff15654b108.png" alt=""></p>
<p>那么如何计算裁减矩阵呢，视频中给出了两种方法：</p>
<ol>
<li><p>通过规范变化，将张量网络变换为中心正交形式，正交中心为连接待裁减指标的两个张量中的一个</p>
</li>
<li><p>对正交中心的张量进行奇异值分解，由前个奇异向量构成，且</p>
</li>
</ol>
]]></content>
      <categories>
        <category>周汇报</category>
      </categories>
      <tags>
        <tag>图片压缩</tag>
      </tags>
  </entry>
  <entry>
    <title>量子图像处理及应用</title>
    <url>/2020/08/23/33Study-Report(0817-0823)/</url>
    <content><![CDATA[<p><a href="https://mp.weixin.qq.com/s?__biz=MzUxMDQzNzEzNA==&amp;mid=2247484527&amp;idx=1&amp;sn=cc8a4dce08140f954d052705f7405b28&amp;chksm=f903b60ece743f1802d5bbafa3db0ce692795419e6df365a1d26e215df7aada060dc0c84a370&amp;scene=21#wechat_redirect">这篇文章</a>简要介绍了图像映射到量子态上的几种方式，分别是QImR、qubit<br>lattice、FRQI以及NEQR，它们各有特点，详细如下：</p>
<a id="more"></a>
<h3 id="1-1-QImR"><a href="#1-1-QImR" class="headerlink" title="1.1 QImR"></a><strong>1.1 QImR</strong></h3><p><strong>这个算法的思想就是将列向量映射成为一个量子态。例如一张m*n的图片，那么一共有n个量子态。每个量子态可以有m个基态，这m个基态的概率幅就表示像素值，而基态本身则能够很好的表示像素对应的位置，这样就能完整的将一个经典的图像映射为量子态表示。</strong></p>
<p><img src="/assets/cafd5d3b503601ef50e2d97ff138e313.png" alt=""></p>
<h3 id="1-2-Qubit-Lattice"><a href="#1-2-Qubit-Lattice" class="headerlink" title="1.2 Qubit Lattice"></a><strong>1.2 Qubit Lattice</strong></h3><p><strong>对于一个输入图像，其中每一个像素点都有一个qubit来表示。因此需要至少2\^n比特的存储。</strong>虽然这种存储方式仅仅是将经典比特转换为量子比特来表示，并没有利用到量子纠缠的性质，但也与经典的存储方式有一定的区别，转换过程如下图所示。</p>
<p><img src="/assets/50b4cda33d636d2f7f1927d7447c908e.png" alt=""></p>
<h3 id="FRQI："><a href="#FRQI：" class="headerlink" title=" FRQI："></a><strong> FRQI：</strong></h3><p>FRQI也是一种比较高效的处理方式，其转换过程如下图。</p>
<p><img src="./assets/7312f086d3e3d6f0dc499ac34b3a4649.png" alt=""></p>
<p>这种编码方式将像素值和像素位置通过量子态张量积的形式进行了关联，与上述qubit<br>lattice不同的地方在于，qubit<br>lattice是一个量子比特对应一个像素信息，因此需要2\^n个量子比特；而后者(FRQI)则采用了n个量子比特来编码像素位置，大大的减少了量子比特所需要的数量。</p>
<h3 id="1-3-NEQR："><a href="#1-3-NEQR：" class="headerlink" title="1.3 NEQR："></a>1.3 NEQR：</h3><p>同样地，下图列举了一个简单的2*2维图像及其NEQR量子态表示：</p>
<p><img src="/assets/d164a3ed88e4daea2f0a907ab202642c.png" alt=""></p>
<p><img src="/assets/772c22a37af7fcb62ce323430f218678.png" alt=""></p>
<p><strong>尽管NEQR算法看起来使用了更多的比特去编码像素信息，但它也有它的优点，NEQR量子态的各个基态是正交可区分的，因此NEQR的量子图像是可区分的。这使得在量子图像的准备阶段，NEQR相比FRQI实现了二次加速，在量子图像压缩率上实现了1.5倍的提升。总体相比其他的量子图像模型更灵活且更适用于量子图像表示。</strong></p>
<h3 id="1-4-感受心得"><a href="#1-4-感受心得" class="headerlink" title="1.4 感受心得"></a><strong>1.4 感受心得</strong></h3><p>我发现之前进行的编程和考量都是基于将每一个像素处理成一个基态的表示，那么一张m*n的图片需要m*n个量子比特去存储表示，这显然与传统的经典比特没有什么区别，完全<strong>没有考虑到量子纠缠的性质</strong>(但考虑了叠加态的性质)<strong>。</strong>如果不考虑这n个量子比特之间的纠缠性(也就是各个量子态独立)，那么能表达的基态个数为2n，仍然是相当大的一个复杂度。可是如果能够借助量子之间的纠缠性，那么数据才能真正意义的实现n个比特能够表示2\^n次方的基态，也就对应着2\^n次方的数据（概率幅的平方）。</p>
<p>这个地方就很好地回答了师兄的疑问，确实对像素进行逐个独立的映射显然不能充分的发挥量子的纠缠优势。</p>
<h2 id="二、TTN结构的机器学习代码"><a href="#二、TTN结构的机器学习代码" class="headerlink" title="二、TTN结构的机器学习代码"></a>二、TTN结构的机器学习代码</h2><h3 id="2-1-目前进度说明"><a href="#2-1-目前进度说明" class="headerlink" title="2.1 目前进度说明"></a>2.1 目前进度说明</h3><p>代码中的参数主要是<strong>输入键（Input bond）的维度，虚拟键（Virtual<br>bond）的维度、样本的个数（n_train）、迭代的次数（n_epochs）</strong>这几项，通过不同的组合来验证论文的内容。</p>
<p>在之前遇到的训练准确率不正常的问题，通过对像素进行归一化处理成功解决，得到了有效的测试集准确率，尽管没有达到实验中那样效果，但也明确了方向。这时能够得到t-SNR算法降维得到的逐层迭代过程，如下图所示</p>
<p><img src="/assets/25ed37ebee7e744ab13025262110de2e.jpg" alt=""></p>
<p>可以看到，数据经过一层一层的迭代，最终能明显的分离开来，达到分类的效果，这与论文中的结论是一致的。</p>
<p>那么下面工作主要就是对上面提到的各类参数进行搜索并调整。首先是增大迭代次数和样本数据，通过对比能够看到数据训练的效果有明显的提升，效果如下图所示。从图中可以明显看出，提升了每个label的样本数量和迭代次数，效果与论文数据已经相当接近。</p>
<p><img src="/assets/808b05937d6f4b6003e7db04ceb1137f.png" alt=""></p>
<p>从上图中也可看出Input bond和Virtual<br>bond参数还可以进行修改优化来得到更好的结果，在实验中又出现了一些问题，例如下面的<strong>内存溢出问题</strong></p>
<p><img src="/assets/6300cf85a496cc70b4a87028d72d6d7d.png" alt=""></p>
<p><strong>这是因为机器所能表示的数据量是有限制的，而上面9*9*9*9*9*5400这些数据超过内存限制，经过尝试即使改成9*9*9*9*9*90还是会因为数据结构过于庞大而内存溢出，因此只能换机器或者通过降低样本数量来寻求这两类参数叠加的一个平衡点，或许有可能进一步提高算法准确率。</strong></p>
<p><strong>后续继续一方面通过服务器优化参数，另一方面学习FRQI的算法代码，FRQI算法结合了IBM的Qiskit库能够在量子线路上得以实现。若能将FRQI的表示方法推广到TTN，也许会有更低的复杂度、更高的准确率。</strong></p>
<h2 id="三、张量网络基础课程（Bilibili）"><a href="#三、张量网络基础课程（Bilibili）" class="headerlink" title="三、张量网络基础课程（Bilibili）"></a><strong>三、张量网络基础课程（Bilibili）</strong></h2><p>本周视频的学习有些疏忽，学习内容比较少。复习了TEBD和DMRG算法。还补充了一个通过<strong>自动微分</strong>方式计算能量的算法，学习了Uniform<br>MPS及其涨落、纠缠面积熵、MPO简述这些内容。</p>
<h3 id="3-1-Uniform-MPS及其涨落"><a href="#3-1-Uniform-MPS及其涨落" class="headerlink" title="3.1 Uniform MPS及其涨落"></a>3.1 Uniform MPS及其涨落</h3><p>这里定义了单张量平移不变MPS（又称均匀MPS,uniform MPS）：</p>
<p><img src="/assets/138f66fc085cfcb18fdfcc3884a23881.png" alt=""></p>
<p>该MPS中仅包含一个张量A，记为不等价张量，整个MPS由不等价张量的无穷多个复制收缩构成，因此不等价张量可以理解为该无穷长MPS的组成基本单元。可以简单的记为：</p>
<p><img src="/assets/d2b3a5e1fb36d08b863ddca532edb6ea.png" alt=""></p>
<p>这个定义也可以推广到<strong>多张量平移不变MPS，</strong>例如双张量平移不变的情况可以表示如下：</p>
<p><img src="/assets/399620b7a24682a3e9fb1a0cae1b2930.png" alt=""></p>
<p>用什么样的平移不变性，取决于对待解决物理问题的先验知识或猜测。例如铁磁的哈密顿量，由于自旋都是同一个方向，所以就对应着单张量的平移不变MPS。</p>
<ul>
<li><p>反应无穷大平移不变MPS性质最重要的是其转移矩阵及转移矩阵的本征向量</p>
</li>
<li><p>有限MPS的各个算法可以推广至无穷长MPS，例如无穷密度矩阵重整化群（iDMRG）算法、无穷TEBD算法（iTEBD）等。</p>
</li>
<li><p>无穷长平移不变矩阵乘积态又称均匀矩阵乘积态，这一类构成了量子Hibert空间中一类特殊的流形。</p>
<p>对于矩阵乘积态的涨落，先来看下面的关联函数：</p>
<p><img src="/assets/3ebfca060a7da2e28c0312fa0a18a0c0.png" alt=""></p>
</li>
</ul>
<p>通过一系列的化简运算，能够得到如下关系，即涨落随着D指数衰减</p>
<p><img src="/assets/8e09d0309af8571db1c052dbd977218b.png" alt=""></p>
<blockquote>
<p>  其中，为正的常数，被称为关联长度，统称可经下式计算</p>
</blockquote>
<p><img src="/assets/8109a32849d8394ad609c023c1648a99.png" alt=""></p>
<p>这里是次大本征值，当实MPS满足归一化条件时，其最大本征值为1，那么，所以为正。</p>
<h3 id="3-2-MPS与纠缠熵面积定律"><a href="#3-2-MPS与纠缠熵面积定律" class="headerlink" title="3.2 MPS与纠缠熵面积定律"></a>3.2 MPS与纠缠熵面积定律</h3><p>由于MPS的正交行书容易看出，其奇异谱的维数等于辅助指标的维数，同时由于MPS的归一化条件，有。</p>
<p>设奇异谱维数，当时，纠缠熵达到极大值，纠缠熵表达式为</p>
<p>因此，给定MPS辅助指标维数之后，其能容纳的纠缠上限为</p>
<p>详细证明过程如下图所示</p>
<p><img src="/assets/6aea947432391ad507a5562ffcb5fef9.jpg" alt=""></p>
<p>可见，在任意一处截断MPS进行二分之后，两部分之间的纠缠熵大小与各部分包含的格点个数无关，仅与边界处辅助指标的维数有关。</p>
<p>那么<strong>纠缠熵的面积定理</strong>就是：对于D维格点系统的量子态，将体系二分后，两部分之间的纠缠熵满足：</p>
<p><img src="/assets/c6023373e402bfd1eba2becd8cbb74b6.png" alt=""></p>
<p>，其中l表示空间尺度</p>
<p><img src="/assets/b2cf5f7f70e11ae6a49aba4e4308b5d9.png" alt=""></p>
]]></content>
      <categories>
        <category>周汇报</category>
      </categories>
      <tags>
        <tag>图片压缩</tag>
        <tag>TTN</tag>
      </tags>
  </entry>
  <entry>
    <title>生成个人相册</title>
    <url>/2020/08/20/32GenPerAlbum/</url>
    <content><![CDATA[<blockquote>
<p>本文章讲解如何利用cos桶+cosbrowser在服务器上构建自己的个人相册</p>
</blockquote>
<a id="more"></a>
<p>在这里梳理一下构建相册的基本思路</p>
<ol>
<li>直接将图片放到服务器上，通过<strong>相对路径</strong>或<strong>网络路径</strong>进行索引。这种方式操作起来不难，但是过程比较繁杂，一方面是图片链接需要一个个<strong>复制粘贴</strong>，另一方面大尺寸图片加载速度<strong>很慢</strong>。</li>
<li>将图片上传到图床上（可理解为一个自动生成图片链接的容器），这样一键能批量生成各种各样的图片链接，但是它们还是需要设计布局并通过src引用到页面上</li>
<li>图床+js脚本，自动读取存储路径下的图片进行页面部署（相当于有了个<a href="https://github.com/Lruihao/cos-album"><strong>模板</strong></a>），这个模板搭配着<strong>图床</strong>将事半功倍，如果你的图床还有CDN加速，那就能加快页面加载速度。</li>
</ol>
<p>本博客使用的是第三种方式，效果见<a href="http://182.92.108.27/album/">这里</a>。创建<strong>cos桶</strong>(用作图床)以及上传文件一般都没什么问题，要格外注意cos桶的权限，包含<strong>policy</strong>和<strong>跨域访问CORS设置</strong>这两部分内容的设置，能够通过网页正常访问<a href="https://album-1259511784.cos.ap-chongqing.myqcloud.com格式的域名之后，才能正常读取cos桶的图片系列。读取[cos桶]">https://album-1259511784.cos.ap-chongqing.myqcloud.com格式的域名之后，才能正常读取cos桶的图片系列。读取[cos桶]</a>(<a href="https://console.cloud.tencent.com/cos5">https://console.cloud.tencent.com/cos5</a>)图片并布局成为相册的内容见<a href="https://github.com/Lruihao/cos-album">这里</a></p>
<p>参考链接</p>
<ol>
<li><a href="https://me.idealli.com/post/73ad4183.html">给HEXO静态博客添加动态相册功能</a></li>
<li><a href="https://lruihao.cn/posts/cos-album.html">利用腾讯云为静态页面添加 “动态” 相册</a></li>
</ol>
]]></content>
      <categories>
        <category>网站建设</category>
      </categories>
      <tags>
        <tag>相册</tag>
      </tags>
  </entry>
  <entry>
    <title>研究生素养提升公益课</title>
    <url>/2020/08/16/31Study-Report(0810-0816)/</url>
    <content><![CDATA[<blockquote>
<p> 本周主要是观看学习了知网研学研究生素养提升课，以及学习层次树张量网络的英文论文（Liu_2019_New_J._Phys._21_073059）和代码。</p>
</blockquote>
<a id="more"></a>
<h2 id="一、研究生素养提升公益课"><a href="#一、研究生素养提升公益课" class="headerlink" title="一、研究生素养提升公益课"></a>一、研究生素养提升公益课</h2><p>此系列讲座持续了3天，各个学校的老师和教授们从研究生入学要求、到论文的写作、到研究生学习规划，全方位的扩展了我们的认知，记录了其中一些重点内容，总结如下</p>
<p><strong>北京印刷学院 魏超 学术训练和论文体裁</strong></p>
<p>魏老师从一个比较宽泛、基础性的概念讲解了研究生的培养目标、学习条件等等，以及一些与期刊相关的常识。下图是期刊的类型，我们研究生发表的大部分都是学术期刊，不同学校对发表文章有不同的毕业或答辩要求。</p>
<p><img src="/assets/5c2eb28d00589bc4cc66780729f5aeb0.png" alt=""></p>
<p><strong>清华大学 王媛教授 中外文数据库的使用</strong></p>
<p>王媛教授主要是通过一些例子，讲解了文献检索的过程和技巧，并带领我们全面认识学术信息资源。其中一些知识点如下</p>
<ul>
<li><p>利用信息创造新知识，合理参与学习社区</p>
</li>
<li><p>一个高信息素养的人避免以下行为</p>
</li>
</ul>
<ol>
<li><p>在课程论文中引用来自“百度百科”或“Wikipedia”的词条</p>
</li>
<li><p>把搜索引擎当做唯一的信息检索工具</p>
</li>
<li><p>对信息的生产者和发布者不加以区分</p>
</li>
</ol>
<ul>
<li><p>科技期刊Science、Nature、Cell</p>
</li>
<li><p>学术发现工具：FirstSearch/Worldcat</p>
</li>
</ul>
<p><img src="/assets/30f2b67002584b92b3bd4b8ff0b2ebd5.jpg" alt=""></p>
<p><strong>中国知网 徐铭梓 如何利用中国知网高效检索文献、阅读和写作</strong></p>
<p>在听这节课之前，我对知网的认知还仅限于查重和搜索。在完整的听完徐铭梓老师的细致讲解之后，才发现知网提供了如此多的功能。包括高级搜索、趋势图标、论文写作、论文发表等一系列的平台，很开阔我的视野。下面是知网研学的写作界面，右侧是摘录的笔记或参考文献，可以随时查看和引用。不知道学校是否开通了这个服务，如果能用可就太舒服了。</p>
<p><img src="/assets/c2a475dfbbe6735bc5e028e4325e3ab2.png" alt=""></p>
<p><strong>北京化工大学 张杰  论文写作技巧与投稿发表</strong></p>
<p>张杰老师讲解了科技论文构成要素及写作要点，并带领我们阅读了几篇论文，教我们如何去快速获取论文的核心观点和结论，以及阅读或写作时要注意的一些细节问题，下图是在投稿之前要注意到的一些技巧。</p>
<p><img src="/assets/3b8037cdcf04a4a842adf5aacfee3e83.png" alt=""></p>
<p>经过几天的学习，我收获了很多有用的知识，同时也非常感谢知网平台提供给我这样一个结课证书，希望能在以后将上面的知识应用到实践中去。</p>
<p><img src="/assets/003d860e20e8f15870553899f690235b.jpg" alt=""></p>
<p><strong>层次树结构酉张量网络的机器学习       </strong></p>
<p><img src="/assets/e35a58d3867ee8c1559ef037ff1dc992.png" alt=""></p>
<p>这篇英文论文涵盖了非常多的内容，并且附有代码。在读论文和读代码时遇到各种各样的问题，但是能够相互印证自行解决。论文中不明白的公式演化过程，都能在代码中得到明确的体现。在代码中看不懂的变量和参数，在论文中也有部分体现。总之，这套代码基于python库<a href="https://github.com/andrewdarmawan/tncontract">tncontract</a>来进行张量网络的缩并操作，重难点都已经写在PPT里了。数据集也已经修复，详细的内容见PPT和<br><a href="https://github.com/YuleZhang/Tree-Tensor-Networks-in-Machine-Learning"></a></p>
]]></content>
      <categories>
        <category>周汇报</category>
      </categories>
      <tags>
        <tag>综合素质</tag>
      </tags>
  </entry>
  <entry>
    <title>图片映射+TEBD+DMRG</title>
    <url>/2020/08/09/30Study-Report(0802-0809)/</url>
    <content><![CDATA[<blockquote>
<p>矩阵乘积态MPS表达多体系统基态</p>
</blockquote>
<a id="more"></a>
<p>TT分解的过程： 已知一个基态对应的高阶张量的样子，然后经过TT分解得到MPS态。<br>而MPS的关键在于，我们在不知道<strong>指数复杂的量子态系数是什么</strong>，也不需要TT分解，而是直接<strong>假设基态具有MPS的形式，直接处理MPS中的局域张量，</strong>从而绕过了指数墙的问题。</p>
<h3 id="MPS的形式可以进行变换"><a href="#MPS的形式可以进行变换" class="headerlink" title="MPS的形式可以进行变换"></a>MPS的形式可以进行变换</h3><p>同一个量子态可以用不同的tensor进行表达，这种变换称为<strong>规范变换</strong></p>
<p><img src="/assets/2df48437508948713ffb813501230b8b.png" alt=""></p>
<p><strong>如何验证不同的规范变换表示同一个量子态呢？</strong></p>
<p>答：将两者都变换成中心正交形式的MPS态，两者变换结果一致说明同一个量子态</p>
<h3 id="如何将图片映射为张量网络"><a href="#如何将图片映射为张量网络" class="headerlink" title="如何将图片映射为张量网络"></a>如何将图片映射为张量网络</h3><p>视频中使用的代码和示例都是采用的<strong>虚拟数据</strong>（无实际含义），通过<strong>裁减误差</strong>来刻画算法的性能。而将该算法实际运用到生活中时则涉及到很多的表示问题，我们对图片过去的印象是它是一个<strong>四阶张量，</strong>即（samples,<br>height, width,<br>channels），以此为输入可以完成很多的工作。可是当我们对单张图片进行张量网络优化时，就会出现表示难题。仍可以从图片各个指标的角度逐步将其拆解，组合成各种各样结构的网络。如下图</p>
<p><img src="./assets/ad43d1a92637073d925cf710f68b50d3.png" alt=""></p>
<p><img src="/assets/b52e0e04b41996b2f80efbd6341c76e5.png" alt=""></p>
<h3 id="TEBD算法："><a href="#TEBD算法：" class="headerlink" title="TEBD算法："></a>TEBD算法：</h3><p>对于一个W*H的张量网络，在规定求和的顺序后可以将它严格求出。当W或H比较大的时候，这个张量网络的复杂度就呈指数级别增长，传统计算机不能在有效时间内给出结果。而TEBD就是一种基于矩阵乘积态的、近似收缩张量网络的数值算法。</p>
<p>主要思路：从处于边界的张量构成的MPS开始，一行一行（或一列一列）地收缩张量网络。</p>
<p><img src="/assets/4df70ce5f5596569ebffc5edb23c92b5.png" alt=""></p>
<p><img src="/assets/6d3020c3b66f0a65b26f7a381fd2cbbe.png" alt=""></p>
<p>TEBD的计算方案并不唯一，它可以采用MPO的形式，逐层进行求和。也可以采用张量</p>
<p>TEBD算法计算基态的思路是退火，而密度矩阵重整化（DMRG）采取的是另一种思路：</p>
<p><strong>基于最大本征态求解对应的最优化问题，</strong>即求解如下<strong>极小化问题</strong></p>
<h3 id="DMRG算法"><a href="#DMRG算法" class="headerlink" title="DMRG算法"></a>DMRG算法</h3><p>DMRG的策略是<strong>更新各个张量，使能量达到极小</strong>，具体的更新策略不唯一。在单点（one-site）DMRG中，每次更新MPS中的一个张量，其余张量看成是给定的参数。单个张量的优化问题可以等价为局域矩阵的最大本征值问题。</p>
<p><img src="/assets/1e88c0c1114804d85411c8a82aac0a28.png" alt=""></p>
<p><img src="/assets/ce70bc9a0007fc1827b7bd40826c251d.png" alt=""></p>
<p><img src="/assets/10ef8e487ea1097d3d92ab7d54aa83f0.png" alt=""></p>
<p>有效哈密顿量h2的能量就能用如上的公式和张量网络图来表示。由于它采用的是（Alternating<br>Least Square,<br>ALS的方法），故需要反复的迭代更新A1，A2….各个张量，这个地方一般迭代50多次就可以收敛了，计算复杂度线性增加，不会出现指数爆炸问题。同时在计算过程中，可以通过移动正交中心简化计算。</p>
<p><img src="/assets/96e6b943dcdbf857cb383b269e341c43.png" alt=""></p>
<h3 id="张量网络态与深度学习的交融"><a href="#张量网络态与深度学习的交融" class="headerlink" title="张量网络态与深度学习的交融"></a>张量网络态与深度学习的交融</h3><p>深度学习在物理方面的应用：</p>
<ul>
<li><p>表示量子多体波函数：RBM</p>
</li>
<li><p>探测相位过渡</p>
</li>
<li><p>蒙特卡罗模拟加速：Self-learning</p>
</li>
<li><p>辅助材料的合成</p>
</li>
<li><p>张量网络的优化</p>
</li>
</ul>
<p>量子多体物理在DL中的应用</p>
<ul>
<li><p>发掘神经网络的新结构</p>
</li>
<li><p>生成模型新的表示方法</p>
</li>
<li><p>光学神经网络</p>
</li>
</ul>
<p>一般性的深度神经网络结构图如下所示，包含了<strong>输入层、多个隐藏层、输出层。</strong>中间通过各种各样的<strong>线性变换和非线性变换。
</strong>最终不断地训练参数，从而找到某个问题的最优近似解。这里有两个定理</p>
<ol>
<li><p>神经网络能够以任意精度逼近所求问题的解，也就是神经网络层数或者神经元个数可以无限延伸</p>
</li>
<li><p>没有免费午餐理论，虽然能够有很强的表示能力，但不一定能找到最优结构</p>
</li>
</ol>
<p><img src="/assets/5cb19173f8a2bdddc73f8e10dd315d1d.png" alt=""></p>
<p><strong>神经网络结构和张量网络的对应，请看下图，张量网络毫无压力的可以表示多层神经网络结构！</strong>通过对MPS态的进一步优化就可以实现对网络结构的优化，这种方式极大的减少了神经网络的<strong>权重参数</strong>。</p>
<p><img src="/assets/7378baf0b60c1e8445a0e7e38e15e22b.png" alt=""></p>
<p>同时作者通过大量的实验表示通过MPS结构进行的训练准确率与原神经网络结构基本一致，但是极大地减少了参数个数，优化了网络结构。</p>
<h3 id="算法代码实现"><a href="#算法代码实现" class="headerlink" title="算法代码实现"></a>算法代码实现</h3><p>本周实现了基于约化密度矩阵的K2DPCA算法处理图像数据，并且在原先水平方向等距约化的基础上增加了垂直方向的处理。</p>
<p>其中水平方向处理如下图所示</p>
<p><img src="/assets/79b69b753ae09e28ddbf1bf3a61efd3a.png" alt=""></p>
<p>垂直方向处理如下图所示</p>
<p><img src="/assets/49c06a504b39d94c5b1ea7f0fc3b4080.png" alt=""></p>
<p>综合水平与垂直方向的处理如下图所示</p>
<p><img src="/assets/da6583c32cf8c10e6cc136b6a1956265.png" alt=""></p>
<p>接下来的实现思路就是通过2-3次这样的矩阵约化，来降低图片的维数，最后通过张量平均的方式代入运算，降低误差。</p>
]]></content>
      <categories>
        <category>周汇报</category>
      </categories>
      <tags>
        <tag>图片压缩</tag>
        <tag>张量基础</tag>
      </tags>
  </entry>
  <entry>
    <title>考研总结</title>
    <url>/2020/06/05/29PGEE-Summary/</url>
    <content><![CDATA[<script src="/crypto-js.js"></script><script src="/mcommon.js"></script><h3 id="encrypt-message">Please enter the password to read the blog.</h3><link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap.min.css"> <link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap-theme.min.css"> <script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script> <script src="//cdn.bootcss.com/bootstrap/3.3.5/js/bootstrap.min.js"></script> <div id="security"> <div> <div class="input-group"> <input type="text" class="form-control" aria-label="Enter the password." id="pass"/> <div class="input-group-btn"> <button type="button" class="btn btn-default" onclick="decryptAES()">Decrypt</button> </div> </div> </div> </div> <div id="encrypt-blog" style="display:none"> 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 </div>]]></content>
      <categories>
        <category>转折点</category>
      </categories>
      <tags>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title>决策树</title>
    <url>/2020/04/03/27Decision-Tree/</url>
    <content><![CDATA[<blockquote>
<p>本文部分图片、材料来自于课程<a href="https://github.com/liuyubobobo/Play-with-Machine-Learning-Algorithms">Python3 入门机器学习</a> </p>
</blockquote>
<p>先来看一个招聘的例子，这就是一颗决策树，根据不同的问题进行一步步划分，最终将结果氛围录用和考察两类</p>
<a id="more"></a>
<p><img src="/assets/1585905261759.png" alt="1585905261759"></p>
<h3 id="决策树实例"><a href="#决策树实例" class="headerlink" title="决策树实例"></a>决策树实例</h3><p>采用sklearn的决策树算法包，见<a href="https://github.com/liuyubobobo/Play-with-Machine-Learning-Algorithms/blob/master/12-Decision-Tree/01-What-is-Decision-Tree/01-What-is-Decision-Tree.ipynb"><strong>What-is-Decision-Tree</strong></a></p>
<h3 id="决策树的特点"><a href="#决策树的特点" class="headerlink" title="决策树的特点"></a>决策树的特点</h3><ul>
<li><p>非参数学习方法</p>
</li>
<li><p>可以解决分类问题</p>
</li>
<li><p>天然可以解决多分类问题</p>
</li>
<li><p>也可以解决回归问题</p>
</li>
<li><p>具有非常好的可解释性</p>
</li>
</ul>
<h3 id="关键问题"><a href="#关键问题" class="headerlink" title="关键问题"></a>关键问题</h3><ul>
<li><p>每个节点在哪个维度做划分</p>
</li>
<li><p>某个维度在哪个值上做划分</p>
</li>
</ul>
<h3 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h3><p>熵在信息论中代表随机变量不确定度的度量</p>
<ul>
<li>熵越大，数据的不确定性越高</li>
<li><p>熵越小，数据的不确定性越低</p>
<p>$Entropy(S) = -\sum p_ilog(p_i)$</p>
</li>
</ul>
<p>二分类问题的信息熵效果图，当两个分类的p都为0.5时，信息熵最大，数据越不稳定</p>
<p><img src="/assets/1585912118170.png" alt="1585912118170"></p>
<h3 id="基尼系数"><a href="#基尼系数" class="headerlink" title="基尼系数"></a>基尼系数</h3><p>$G = 1 - \sum_{i=1}^{k}p^2_{i}$</p>
<p>同信息熵类似，G越大表示样本的不确定性越强，反之则表示样本的分类没有任何不确定，最小值为0</p>
<p>以二分类为例，其函数图像为开口向下的抛物线</p>
<blockquote>
<p>np.argsort()将np.array中的值从小到大进行排序，按照此顺序依次返回元素在元数组中的index</p>
<p>Counter参数为list，求出列表中值的出现次数</p>
</blockquote>
<h3 id="信息熵VS基尼系数"><a href="#信息熵VS基尼系数" class="headerlink" title="信息熵VS基尼系数"></a>信息熵VS基尼系数</h3><ul>
<li>信息熵的计算比基尼系数稍慢</li>
<li>scikit-learn包中默认参数为基尼系数</li>
<li>大多数时候二者没有特别的效果优劣</li>
</ul>
<h3 id="CART-Classification-And-Regression-Tree"><a href="#CART-Classification-And-Regression-Tree" class="headerlink" title="CART(Classification And Regression Tree)"></a>CART(Classification And Regression Tree)</h3><blockquote>
<p>scikit-learn的决策树实现：CART</p>
</blockquote>
<p><strong>复杂度</strong></p>
<ul>
<li>预测： $O(logm)$</li>
<li>训练： $O(n<em>m</em>logm)$</li>
<li>剪支： 降低复杂度，解决过拟合</li>
</ul>
<p><strong>超参数</strong></p>
<p>避免过拟合、欠拟合</p>
<ul>
<li>max_depth： 限制最大深度为2</li>
<li>min_samples_split： 至少要有多少个样本数据才继续拆分下去</li>
<li>min_samples_leaf： 对于叶子结点来说最少要有几个样本</li>
<li>max_leaf_nodes：最多有多少个叶子节点</li>
</ul>
<p>可以用网格搜素寻找合适的参数</p>
<h3 id="决策树解决回归问题"><a href="#决策树解决回归问题" class="headerlink" title="决策树解决回归问题"></a>决策树解决回归问题</h3><h3 id="决策树的局限性"><a href="#决策树的局限性" class="headerlink" title="决策树的局限性"></a>决策树的局限性</h3><ul>
<li>决策边界只能是横平竖直，不能倾斜</li>
<li>不能学习参数</li>
<li>对个别样本比较敏感，可能会很大影响决策树</li>
</ul>
<p>每天都汇报投了哪几个单位</p>
]]></content>
      <categories>
        <category>复试</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据挖掘</tag>
      </tags>
  </entry>
  <entry>
    <title>421总结</title>
    <url>/2020/04/03/28GraduateSummary/</url>
    <content><![CDATA[<script src="/crypto-js.js"></script><script src="/mcommon.js"></script><h3 id="encrypt-message">Please enter the password to read the blog.</h3><link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap.min.css"> <link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap-theme.min.css"> <script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script> <script src="//cdn.bootcss.com/bootstrap/3.3.5/js/bootstrap.min.js"></script> <div id="security"> <div> <div class="input-group"> <input type="text" class="form-control" aria-label="Enter the password." id="pass"/> <div class="input-group-btn"> <button type="button" class="btn btn-default" onclick="decryptAES()">Decrypt</button> </div> </div> </div> </div> <div id="encrypt-blog" style="display:none"> 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 </div>]]></content>
      <categories>
        <category>日志</category>
      </categories>
      <tags>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title>复试之C/C++系列问题</title>
    <url>/2020/04/02/26Pku-Interview-C/</url>
    <content><![CDATA[<h3 id="C-C-中为什么有引用"><a href="#C-C-中为什么有引用" class="headerlink" title="C/C++中为什么有引用"></a>C/C++中为什么有引用</h3><p>C++之所以增加引用类型, 主要是把它作为函数参数,以扩充函数传递数据的功能。</p>
<p>引用是一个常量指针占四个字节，编译器在编译时对引用作了更严格的限制，与普通指针相比更加安全。详细见<a href="https://www.cnblogs.com/ronny/p/3662556.html">C++的那些事：你真的了解引用吗</a></p>
<a id="more"></a>
<h3 id="指针和引用的区别"><a href="#指针和引用的区别" class="headerlink" title="指针和引用的区别"></a>指针和引用的区别</h3><p>（1）指针：指针是一个变量，只不过这个变量存储的是一个地址，指向内存的一个存储单元；而引用跟原来的变量实质上是同一个东西，只不过是原变量的一个别名而已。<br>（2）指针可以有多级，但是引用只能是一级（int **p；合法 而 int &amp;&amp;a是不合法的）<br>（3）指针的值可以为空，但是引用的值不能为NULL，并且引用在定义的时候必须初始化<br>（4）指针的值在初始化后可以改变，即指向其它的存储单元，而引用初始化后就不会再改变。<br>（5）”sizeof引用”得到的是所指向的变量(对象)的大小，而”sizeof指针”得到的是指针本身的大小。<br>（6）作为参数传递时，二者有本质不同：指针传参本质是值传递，被调函数的形参作为局部变量在栈中开辟内存以存放由主调函数放进来的实参值，从而形成实参的一个副本。而引用传递时，被调函数对形参的任何操作都会通过一个间接寻址的方式影响主调函数中的实参变量。</p>
<h3 id="指针数组、数组指针"><a href="#指针数组、数组指针" class="headerlink" title="指针数组、数组指针"></a>指针数组、数组指针</h3><p>（1）指针数组：首先它是一个数组，数组的元素都是指针，数组占多少个字节由数组本身的大小决定，每一个元素都是一个指针，在32 位系统下任何类型的指针永远是占4 个字节。它是“储存指针的数组”的简称。<br>（2）数组指针：首先它是一个指针，它指向一个数组。在32 位系统下任何类型的指针永远是占4 个字节，至于它指向的数组占多少字节，不知道，具体要看数组大小。它是“指向数组的指针”的简称。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span> *arr[<span class="number">4</span>] = &#123;<span class="string">&quot;hello&quot;</span>, <span class="string">&quot;world&quot;</span>, <span class="string">&quot;shannxi&quot;</span>, <span class="string">&quot;xian&quot;</span>&#125;; </span><br><span class="line"><span class="comment">//arr[4]是一个定义的数组。把它对应到对应到内存中，arr是一个在栈区,有四个元素的数组，而每一个元素又是一个指针，所以说它的四个元素各占四个字节，所以变量arr的大小是16个字节。arr+1会跳过四个字节。也就是一个指针的大小 。</span></span><br><span class="line"><span class="keyword">char</span> (*pa)[<span class="number">4</span>]; <span class="comment">//pa是一个指针指向一个char [4]的数组</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="C-内存布局"><a href="#C-内存布局" class="headerlink" title="C++内存布局"></a>C++内存布局</h3><p>（1）栈区（stack）：由编译器自动分配释放，存放函数的参数值，局部变量值等，其操作方法类似数据结构中的栈。<br>（2）堆区（heap）：一般由程序员分配释放，与数据结构中的堆毫无关系，分配方式类似于链表。<br>（3）全局/静态区（static）：全局变量和静态变量的存储是放在一起的，在程序编译时分配。<br>（4）文字常量区：存放常量字符串。<br>（5）程序代码区：存放函数体（类的成员函数、全局函数）的二进制代码</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> a=<span class="number">0</span>; <span class="comment">//全局初始化区</span></span><br><span class="line"><span class="keyword">char</span> *p1; <span class="comment">//全局未初始化区</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> b; <span class="comment">//栈</span></span><br><span class="line">    <span class="keyword">char</span> s[]=<span class="string">&quot;bb&quot;</span>; <span class="comment">//栈</span></span><br><span class="line">    <span class="keyword">char</span> *p2; <span class="comment">//栈</span></span><br><span class="line">    <span class="keyword">char</span> *p3=<span class="string">&quot;123&quot;</span>; <span class="comment">//其中，“123\0”常量区，p3在栈区</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> c=<span class="number">0</span>; <span class="comment">//全局区</span></span><br><span class="line">    p1=(<span class="keyword">char</span>*)<span class="built_in">malloc</span>(<span class="number">10</span>); <span class="comment">//10个字节区域在堆区</span></span><br><span class="line">    <span class="built_in">strcpy</span>(p1,<span class="string">&quot;123&quot;</span>); <span class="comment">//&quot;123\0&quot;在常量区，编译器 可能 会优化为和p3的指向同一块区域</span></span><br><span class="line">｝</span><br></pre></td></tr></table></figure>
<h3 id="C-C-内存分配有三种方式："><a href="#C-C-内存分配有三种方式：" class="headerlink" title="C/C++内存分配有三种方式："></a>C/C++内存分配有三种方式：</h3><p>（1）从静态存储区域分配。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量，static变量。<br>（2）在栈上创建。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。<br>（3）从堆上分配，亦称动态内存分配。程序在运行的时候用malloc或new申请任意多少的内存，程序员自己负责在何时用free或delete释放内存。<br>动态内存的生存期由程序员决定，使用非常灵活，但如果在堆上分配了空间，就有责任回收它，否则运行的程序会出现内存泄漏。另外频繁地分配和释放不同大小的堆空间将会产生堆内碎块。</p>
<h3 id="malloc-free-、new-delete区别"><a href="#malloc-free-、new-delete区别" class="headerlink" title="malloc/free 、new/delete区别"></a>malloc/free 、new/delete区别</h3><p>（1）malloc与free是C++/C语言的标准库函数，new/delete是C++的运算符。它们都可用于申请动态内存和释放内存。<br>（2）对于非内部数据类型的对象而言，光用malloc/free无法满足动态对象的要求。对象在创建的同时要自动执行构造函数，对象在消亡之前要自动执行析构函数。由于malloc/free是库函数而不是运算符，不在编译器控制权限之内，不能够把执行构造函数和析构函数的任务强加于malloc/free。因此C++语言需要一个能完成动态内存分配和初始化工作的运算符new，以一个能完成清理与释放内存工作的运算符delete。注意new/delete不是库函数。<br>（3）C++程序经常要调用C函数，而C程序只能用malloc/free管理动态内存。<br>（4）new可以认为是malloc加构造函数的执行。new出来的指针是直接带类型信息的。而malloc返回的都是void指针。</p>
<h3 id="字节对齐问题"><a href="#字节对齐问题" class="headerlink" title="字节对齐问题"></a>字节对齐问题</h3><p>字节对齐是C/C++编译器的一种技术手段，主要是在可接受空间浪费的前提下，尽可能地提高对相同元素过程的快速处理（比如32位系统，4字节对齐能使CPU访问速度提高）</p>
<p>字节对齐的原则</p>
<p>（1）结构体中每个成员相对于结构体首地址的偏移量都是成员大小的整数倍，如有需要编译器会填充字节</p>
<p>（2）结构体的总大小为结构体最宽基本类型成员大小的整数倍，如有需要，编译器会填充字节。</p>
<h3 id="内联函数有什么优点？内联函数和宏定义的区别"><a href="#内联函数有什么优点？内联函数和宏定义的区别" class="headerlink" title="内联函数有什么优点？内联函数和宏定义的区别"></a>内联函数有什么优点？内联函数和宏定义的区别</h3><p><strong>优点：</strong></p>
<p>函数会在它所调用的位置上展开。这么做可以消除函数调用和返回所带来的开销（寄存器存储和恢复），而且，由于编译器会把调用函数的代码和函数本身放在一起优化，所以也有进一步优化代码的可能。<br>内联函数使用的场合：对于简短的函数并且调用次数比较多的情况，适合使用内联函数。</p>
<p>内联函数和宏定义区别：</p>
<p>1)<strong>内联函数在编译时展开，而宏在预编译时展开</strong><br>2)在编译的时候，内联函数直接被嵌入到目标代码中去，而宏只是一个简单的文本替换。<br>3)内联函数可以进行诸如类型安全检查、语句是否正确等编译功能，宏不具有这样的功能。<br>4)宏不是函数，而inline是函数</p>
<p><strong>以下情况不宜使用内联：</strong></p>
<p>（1）如果函数体内的代码比较长，使用内联将导致内存消耗代价较高。</p>
<p>（2）如果函数体内出现循环，那么执行函数体内代码的时间要比函数调用的开销大。</p>
<h3 id="覆盖、重载、隐藏的区别"><a href="#覆盖、重载、隐藏的区别" class="headerlink" title="覆盖、重载、隐藏的区别"></a>覆盖、重载、隐藏的区别</h3><p>（1）重载：重载翻译自overload，是指同一可访问区内被声明的几个具有不同参数列表（参数的类型，个数，顺序不同）的同名函数，根据参数列表确定调用哪个函数，重载不关心函数返回类型。<br>（2）覆盖：重写翻译自override，是指派生类中存在重新定义的函数。其函数名，参数列表，返回值类型，所有都必须同基类中被重写的函数一致，只有函数体不同。</p>
<p>（3）重定义(隐藏)是指派生类的函数屏蔽了与其同名的基类函数，规则如下：</p>
<ul>
<li>如果派生类的函数和基类的函数同名，但是参数不同，此时不管有无virtual，基类的函数被隐藏；</li>
<li>如果派生类的函数与基类的函数同名，并且参数也相同，但是基类函数没有virtual关键字，此时基类函数被隐藏。</li>
</ul>
<h3 id="虚函数有什么作用？"><a href="#虚函数有什么作用？" class="headerlink" title="虚函数有什么作用？"></a>虚函数有什么作用？</h3><p>（1）虚函数的功能是使子类可以用同名的函数对父类函数进行覆盖，并且在通过父类指针调用时，如果有覆盖则自动调用子类覆盖函数，如果没有覆盖则调用父类中的函数，从而实现<strong>灵活扩展和多态性</strong>；</p>
<p>（2）如果是纯虚函数，则纯粹是为了在子类覆盖时有个统一的命名而已，子类必须覆盖纯虚函数，则否子类也是抽象类；</p>
<p>（3）含有纯虚函数的类称为抽象类，不能实例化对象，主要用作接口类。</p>
<p>更详细的讲解见<a href="https://blog.csdn.net/haoel/article/details/1948051">C++虚函数表解析</a></p>
<h3 id="虚析构函数有什么作用？"><a href="#虚析构函数有什么作用？" class="headerlink" title="虚析构函数有什么作用？"></a>虚析构函数有什么作用？</h3><p>（1）析构函数的工作方式是：最底层的派生类的析构函数最先被调用，然后调用每一个基类的析构函数；</p>
<p>（2）在C++中，当一个派生类对象通过使用一个基类指针删除，而这个基类有一个非虚的析构函数，则可能导致运行时派生类不能被销毁。然而基类部分很有可能已经被销毁，这就导致“部分析构”现象，造成内存泄漏；</p>
<p>（3）给基类一个虚析构函数，删除一个派生类对象的时候就将销毁整个对象，包括父类和全部的派生类部分。</p>
<h3 id="构造函数与析构函数的异同点"><a href="#构造函数与析构函数的异同点" class="headerlink" title="构造函数与析构函数的异同点"></a>构造函数与析构函数的异同点</h3><h4 id="构造函数特点"><a href="#构造函数特点" class="headerlink" title="构造函数特点"></a>构造函数特点</h4><p>（1）构造函数的名字必须与类名相同；</p>
<p>（2）构造函数<strong>可以有任意类型的参数，但不能有返回类型</strong>；</p>
<p>（3）定义对象时，编译系统会自动调用构造函数；</p>
<p>（4）构造函数是<strong>特殊的成员函数</strong>，函数体可以在类体内也可以在类体外；</p>
<p>（5）构造函数被声明为公有函数，但它不能像其他成员函数那样被显式调用，它是在定义对象的同时被调用的。</p>
<h4 id="析构函数特点"><a href="#析构函数特点" class="headerlink" title="析构函数特点"></a>析构函数特点</h4><p>（1）析构函数的名字必须与类名相同，但它<strong>前面必须加一个波浪号</strong>；</p>
<p>（2）析构函数没有参数，也没有返回值，而且不能被重载，因此<strong>在一个类中只能有一个析构函数</strong>；</p>
<p>（3）当撤销对象时，编译系统会自动调用析构函数；</p>
<p>（4）析构函数<strong>可以是virtual</strong>，而<strong>构造函数不能是虚函数</strong>。</p>
<h3 id="成员函数和友元函数的区别"><a href="#成员函数和友元函数的区别" class="headerlink" title="成员函数和友元函数的区别"></a>成员函数和友元函数的区别</h3><p>相同点：</p>
<ol>
<li>对类的存取方式相同，可以直接存取类的任何存取控制属性的成员</li>
<li>可以通过对象存取形参、函数体中该类类型对象的所有成员</li>
</ol>
<p>不同点：</p>
<ol>
<li>成员函数有this指针，而友元函数没有</li>
<li>友元函数不能被继承</li>
</ol>
<h3 id="vector迭代器的几种失效的情况"><a href="#vector迭代器的几种失效的情况" class="headerlink" title="vector迭代器的几种失效的情况"></a><strong>vector迭代器的几种失效的情况</strong></h3><p>1.当插入（push_back）一个元素后，end操作返回的迭代器肯定失效。</p>
<p>2.当插入(push_back)一个元素后，capacity返回值与没有插入元素之前相比有改变，则需要重新加载整个容器，此时first和end操 作返回的迭代器都会失效。</p>
<p>3.当进行删除操作（erase，pop_back）后，指向删除点的迭代器全部失效；指向删除点后面的元素的迭代器也将全部失效。</p>
<h3 id="有哪些东西是编译期间确定的，哪些是运行期间确定的？"><a href="#有哪些东西是编译期间确定的，哪些是运行期间确定的？" class="headerlink" title="有哪些东西是编译期间确定的，哪些是运行期间确定的？"></a>有哪些东西是编译期间确定的，哪些是运行期间确定的？</h3><p>考察编译和运行的了解。编译期间确定数组大小空间，宏定义，内联函数展开，extern变量等。运行期间确定new大小，多态类对象的函数调用，未赋值全局指针的指向等。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://blog.csdn.net/hsq1596753614/article/details/80249605">C/C++ 经典面试题总结</a></p>
]]></content>
      <categories>
        <category>复试</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title>澳洲之行</title>
    <url>/2020/03/31/25Australia-Trip/</url>
    <content><![CDATA[<p><img src="/images/Australia.jpg" alt="cover"><br><a id="more"></a></p>
<p>距离开澳洲已经两个多月了，由于最近要交材料、做总结，才让我想起来还没有给这趟旅途画上一个完美的句号，让我沿着日志集再回忆一下</p>
<p>那是我第一次坐飞机，惊叹于那狭小的座椅提供给我丰富的功能，也是第一次感受飞机上升、下坠的不适感，让我难以忘怀。到了悉尼，还没下飞机就感受到那扑面而来的热风，果然跟书上写的一样，南半球的1月是夏天，我好奇的打量着周围的一切，看到了与我们国内相反的驾驶员位置、靠左行驶、过马路拍按钮等各种新鲜事。</p>
<p>第一周的生活是围绕<strong>International house</strong>和<strong>卧龙岗大学</strong>展开的，我们每天在Internation house吃饭(一天两顿)，到卧龙岗大学听课+参观。吃了将近一周的三明治，最后大家闻面包色变哈哈，并且那的菜经常是土豆和烤肉，偶尔还会有Spaghetti，没有筷子，都是刀叉，每天有水果有热饮，总的来说不算太糟糕(佩服常住的国人)。</p>
<p>至于听课内容，我觉得主要是在锻炼我们的听力和口语，内容不是很复杂，浅显易懂，还是挺适合我们的，Helen老师亲切友善，给个赞！另外我在交流学习的过程中，也感受到国外的课堂氛围，很轻松，老师同学互动频繁。同时也认识到了自己的局限与不足，从Belinda博士那里了解到我们<strong>不应该局限于工作本身</strong>，而是经常思考<strong>我们未来从事的工作如何能贡献世界</strong>。周五进行了Presentation，感觉很糟糕，虽然做了长时间，但稿子还是不熟练，磕磕绊绊，场面十分尴尬，不过Helen老师还是给了每个人不错的成绩，我意识到是我把成绩看的太重要了，而一定程度上忽略了在准备过程中的提升。</p>
<p><img src="/assets/1585663552586.png" alt="1585663552586"></p>
<p>每个人都获得了一份结业证书，如图</p>
<p>在周六日我们坐了轮渡，去了动物园，目睹了可爱的考拉和袋鼠的风采</p>
<p><img src="/assets/1585664083920.png" alt="1585664083920"></p>
<p>后来又去逛商场，看着一件件衣服也没标多少，可想想1：5的汇率就谨慎了很多哈哈，期间我疯狂的想办法冲上去跟店员chat，迫切的想提高自己的英语口语水平，事实情况就是问了一句之后，就疯狂点头然后撤(因为听不懂回了)，因为这个闹了不少笑话。</p>
<p>在整个旅途中，我不得不吐槽澳洲的饭店，多倒是挺多的，就是去哪都得用手抓(筷子、勺子、刀叉啥都没有)，而且坐的地方还很少，还得想尽办法给店员指想要的东西，那段时间我天天练英语口语来安慰自己。</p>
<p>第二周就丰富多了，先是住进了豪华总统套房，超大的客厅、超全的配置，简直是VIP的体验。</p>
<p><img src="assets/Australia_Room.jpg" alt=""></p>
<p>期间，我们参观了悉尼大学，看到了哈利波特取景的那栋大楼，真的是非常美了，参观了悉尼大学的图书馆、博物馆，看到了很多新颖的设计以及一些珍贵的文物。</p>
<p><img src="assets/Australia_Sydney.jpg" alt=""></p>
<p>此行是Elieen Zhang 老师给我们做介绍，她是悉尼大学的毕业生，在参观即将结束时，Elieen老师针对我们当前即将毕业的困惑谈了谈自己的经历和看法，真的是收益匪浅。</p>
<p>后来，我们又有幸见到了各行各业的大佬(包括owen老师)，他们讲述了自己创业的经历，有中国人也有外国人，让我或者说我们印象最深刻的还是Iron Fish的终极boss周华先生，他能给我们做演讲是大家都没有意料到的，他是俞敏洪的同窗室友，早些年放弃了翻译官的岗位来到澳洲从零开始，从小职员做起，一步一步创建了建立了自己的事业。</p>
<p>他简单给我们讲述了他的传奇经历，告诫我们人所赚到的钱和他给社会所带来的便利和服务是成正比的，我总结了出了以下几点</p>
<ul>
<li>有高的目标</li>
<li>思想开放，积极听取别人的意见，博采众长</li>
<li>做自己喜欢做的、擅长做的，做的事情要对别人有价值、对社会有价值</li>
</ul>
<p>多向优秀的人靠拢，他们对你的影响远远大于你的工资收入。</p>
<p>学校只是一个好的起点，不要盲目追求学历，学的越多越会分析事情为什么不可能发生，限制自己的想象。不要那么焦躁，把该学的东西学好了，在各个领域都会起到作用。还有就是<strong>要多看新闻、政治热点、要兴趣广泛，多谈别人感兴趣的，做一个专心的listener。不管做什么，即使是自己不喜欢的，但也一定把它做好，因为这些都是暂时的，这是一个好的习惯</strong>。选择比努力重要，走的越远偏离的方向越远，小刀磨得再锋利也不实用，要善于把握机遇。</p>
<p>一句座右铭送给大家<strong>有事做，有人爱，有所期待！</strong></p>
<p><img src="/assets/Australia_Speech.jpg" alt=""></p>
<p>在此次交流学习的最后，我们每个人进行了汇报，分享了此次交流学习的感想，认真的进行了自我反思，大家都有一定程度的提高，我也成长了不少，感谢李老师、owen老师和小姐姐一路上的照顾，感谢企业大亨们的分享，感谢学校精心的安排，相信我能走的更远！</p>
]]></content>
      <categories>
        <category>日志</category>
      </categories>
      <tags>
        <tag>旅行</tag>
      </tags>
  </entry>
  <entry>
    <title>数据挖掘学习笔记</title>
    <url>/2020/02/15/24DataMining/</url>
    <content><![CDATA[<p><img src="/images/data-mining.jpg" alt="cover"><br><a id="more"></a></p>
<blockquote>
<p>记笔记的方式，先听课程，然后回忆复述课程里的重要知识点及相关概念，将其写到笔记上，随后看PPT核对</p>
<p>通过这三轮的反复强化一定可以把知识学牢！</p>
</blockquote>
<p>数据挖掘在高校内没有对应的课程或者方向，它是一个融合了数学、统计学、计算机、以及各领域知识的综/合性方向，它涵盖范围很广，遍及互联网的各个角落。它能够实现”数据-&gt;信息-&gt;知识-&gt;决策支持“的转变。</p>
<h2 id="走进数据科学"><a href="#走进数据科学" class="headerlink" title="走进数据科学"></a>走进数据科学</h2><p>相关资料<a href="/download/Introduction.pptx">点击下载</a> </p>
<p><img src="/assets/1581220990738.png" alt="1581220990738"></p>
<h3 id="大数据的三个特征"><a href="#大数据的三个特征" class="headerlink" title="大数据的三个特征"></a>大数据的三个特征</h3><ul>
<li>高容量：从TB到ZB</li>
<li>多样性：从结构化数据到结构与非结构数据的混合</li>
<li>高速度：从批处理到如今的实时流数据处理</li>
</ul>
<h3 id="应用领域"><a href="#应用领域" class="headerlink" title="应用领域"></a>应用领域</h3><ul>
<li>公共安全：美国各地区犯罪预测</li>
<li>健康医疗：根部人不同的DNA开出个性化药方</li>
<li>城市规划：哪些地方是人口密集区、交通、市场如何部署</li>
<li>零售行业：针对性广告投放</li>
<li>运动：美国小棒球社如何挑选潜力球员</li>
</ul>
<h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><ul>
<li>交叉验证：将数据分为训练集和测试集</li>
<li>混淆矩阵：分为TP(True Positive)、FP(False Positive)、FT和TN，用来评估模型准确率</li>
<li>ROC曲线：AUC是ROC曲线与x轴围成的面积，用来评估模型的准确率</li>
</ul>
<p><img src="/assets/1581221686688.png" alt="1581221686688"></p>
<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>缺失值处理—–&gt;重复值处理—–&gt;类型转换与采样—–&gt;数据描述与可视化</p>
<h3 id="异常值与重复值检测"><a href="#异常值与重复值检测" class="headerlink" title="异常值与重复值检测"></a>异常值与重复值检测</h3><p>数据缺失的原因</p>
<ul>
<li>设备故障</li>
<li>隐私数据没有提供</li>
<li>数据不适用</li>
</ul>
<p>数据缺失的种类</p>
<ul>
<li>完全随机的缺失</li>
<li>跟属性相关的缺失</li>
<li>不是随机的缺失</li>
</ul>
<p><strong>离群点（Outliers）</strong>：跟整体数据差异比较大</p>
<p><strong>异常点（Anomaly）</strong>：数据由于某种特定的原因导致异常</p>
<p><strong>LOF（Local Outlier Factor）</strong>：离群点检测算法</p>
<p>当一个点距离周围的点越近$lrd$的值就会越大，$lrd$的分母相当于平均距离。</p>
<p><img src="/assets/1582771321867.png" alt="1582771321867"></p>
<p>LOF的值表示的是相对距离的概念，当$lrd(B)$远大于$lrd(A)$就说明A的近邻B到它附近的点的距离远小于A到它近邻的距离，那么就是表明A是一个离群点了。LOF值越大表明是离群点可能越大</p>
<p><strong>重复数据（Duplicate Data）</strong>：不同统计方式的列名不同、统计方式不同、存储方式也可能不同，但是统计的都是同类数据，解决方法是先排序(需要根据背景知识用key排序)再用滑动窗口进行比较去重。</p>
<h3 id="类型转换与采样"><a href="#类型转换与采样" class="headerlink" title="类型转换与采样"></a>类型转换与采样</h3><p>对于某个属性的不同类别，不能采用简单的012的方式进行编码，因为这改变了不同属性之间的距离，从而可能改变问题复杂度。例子如下</p>
<p><img src="/assets/1582773085533.png" alt="1582773085533"></p>
<p>仅仅是将绿色和蓝色交换了位置，分界线就从两条曲线变成了两条直线，问题求解的方式就发生了改变。</p>
<p>因此在处理这些数据时，往往采用one-hot独热编码，解决了分类器不好处理属性数据的问题，让特征之间的距离计算更加合理</p>
<p><strong>One-Hot和word2vec</strong></p>
<p>One-Hot</p>
<ul>
<li>优点：一是解决了分类器不好处理离散数据的问题，二是在一定程度上也起到了扩充特征的作用</li>
<li>缺点：在文本特征表示上有些缺点就非常突出了。首先，它是一个词袋模型，不考虑词与词之间的顺序（文本中词的顺序信息也是很重要的）；其次，它假设词与词相互独立（在大多数情况下，词与词是相互影响的）；最后，它得到的特征是离散稀疏的</li>
</ul>
<p>word2vec</p>
<p><strong>采样的原因：</strong>1.数据量非常大计算机处理不过来   2.没有办法得到完整的用户数据</p>
<p>采样的优点：能够用于调整类别比例，例如理工科男女比例，如果采用完整数据集，则明显男生比例很高，不利于模型处理</p>
<p><strong>不平衡数据：</strong>不同类别的样本数相差较大，尽管分类器A的准确率高，但是其误判了很重要的5%的数据，并不合理</p>
<p><img src="/assets/1582773995499.png" alt="1582773995499"></p>
<p>解决办法</p>
<ul>
<li>扩充数据集</li>
<li>对数据集进行重采样，包括过采样和欠采样</li>
<li>改变分类算法</li>
<li>改变评价指标，如PR曲线</li>
</ul>
<p>在实际中可以采用除了Acc以外的其它的度量方式如G-mean、F-measure、Recall等等</p>
<p><strong>边缘采样</strong>：对于几百万的数据，其中有很多数据都是作用不大的，提取其中的边缘点进行计算更有价值，能够节约计算资源</p>
<h3 id="数据描述与可视化"><a href="#数据描述与可视化" class="headerlink" title="数据描述与可视化"></a>数据描述与可视化</h3><p>Norlization：Min-max norlization、Z-score</p>
<p><strong>数据描述</strong>：平均值、中位数、变化程序</p>
<p><strong>数据可视化</strong>：一维数据直方图、二位数据坐标系、三维数据三维坐标系、高维数据Parallel<br>Coordinates </p>
<h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><p>从多个属性中，找出与问题有一定关联性的属性。</p>
<p><strong>信息增益</strong></p>
<p>怎么评价属性好不好？</p>
<p>答：查看该属性对结果的区分度，用熵Entropy衡量</p>
<p>信息增益ID3（Information gain）越大属性越好，表示它的跟结果越有关联，通常应用在决策树中</p>
<p><strong>特征子集搜索</strong></p>
<p><img src="/assets/1585473917480.png" alt="1585473917480"></p>
<p><strong>优化算法</strong></p>
<ul>
<li>模拟退火</li>
<li>禁忌搜索</li>
<li>遗传算法</li>
</ul>
<h3 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h3><p><strong>特征选择和特征提取的区别</strong></p>
<p><strong>特征提取</strong>的方法主要是通过属性间的关系，如<strong>组合</strong>不同的属性<strong>得到</strong>新的属性，这样就<strong>改变</strong>了原来的特征空间。<br><strong>特征选择</strong>的方法是从原始特征数据集中<strong>选择</strong>出子集，是一种<strong>包含</strong>的关系，<strong>没有</strong>更改原始的特征空间。</p>
<p><strong>PCA（Principal Component Analysis）</strong></p>
<p>无监督学习，不考虑label，将高维数据降维，将其投影到可以分类的方向上（可以通过坐标旋转），数据在该方向上分布越分散越好</p>
<p>将样本点到投影线的距离表示成$J(\theta)$，$J(\theta)$越小表明从高维投影到低维损失的信息越少</p>
<p>因此对$J(\theta)$使用拉格朗日乘数法，最后发现要最大化的值就是特征值</p>
<p>描述：将数据的协方差矩阵（covariance matrix）进行特征分解，找到特征值最大的特征向量上，投影到该方向上即可在满足最少损失的条件下，将数据降维到n-1、n-2、…、2、1维</p>
<p><strong>LDA（Linear Discriminant Analysis）</strong></p>
<p>针对有标签数据，基本思路也是降维，但是要保留的是类的区分属性。LDA在投影时的思想类似于PCA，都是进行坐标旋转，并使得目标函数最大</p>
<p>目标：令$J$最大化</p>
<p><img src="/assets/1582795035267.png" alt="1582795035267"></p>
<p><strong>LDA和PCA例子</strong></p>
<p><img src="/assets/1582795709134.png" alt="1582795709134"></p>
<p><strong>LDA的缺点</strong></p>
<ul>
<li>$S_w$可能是奇异矩阵，即行数不等于列数时，逆矩阵不存在</li>
<li>当不同类的中心点重合时，目标函数$J(\theta)$为0，不work</li>
</ul>
<h2 id="从贝叶斯到决策树"><a href="#从贝叶斯到决策树" class="headerlink" title="从贝叶斯到决策树"></a>从贝叶斯到决策树</h2><p><a href="NB-DT.pptx">课件下载</a></p>
<h3 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h3><p>一种从数据推测函数的技术，输入是一系列的特征，输出是一个bool值(二分类)或者整数(多分类)</p>
<h3 id="贝叶斯分类-Naive-Bayes-Classifier"><a href="#贝叶斯分类-Naive-Bayes-Classifier" class="headerlink" title="贝叶斯分类(Naive Bayes Classifier)"></a>贝叶斯分类(Naive Bayes Classifier)</h3><p>一些贝叶斯应用实例</p>
<p><strong>癌症</strong>：人群中检测出得癌症的概率是千分之八，人们往往容易产生恐慌</p>
<p>而从贝叶斯的角度分析，在得癌症的人群中假阳性的概率远大于真正癌症阳性的概率</p>
<p>这意味着即使体检报告上说得了癌症阳性，但其实上只有百分之20的概率是阳性。</p>
<p><strong>头疼和流感</strong>：不同的先验概率得到的结果不同</p>
<p>$H=$“Having a headache”           $F=$“Coming down with flu”</p>
<p>设$P(H)=1/10;  P(F)=1/40;   P(H|F)=1/2$，这意味着患流感人中有50%会头疼，这听起来不可思议。</p>
<p>但从另一个角度来看头疼的人中只有$1/8$的人患了流感，而现实人们往往将其混为一谈，误以为头疼有50%是得了流感</p>
<p><strong>贝叶斯公式</strong></p>
<p>​                            $  P(A|B)=\frac{P(B|A)P(A)}{P(B)} $</p>
<p><strong>朴素贝叶斯</strong></p>
<p>在贝叶斯公式基础上assumpt各个事件是<strong>条件独立</strong>的</p>
<p>​                             $ P (A,B|G) = P(A|G)P(B|G)          \leftrightarrows                       P(A|G,B) = P(A|G)$ </p>
<p>在实际中的例子</p>
<p>$P(Cancer│Male,Smoking)=P(Cancer|Smoking)$</p>
<p>即抽烟男性得肺癌得概率等于抽烟者得肺癌的概率，跟性别无关</p>
<p><strong>肺癌</strong></p>
<p><strong>应用领域</strong></p>
<p>文本分类，提取文本中的关键词，作为分类属性，使用贝叶斯分类器计算不同用户感兴趣的类别</p>
<p>在提取文本关键词时，并不是将文本简单分成词，随后将每一组词都参与运算，这样计算量很大并且效果也不明显，可以提取文章中出现最多的词语来为文章分类标签，那么就只需要统计每个词的频率，简化了公式，也就能够构建词袋模型，每个用户都会有自己的词袋，里面装满了用户的阅读喜好</p>
<p><img src="/assets/1581422114618.png" alt="1581422114618"></p>
<h3 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h3><p>决策树的优点是<strong>可解释性好</strong>，侯选属性在决策树中可以使用多次</p>
<p>决策树中建树的基本规则：信息增益大的属性应放在上层</p>
<p>当<strong>当前数据子集的标签一致</strong>、<strong>没有更多可用属性</strong>以及<strong>当前数据子集为空</strong>时必须停止树的增长</p>
<p>决策树剪支从<strong>叶节点</strong>开始</p>
<p>一些基本概念：</p>
<ul>
<li><p>熵(Entropy)：最大值是1，熵越大表示越难分类，即分类更倾向于靠猜</p>
<p>​                     $Entropy(S) = -\sum p_ilog(p_i)$</p>
</li>
<li><p>信息增益(Information Gain)：表示经过分类后对熵的优化程度，值越大表示效果越好，每次选取信息增益最大的分类属性作为根节点，以此类推。但当Information Gain接近于1时表明该属性将每个样本都分成一个类别，容易出现过拟合。</p>
<p>​                    $Gain(S,A)=Entropy(S)-\sum\frac{\vline S_V\vline}{\vline S\vline}Entropy(S_v)$</p>
</li>
<li><p>奥卡姆的剃刀：如无必要，勿增实体，常用于两种或两种以上假说的取舍上，如果对于同一现象有两种或多种不同的假说，我们应该采取比较简单或可证伪的那一种，世界客观存在即是建立在客观实践之上，正所谓<strong>实践是检验真理的唯一标准</strong></p>
</li>
<li><p>过拟合：训练集效果好，可是测试集效果差</p>
</li>
</ul>
<p><strong>ID3决策树</strong></p>
<p>ID3是比较早期的一种决策树算法，分别对样本的所有属性计算信息增益， 找出信息增益最大的属性作为结点，并将该属性从候选属性中去除，以此类推最终得到一颗决策树。</p>
<p>但是ID3的缺点也比较明显，当Information Gain每次都接近于1时，很容易造成过拟合，即某个属性将单个样本分到一个个叶节点，这对新来的样本不能进行有效的预测。因此人们在此基础上进行了改进，出现了C4.5</p>
<p><strong>C4.5决策树</strong></p>
<p>C4.5算法不直接使用信息增益作为划分样本的主要依据，而是提出了另外一个概念————增益率，它在信息增益的基础上加入了惩罚项Penalized</p>
<p>$Gainratio(D,a) = \frac{Gain(D,a)}{IV(a)}$</p>
<p>$IV(A)=-\sum_{v=1}^V\frac{\vline D^v\vline}{\vline D\vline}log_2\frac{\vline D^v\vline}{\vline D\vline}$</p>
<p>但是同样的这个增益率对可取值数目较少的属性有所偏好，因此C4.5决策树先从候选划分属性中找出信息增益高于平均水平的属性，在从中选择增益率最高的。</p>
<p><strong>CART决策树</strong></p>
<p>CART决策树的全称为Classification and Regression Tree,可以应用于分类和回归。采用基尼系数来划分属性</p>
<p>基尼值</p>
<p>$Gini(D)=\sum_{k=1}^{\vline y\vline}\sum_{k’}p_kp_{k’}=1-\sum_{k=1}^{\vline y\vline}p_k^2$</p>
<p>基尼系数</p>
<p>$GiniIndex (D,a)=\sum_{v=1}^{V}\frac{\vline D^v\vline}{\vline D\vline}Gini(D^v)$</p>
<p>因此在候选属性中选择基尼系数最小的属性作为最优划分属性。</p>
<p><strong>剪支</strong></p>
<p>树不能太复杂了，会过学习，当然也不能太简单了，否则不足以描述数据的分布</p>
<p>决策树数据集三个部分：训练集、训练集、验证集(validation set)</p>
<p>剪一点看一点盯着验证集的误差，在拐点的地方收手，不能再减了</p>
<p><strong>连续型属性（Continuous Attributes）</strong></p>
<p>取阈值进行离散化，阈值一般都出现在结果发生变化的地方</p>
<p>如何取阈值，还要用信息增益评估</p>
<p>扩展阅读<a href="https://blog.csdn.net/jiaoyangwm/article/details/79525237">https://blog.csdn.net/jiaoyangwm/article/details/79525237</a></p>
<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a><strong>神经</strong>网络</h2><p><a href="39.106.111.188/download/Neural_Networks.pptx">课件下载</a></p>
<h3 id="感知机"><a href="#感知机" class="headerlink" title="感知机"></a>感知机</h3><p>无法解决线性不可分问题</p>
<p><strong>梯度下降（Gradient Descent）</strong></p>
<p>误差沿着每次梯度的方向移动，从而不断调整权重大小，最终能找到解决问题的最佳权重组合</p>
<p><img src="/assets/1582970841376.png" alt="1582970841376"></p>
<p>图中学习率$\eta$限制权重调整的快慢，通常取0.001。$t_d$表期望输出，$O_d$表示实际输出。$E(w)$中的$\frac{1}{2}$则是为了便于平方求导消掉。$\Delta W_i&lt;0$则是由于要减小误差，要使$w_i$不断向误差减小的方向调整</p>
<p><strong>Delta Rule公式</strong></p>
<p>$\Delta W_i = \eta \sum_{d\in D}(t_d - o_d)x_{id}$</p>
<p>当期望输出$t_d=1$时，假设$o_d$没有那么大，那么$t_d-o_d&gt;0$，那么$\Delta W_i$和$x_{id}$同号，这意味着当输入一个正数$x$时，权重会增加，进而增大输出，进而使实际输出$o_d$接近$t_d$</p>
<p><strong>batch learning</strong></p>
<p>在batch learning模式下，权重调整出现在学习一批样本之后，即将每个样本的$\Delta w_i$累加起来，最终再修改$w_i$</p>
<p><strong>stochastic learning</strong></p>
<p>知错就改，每个样本都会更新$w_i$</p>
<h3 id="多层感知机"><a href="#多层感知机" class="headerlink" title="多层感知机"></a>多层感知机</h3><p>可以解决线性不可分问题，如XOR，原理是将原始问题在隐含层映射成线性可分问题</p>
<p><img src="/assets/1582972473943.png" alt="1582972473943"></p>
<p><strong>Sigmoid函数</strong></p>
<p><img src="/assets/1582972522129.png" alt="1582972522129"></p>
<h3 id="BP反向传播"><a href="#BP反向传播" class="headerlink" title="BP反向传播"></a>BP反向传播</h3><p><strong>对输出层权重的调整</strong></p>
<p><img src="/assets/1582972912130.png" alt="1582972912130"></p>
<p>BP算法在误差对输入求偏导的过程同感知机基本一致，唯一不同的是不在假设输出等于输入，而是更换了激活函数sigmoid。由于隐含层不知道期望输出$t_j$因此不能直接套。</p>
<p><strong>输入对隐含层的误差分析</strong></p>
<p>采用反向传播的方式，从输出层倒着向输入层过过渡</p>
<p><img src="/assets/1582973246391.png" alt="1582973246391"></p>
<p>从图中可以看到，隐含层的第$j$个神经元的权重修改量$\Delta w_{ji}$是由它指向的各个输出的权重加权和</p>
<p><strong>延伸</strong></p>
<p>BP算法是一种更新权重的方法，容易掉到局部最优点，解决方案从不同的起始点出发。</p>
<p>在权重更新公式中引入冲量有助于摆脱平缓区域</p>
<p>Elman Network：第T时刻网络的输出取决于当前的网络输入和第T-1时刻网络的内部状态</p>
<p>Hopfield Network：在一定程度上模拟人脑的联想记忆功能，是<strong>基于内容的检索</strong>，含噪声的模式识别</p>
<h2 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h2><p><a href="39.106.111.188/download/Support_Vector_Machines.ppdx">资源下载</a></p>
<p>线性SVM</p>
<p>线性分类器</p>
<p>支持向量(support vector):确定了分界面可以平移范围的数据点，margin越大容错能力越强</p>
<p>超平面$w*x+b=0$的margin大小为$\frac{2}{\vline w\vline}$</p>
<p><img src="/assets/1581757370434.png" alt="1581757370434"></p>
<p>Soft Margin:有些点$wx+b\not\geq1$，即噪声点使得无法优化margin，于是放宽条件，在求解时加入了惩罚量$\varepsilon$</p>
<p>但在实际推倒之后发现目标函数(objective function)并没有发生很大变化。</p>
<h3 id="非线性SVM"><a href="#非线性SVM" class="headerlink" title="非线性SVM"></a>非线性SVM</h3><p>映射到feature space，高维空间得特点是容易分类，可是问题在于计算量很大</p>
<p><img src="/assets/1581760041535.png" alt="1581760041535"></p>
<p>kernel trick：利用向量的特性，将高维空间得计算与低维空间得计算等价，巧妙地绕开了高维空间的计算</p>
<p>String Kernel：专门处理字符串的和函数</p>
<h3 id="发展过程"><a href="#发展过程" class="headerlink" title="发展过程"></a>发展过程</h3><p><img src="/assets/1581765589562.png" alt="1581765589562"></p>
<ul>
<li><strong>VC Dimension</strong></li>
</ul>
<p>一个分类模型的Capacity是指不论怎么分配标签，都能将多少个点分开，也就是VC Dimension</p>
<p><a href="39.106.111.188/download/SVM_Explained.pdf">拓展</a></p>
<h2 id="聚类分析"><a href="#聚类分析" class="headerlink" title="聚类分析"></a>聚类分析</h2><p>一个好的聚类算法能够<strong>处理非球形的数据分布</strong>、<strong>能够处理噪点和离群点</strong>、<strong>对样本输入序列不敏感</strong>、<strong>对海量数据的可扩展性</strong> </p>
<p>分割聚类(Partitioning Methods)    </p>
<p>K-means</p>
<p>Sequential Leader Cluster:处理流数据，迭代一次，不需要初始k</p>
<p>层次聚类(Hierarchial  Methods)</p>
<p>EM算法：Model Para和latent Para，迭代收敛求模型参数</p>
<h3 id="Density-Based-Methods"><a href="#Density-Based-Methods" class="headerlink" title="Density Based Methods"></a>Density Based Methods</h3><p><strong>DBSCAN</strong> </p>
<h3 id="Hierarchical-Clustering"><a href="#Hierarchical-Clustering" class="headerlink" title="Hierarchical Clustering"></a><strong>Hierarchical Clustering</strong></h3><p>Agglomerative Methods</p>
<h2 id="推荐算法"><a href="#推荐算法" class="headerlink" title="推荐算法"></a>推荐算法</h2><p>PageRank：在Googlez中用的比较多，评价网页重要性的指标</p>
<h3 id="协同过滤-Collaborative-Filtering"><a href="#协同过滤-Collaborative-Filtering" class="headerlink" title="协同过滤(Collaborative Filtering)"></a>协同过滤(Collaborative Filtering)</h3><p><strong>Memory-Based CF</strong>：求不同用户或者商品的相似性来预测分数</p>
<p><strong>Model-Based CF</strong>：将问题转化为分类问题，例如Naive classifier</p>
<p>三个经常遇到的问题</p>
<ul>
<li>Gray Shape：兴趣跟别人不一样，找不到类似的参考</li>
<li>Shilling Attack：恶意好评或者坏评，水军</li>
<li>Cold start：一个新用户或者新商品往往还没有数据难以打分</li>
</ul>
<p>求不同用户的相关性系数，求出用户对某商品的评分，进而进行适当推荐</p>
<p>也可以从不同的商品的相关性考虑，进而得到不同商品之间的关系</p>
<p><strong>TF-IDF的机理</strong></p>
<h2 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h2><p>集成学习是按照一定策略的将不同的模型组合到一起，从而能更好的解决机器学习问题。</p>
<p>集成学习是一类算法的统称，包含Bagging和Boosting，这两类各自又包含了很多的算法。</p>
<p>集成学习主要解决两个问题：</p>
<ol>
<li>单个模型效果不佳</li>
<li>解决多个模型的Model Selection问题</li>
</ol>
<p>集成学习在机器学习中的位置</p>
<p><img src="/assets/1582511583363.png" alt="1582511583363"></p>
<p><strong>Divide and Conquer</strong></p>
<p>集成学习可以将复杂问题简化为多个简单分类问题，来求的近似解，即分而治之。</p>
<h3 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h3><p><strong>Majority Voting</strong>：统计不同分类器的投票结果，选出票数最多的结果作为最终answer</p>
<p><strong>Weighted Majority Voting</strong>：按照权重投票，不同的分类器的效果不一样，选择加权最大的类别作为answer</p>
<p><strong>Diversity</strong>：Bagging的前提是各个分类器都不同，不同主要包含三个方面</p>
<ul>
<li><p>不同的训练算法：SVM、LinearRegression、DeepLearning等等</p>
</li>
<li><p>不同的训练过程：1.不同的初始参数   2.不同的训练集   3.不同的Feature Selection</p>
</li>
</ul>
<p><strong>Bootstrap Samples</strong>：随机抽样，有放回的随机抽取</p>
<p><strong>Bagging的思想</strong>：Bootstrap Aggregation，对不同的分类器进行Majority Voting</p>
<p><strong>Ramdom Forest</strong></p>
<p>随机森林算法是Bagging的一种，这个森林是由多颗决策树构成的，并且这些决策树互不相同。为了保证生成不同的决策树，随机森林算法进行了以下的处理</p>
<ul>
<li>Bootstrap Samples：随机抽样，选取一部分数据集</li>
<li>Ramdom Feature Selection：随机选区一定数量的特征</li>
</ul>
<p>因此随机森林的优点也很明显</p>
<ul>
<li>随机森林的Cross-Validation不再是传统的divide，而是将随机抽样中一次都没有被选中的样本Out of Bag（大概1/3）作为测试集</li>
<li>随机森林巧妙地化解了特征选择问题、过拟合问题</li>
<li>随机森林支持分类和回归问题，只有少量的参数，却有很高的Accuracy</li>
</ul>
<h3 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h3><p><strong>Stacking</strong>：bagging升级版，其工作过程如下图所示，在原有基础分类器上增加了权重，这些权重通过训练器C的训练进行调节，最终利用权重和来决策最终结果。</p>
<p><img src="/assets/1582517309628.png" alt="1582517309628"></p>
<p><strong>Boosting思想</strong>：串行训练分类器，对样本引入了权重。当前面的分类器总是将一个样本分错的时候，其权重就会越来越大，那么最新的分类器总是着重训练这些权重较大的样本，从而提高算法的accuracy。下面是boosting的一些特点</p>
<ul>
<li>分类器串行生成</li>
<li>集中训练权重较大的数据点</li>
<li>输出结合权重进行投票</li>
<li>可以通过多个弱分类器（accuracy&gt;50%）来训练出强分类器</li>
</ul>
<p><strong>boosting算法流程</strong></p>
<p><img src="/assets/1582517747859.png" alt="1582517747859"></p>
<p><strong>AdaBoost</strong></p>
<p>数据挖掘十大算法之一，运用了boosting的思想，每次分类后对样本权重进行调节，输出不同准确率加权和。<br>如下如是一个Demo演示训练过程，第一个分类器分出了两个，分错了四个，那么下一次就会在第一个分错的基础上进行二次分类，以此类推，最终得到黑色的不规则图形，完美的将数据分开。可以看出多个弱分类器是完全可以生成一个强分类器的。</p>
<p><img src="/assets/1582517968500.png" alt="1582517968500"> </p>
<p>公式推导过程：详见<a href="39.106.111.188/download/Ensemble_Learning.pptx">集成学习</a></p>
<p><strong>优点：</strong></p>
<ul>
<li>简单容易使用</li>
<li>几乎没有需要调整的参数</li>
<li>训练集可证明误差边界</li>
<li>不会出现过拟合</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>每次选则的不是最优的$\alpha$ ，只是采用贪心策略取的近似值</li>
<li>不能根据测试样本进行自适应调整</li>
<li>对噪声比较敏感</li>
</ul>
<p><strong>固定权重和动态权重：</strong></p>
<p>在adaboost中各个样本的权重都是固定的，不会根据输入发生变化，但是实际上有些模型对样本的估计结果并不好。在ReginBoost中引入了动态权重，解决了这个问题</p>
<p><strong>ReginBoost</strong></p>
<p>在基础分类器之上添加置信度的预测器，该置信度预测器实际上采用了k近邻的方式评估置信度</p>
<p><img src="/assets/1582536785047.png" alt="1582536785047"></p>
<p>对比RegionBoost和Adaboost的训练效果，如下图，左侧为训练误差，右侧为测试误差</p>
<p><img src="/assets/1582536927758.png" alt="1582536927758"></p>
<p>很明显可以看到尽管Adaboost的训练误差比较小，最后甚至趋于0，但是其测试误差很大，也就是说它预测的并不可靠。而相反ReginBoost虽然训练误差最终趋于平缓，但是其测试误差越来越小，这才是我们需要的模型。</p>
<h2 id="进化计算"><a href="#进化计算" class="headerlink" title="进化计算"></a>进化计算</h2><h3 id="全局优化"><a href="#全局优化" class="headerlink" title="全局优化"></a>全局优化</h3><p><strong>旅行商问题（tsp）</strong></p>
<p>假设有一个旅行商人要拜访n个城市，他必须选择所要走的路径，路径的限制是每个城市只能拜访一次，而且最后要回到原来出发的城市。路径的选择目标是要求得的路径路程为所有路径之中的最小值。</p>
<p>关键概念</p>
<ul>
<li>基于人口的随机优化算法</li>
<li>内在并行，不容易陷入局部最优点</li>
</ul>
<p>经典算法</p>
<ul>
<li><strong>GA：Genetic Algorithm</strong></li>
<li><strong>GP：Genetic Proramming</strong></li>
<li>ES：Evolution Strategies</li>
<li>EP：Evoluntionary Programming</li>
</ul>
<ul>
<li>EDA：Estimation of Distribution Algorithm</li>
<li>PSO：Particle Swarm Optimization</li>
<li>ACO：Ant Colony Optimization</li>
<li>DE：Differencial Evoluntion</li>
</ul>
<p><strong>并行搜索：</strong> </p>
<h3 id="遗传算法-Genetic-Algorithms"><a href="#遗传算法-Genetic-Algorithms" class="headerlink" title="遗传算法(Genetic Algorithms)"></a>遗传算法(Genetic Algorithms)</h3><p>每个问题的解决方案表示为染色体向量，初始随机生成多个染色体，然后一代代发生进化，基于自然进化的方式一代代进行改良。主要包含以下三方面的内容</p>
<ol>
<li><strong>表示</strong><ul>
<li>Individual（chromesome）</li>
<li>Population：a set of individuals</li>
<li>Offspring：通过基因生成器生成的individuals</li>
<li>Encoding：Binary Or Gray</li>
</ul>
</li>
<li><strong>生成基因</strong><ul>
<li>杂交：在两个染色体之间交换遗传物质</li>
<li>变异：随机修改选定位置的基因值</li>
</ul>
</li>
<li><p><strong>选择</strong></p>
<ul>
<li>Roulette Wheel Selection：轮盘选择法，就是通过丢飞镖选择性状，值越大概率越大，缺点是没法处理负值或有单个值特别高就会漏选较好的变异体</li>
<li>Rank Selection：利用排名减小值的差距</li>
<li>Tournament Selection：两个或多个人相互PK，人数越多presure越大</li>
<li>Elitism Selection：精英选择，后代不一定比双亲好，可能由于变异或者杂交损失一些染色体，复制最好的性状到下一代。</li>
<li>Offspring Selection：用最老的染色体代替子孙染色体</li>
</ul>
</li>
</ol>
<p><strong>选择VS杂交VS变异</strong></p>
<ul>
<li>选择<ul>
<li>可视为搜索资源分配的调节机制</li>
<li>进化初期Selection Pressure过大易导致不成熟收敛</li>
</ul>
</li>
<li>杂交<ul>
<li>从好的个体基因生成更好的个体</li>
<li>是GA的主要搜索方式</li>
<li>体现出对现有搜索结果的精细利用（Exploitation）</li>
<li>不影响基因的多样性</li>
</ul>
</li>
<li>变异<ul>
<li>增加基因多样性</li>
<li>体现出对解空间的各个区域的探索（Exploration）</li>
<li>通常独立作用于个体的某一位基因</li>
</ul>
</li>
</ul>
<p>上述过程总的来说是Exploration vs. Exploitation，前者意为探险，即探索不同的区域，主要从基因多样性角度考虑，后者Exploitation则指在某个区域进行更深层次的勘探（Choice）</p>
<p><strong>GA 框架</strong></p>
<p><img src="/assets/1582683540858.png" alt="1582683540858"></p>
<h3 id="遗传编程-Genetic-Programming"><a href="#遗传编程-Genetic-Programming" class="headerlink" title="遗传编程(Genetic Programming)"></a>遗传编程(Genetic Programming)</h3><h3 id="可进化硬件-Evolvable-Things"><a href="#可进化硬件-Evolvable-Things" class="headerlink" title="可进化硬件(Evolvable Things)"></a>可进化硬件(Evolvable Things)</h3>]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>数据挖掘</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo部署博客到云服务器ECS</title>
    <url>/2020/02/07/23DeployToECS/</url>
    <content><![CDATA[<p><img src="/images/aliyunPlan.jpg" alt="cover"></p>
<a id="more"></a>
<h2 id="前言："><a href="#前言：" class="headerlink" title="前言："></a>前言：</h2><p>在新型肺炎盛极一时的寒假，只能呆在家里，所以可不能一直堕落下去，否则就浪费太多时间了。正好这会各个机构都尽其所能提供<strong>免费</strong>资源，还有免费6个月的阿里云服务器可以用(详见<a href="https://developer.aliyun.com/adc/student/">阿里云高校学生“在家实践计划”</a>)，还不赶紧趁这个机会好好冲冲电！</p>
<p>租了服务器可以用来运行一些网站，应用还有一些小工具，还可以做内网穿透，总之极大的方便了与其他同学的分享和交流，所以决定先把我本地的hexo部署到服务器上(原先部署在github上)。</p>
<h2 id="本地环境"><a href="#本地环境" class="headerlink" title="本地环境"></a>本地环境</h2><p>要有hexo,node.js,git，详情见<a href="http://39.106.111.188/2018/08/07/02Blog-Build/">第一次建网站</a></p>
<h2 id="服务器端"><a href="#服务器端" class="headerlink" title="服务器端"></a>服务器端</h2><p>需要一台服务器，这里用的是阿里云的ECS ubuntu 18.04.1，能够正常登陆实例</p>
<h2 id="安装Git和Nginx"><a href="#安装Git和Nginx" class="headerlink" title="安装Git和Nginx"></a>安装Git和Nginx</h2><p>git用于版本管理和部署，Nginx用于静态博客托管</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install git nginx -y</span><br></pre></td></tr></table></figure>
<h2 id="配置SSH"><a href="#配置SSH" class="headerlink" title="配置SSH"></a>配置SSH</h2><p>将本地公钥复制，一般在(C:\Users\Administrator\.ssh)下，如果没有的话，在git bash中用<code>ssh-ken -t rsa</code>生成ssh公钥</p>
<p><img src="/assets/1581063553702.png" alt="1581063553702"></p>
<ul>
<li>在云服务器上创建一个git用户，用来运行git服务</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">adduser git #创建用户</span><br><span class="line">passwd git  #设置密码</span><br></pre></td></tr></table></figure>
<ul>
<li>切换至git用户，添加SSH Key</li>
</ul>
<p>在服务器端，切换至刚刚创建好的git用户下，创建<code>.ssh文件</code>和<code>authorized_keys</code>文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">su git</span><br><span class="line">mkdir ~&#x2F;.ssh</span><br><span class="line">vim ~&#x2F;.ssh&#x2F;authorized_keys</span><br></pre></td></tr></table></figure>
<ul>
<li>修改权限</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd ~</span><br><span class="line">chmod 600 .ssh&#x2F;authorzied_keys # 将文件设置为可读可写</span><br><span class="line">chmod 700 .ssh #将该文件夹设置为可读可写可执行，注意文件夹的可执行是指能访问</span><br></pre></td></tr></table></figure>
<ul>
<li>测试git连接</li>
</ul>
<p>切换到本地机器上，在本地机器上测试是否能连接到你的远程git用户</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh -v git@SERVER_IP   #你的服务器IP</span><br></pre></td></tr></table></figure>
<p>测试成功（中间可能让输入密码，不要慌就是你的git user的密码或者试试远程）</p>
<p><img src="/assets/1581064070477.png" alt="1581064070477"></p>
<h2 id="创建Git仓库"><a href="#创建Git仓库" class="headerlink" title="创建Git仓库"></a>创建Git仓库</h2><p>在<code>/var/repo/</code>下创建名为hexo_website的裸仓库。用如下命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo mkdir &#x2F;var&#x2F;repo&#x2F;   #创建目录</span><br><span class="line">sudo chown -R $USER:$USER &#x2F;var&#x2F;repo&#x2F;  #文件拥有着</span><br><span class="line">sudo chmod -R 755 &#x2F;var&#x2F;repo&#x2F;    #可读可写可执行</span><br><span class="line"> </span><br><span class="line">cd &#x2F;var&#x2F;repo&#x2F; </span><br><span class="line">git init --bare hexo_static.git  #初始化仓库</span><br></pre></td></tr></table></figure>
<h2 id="配置Nginx托管文件目录"><a href="#配置Nginx托管文件目录" class="headerlink" title="配置Nginx托管文件目录"></a>配置Nginx托管文件目录</h2><p>创建<code>/var/www/hexo</code>目录，用于Nginx托管，修改目录所有权和权限</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo mkdir -p &#x2F;var&#x2F;www&#x2F;hexo</span><br><span class="line"></span><br><span class="line">sudo chown -R $USER:$USER &#x2F;var&#x2F;www&#x2F;hexo</span><br><span class="line">sudo chmod -R 755 &#x2F;var&#x2F;www&#x2F;hexo</span><br></pre></td></tr></table></figure>
<p>随后修改Nginx的<code>default</code>设置，使<code>root</code>指向<code>hexo</code>目录</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim &#x2F;etc&#x2F;nginx&#x2F;sites-available&#x2F;default</span><br></pre></td></tr></table></figure>
<p>修改文件中对应的项，vim操作见<a href="https://blog.csdn.net/wuyuefei3/article/details/81139343">linux下使用vim编辑文件并保存</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 80 default_server;</span><br><span class="line">    listen [::]:80 default_server;</span><br><span class="line"></span><br><span class="line">    root &#x2F;var&#x2F;www&#x2F;hexo; # 需要修改的部分</span><br><span class="line">    index index.html index.htm;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>重启Nginx服务，使得改动生效</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo service nginx restart</span><br></pre></td></tr></table></figure>
<h2 id="创建Git钩子"><a href="#创建Git钩子" class="headerlink" title="创建Git钩子"></a>创建Git钩子</h2><blockquote>
<p><a href="https://git-scm.com/book/zh/v2/%E8%87%AA%E5%AE%9A%E4%B9%89-Git-Git-%E9%92%A9%E5%AD%90">git钩子</a>在此处命名为<code>post-receive</code>也就是该挂钩在git提交之后自动执行文件里的内容。</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim &#x2F;var&#x2F;repo&#x2F;hexo_static.git&#x2F;hooks&#x2F;post-receive</span><br></pre></td></tr></table></figure>
<p>在该文件中添加代码，指定Git的工作树（源代码）和Git目录（配置文件等）的位置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">git --work-tree&#x3D;&#x2F;var&#x2F;www&#x2F;hexo --git-dir&#x3D;&#x2F;var&#x2F;repo&#x2F;hexo_static.git checkout -f</span><br></pre></td></tr></table></figure>
<p>保存并退出文件，并将该文件变成可执行文件。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod +x &#x2F;var&#x2F;repo&#x2F;hexo_static.git&#x2F;hooks&#x2F;post-receive</span><br></pre></td></tr></table></figure>
<h2 id="回到本地配置"><a href="#回到本地配置" class="headerlink" title="回到本地配置"></a>回到本地配置</h2><p>在站点_config.yml中修改博客url地址</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># URL</span><br><span class="line">## If your site is put in a subdirectory, set url as &#39;http:&#x2F;&#x2F;yoursite.com&#x2F;child&#39; and root as &#39;&#x2F;child&#x2F;&#39;</span><br><span class="line"></span><br><span class="line">url: http:&#x2F;&#x2F;server-ip # 没有绑定域名时填写服务器的实际 IP 地址。</span><br><span class="line">root: &#x2F;</span><br><span class="line">permalink: :year&#x2F;:month&#x2F;:day&#x2F;:title&#x2F;</span><br><span class="line">permalink_defaults:</span><br></pre></td></tr></table></figure>
<h2 id="通过Git部署"><a href="#通过Git部署" class="headerlink" title="通过Git部署"></a>通过Git部署</h2><p>先在任意位置处打开cmd, 从服务器上把<code>hexo_static</code>仓库克隆下来, 以此来将服务器地址添加到受信任的站点中。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone git@server_ip:&#x2F;var&#x2F;repo&#x2F;hexo_static.git</span><br></pre></td></tr></table></figure>
<p>注意在第一次进行这一步时会提示是否继续，选yes即可。<code>git@server_ip</code>这里的<strong>git</strong>不是固定的，而是你的服务器用户名（例如root/admin，<strong>我曾在这个错误上困扰了许久许久</strong>！！！），此外<strong>server_ip</strong>就是你的远程服务器IP地址。</p>
<p>再编辑Hexo的<code>config.yml</code>文件，找到Deployment, 修改为</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line"> type: git</span><br><span class="line"> repo:</span><br><span class="line">     #同步部署到服务器和github</span><br><span class="line">    github: https:&#x2F;&#x2F;github.com&#x2F;GithubName&#x2F;GithubName.github.com </span><br><span class="line">    hexo: git@server_ip:&#x2F;var&#x2F;repo&#x2F;hexo_static.git</span><br><span class="line"> branch: master</span><br></pre></td></tr></table></figure>
<p>于是就可用<code>hexo d</code>命令来部署了到服务器了。</p>
<h2 id="外部访问服务器网站"><a href="#外部访问服务器网站" class="headerlink" title="外部访问服务器网站"></a>外部访问服务器网站</h2><p>部署到服务器之后，需要开启80端口(与Nginx配置文件中同步)，详情见<a href="https://www.aliyunfuwuqi.com/ecs/2254/">https://www.aliyunfuwuqi.com/ecs/2254/</a>开启了80端口并成功部署网站之后，就可以通过<a href="http://xx.xx.xx.xx来访问你的网站啦！">http://xx.xx.xx.xx来访问你的网站啦！</a></p>
<p>欢迎大家访问<a href="http://39.106.111.188/">我的网站主页</a>。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><em>用Hexo部署博客到Ubuntu服务器：<a href="https://www.jianshu.com/p/16b89f4f7136">https://www.jianshu.com/p/16b89f4f7136</a></em></p>
<p><em>阿里云服务器远程连接：<a href="https://www.cnblogs.com/chenyablog/p/10281995.html">https://www.cnblogs.com/chenyablog/p/10281995.html</a></em></p>
<p><em>linux下使用vim编辑文件并保存：<a href="https://blog.csdn.net/wuyuefei3/article/details/81139343">https://blog.csdn.net/wuyuefei3/article/details/81139343</a></em></p>
<p><em>linux下chmod +x的意思？<a href="https://blog.csdn.net/u012106306/article/details/80436911">https://blog.csdn.net/u012106306/article/details/80436911</a></em></p>
<p><em>Git钩子的使用<a href="https://git-scm.com/book/zh/v2/%E8%87%AA%E5%AE%9A%E4%B9%89-Git-Git-%E9%92%A9%E5%AD%90">https://git-scm.com/book/zh/v2/%E8%87%AA%E5%AE%9A%E4%B9%89-Git-Git-%E9%92%A9%E5%AD%90</a></em></p>
]]></content>
      <tags>
        <tag>ECS</tag>
      </tags>
  </entry>
  <entry>
    <title>考研结束</title>
    <url>/2019/12/24/22PostGraduate_Exam/</url>
    <content><![CDATA[<script src="/crypto-js.js"></script><script src="/mcommon.js"></script><h3 id="encrypt-message">Please enter the password to read the blog.</h3><link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap.min.css"> <link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap-theme.min.css"> <script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script> <script src="//cdn.bootcss.com/bootstrap/3.3.5/js/bootstrap.min.js"></script> <div id="security"> <div> <div class="input-group"> <input type="text" class="form-control" aria-label="Enter the password." id="pass"/> <div class="input-group-btn"> <button type="button" class="btn btn-default" onclick="decryptAES()">Decrypt</button> </div> </div> </div> </div> <div id="encrypt-blog" style="display:none"> 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 </div>]]></content>
      <tags>
        <tag>随笔</tag>
        <tag>考研</tag>
      </tags>
  </entry>
  <entry>
    <title>考研复习回顾总结</title>
    <url>/2019/08/07/21NextPlan/</url>
    <content><![CDATA[<p><img src="/images/21NextPlan.jpg" alt="cover"><br><a id="more"></a></p>
<h1 id="考研复习回顾总结"><a href="#考研复习回顾总结" class="headerlink" title="考研复习回顾总结"></a>考研复习回顾总结</h1><p><strong>数学</strong>：</p>
<p>截至到目前为止，已经完成了高数部分的二轮回顾，以及660高数选择部分，正在进行线代的二轮强化，本月目标</p>
<ul>
<li>8.07-8.15  完成线性代数的二刷，同时完成高数前三章的李范全书。</li>
<li>8.15-8.31 完成概率论的二轮复习，继续刷李范全书。</li>
</ul>
<p>在此期间同时不定期的回顾分阶训练及660错题的回顾分析。</p>
<p><strong>英语</strong>：</p>
<p>英语已经完成了1998-2015中十年左右的真题阅读部分，阅读能力、对题目的理解有所提高，但也发现对自己来说单词是弱项，本月目标</p>
<ul>
<li>8.07-8.15  每日阅读+完成list21-list30的单词，完成恋恋有词一刷</li>
<li>8.16-8.31  翻译训练+二刷恋恋有词+主攻单词本积累</li>
</ul>
<p><strong>专业课</strong></p>
<p>专业课到目前为止已经完成了操作系统及数据结构的大部分内容，第一遍过的时候比较费劲，但一定要都啃一遍。本月目标</p>
<ul>
<li>8.07-8.10  完成数据结构的复习及回顾</li>
<li>8.11-8.21 完成计算机网络的一轮复习，同时刷完一遍操作系统网课</li>
</ul>
<p><strong>政治</strong></p>
<ul>
<li>8.07-8.31  完成徐涛强化班学习，并且学完一科，刷一科的1000题</li>
</ul>
<p><strong>总结</strong></p>
<p>​    整体来说进度适中，专业课进度有些慢，在中旬之前抽出晚上部分英语时间补补专业课进度。争取在计划之内完成专业课一轮，然后在对英语进行其他题型的专项训练，现阶段主要以积累词汇为主。</p>
<p><strong>感受</strong>：习惯了考研的节奏以后，发现每天还都过的挺充实的，有时候做题不顺会心急，需要克服。看了很多经验帖，也得到很多高人指点了，剩下的就剩把方法论运用于实践了！此梦必圆！</p>
]]></content>
      <tags>
        <tag>随笔</tag>
        <tag>考研</tag>
      </tags>
  </entry>
  <entry>
    <title>西安交大&amp;百度竞赛总结</title>
    <url>/2019/07/01/20Baidu-XJTU_BigData_Contest/</url>
    <content><![CDATA[<p><img src="/images/BaiDuContest.jpg" alt="cover"><br><a id="more"></a></p>
<h1 id="西安交大-amp-百度竞赛总结"><a href="#西安交大-amp-百度竞赛总结" class="headerlink" title="西安交大&amp;百度竞赛总结"></a>西安交大&amp;百度竞赛总结</h1><p>比赛的相关介绍见：<a href="https://dianshi.baidu.com/competition/30/rule">百度点石竞赛总结</a> ，数据分为遥感图像和用户访问数据两部分，要求参赛者根据这两部分数据预测新地点的标签，分类内容如下图</p>
<p><img src="/assets/1561900835759.png" alt="1561900835759"> </p>
<h3 id="第一版思路"><a href="#第一版思路" class="headerlink" title="第一版思路"></a>第一版思路</h3><p>这是第一次参加接触相关领域的知识，作为一个小白，很想从这个竞赛入手来学习深度学习相关的知识技能。起初分别对遥感图像和用户访问数据建立单网进行深度学习，整体使用的是keras框架，考虑到keras易于学习和使用，且能够以较快的尝试更多的创意。</p>
<p><img src="/assets/1561952095923.png" alt="1561952095923"></p>
<h4 id="图像处理"><a href="#图像处理" class="headerlink" title="图像处理"></a>图像处理</h4><p>对图像部分的数据尝试了Inception系列、VGG系列、NasNet及Xception等，构建模型时，初始采用各个模型在imgnet网络上的训练权重，在各网的基础结构后添加9个神经元的Dense层，用于最后的分类。经过实验，发现NASNet的Accuracy的结果较好，在0.42左右。</p>
<h4 id="用户访问数据处理"><a href="#用户访问数据处理" class="headerlink" title="用户访问数据处理"></a>用户访问数据处理</h4><p>对用户数据部分试验了Rnn、Xgboost及Lightgbm等网络</p>
<h4 id="数据融合"><a href="#数据融合" class="headerlink" title="数据融合"></a>数据融合</h4><p>数据融合实际上一开始用了权重相加，效果不好，只有0.71左右，后来认为为什么不将不同所求的概率作为输入，用验证集作为最后的一个xgboost的训练集来训练融合模型，最后效果为0.7240，比直接通过加权相加的效果好了很多，可以调节xgboost的参数来提高效果。</p>
<h3 id="第二版思路"><a href="#第二版思路" class="headerlink" title="第二版思路"></a>第二版思路</h3><h4 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h4><p>经队员提醒，发现所给的遥感图像中有很多脏数据，如下图所示</p>
<p><img src="/assets/1561964040175.png" alt="1561964040175"> </p>
<p>有一部分图块是全黑的，还有一部分图块是被云朵遮盖的，剩下的就是只能看到部分区域图，这也许会影响到模型的质量，我们第二版的思路就是将这些图片剔除掉之后再使用NasNet进行建模。</p>
<p>随后又对图像做了一些预处理，包括去雾、旋转等，后来还使用GNN对图片进行了增强，从100×100的小矩阵增强到了224×224的矩阵形式，随后送入到神经网络中进行训练，最后的得到的实验结果是…。</p>
<h4 id="尝试用户访问数据新模型思路"><a href="#尝试用户访问数据新模型思路" class="headerlink" title="尝试用户访问数据新模型思路"></a>尝试用户访问数据新模型思路</h4><p>虽然用户的访问数据比较适合序列的训练方式，我们团队尝试将访问数据按照不同的特征问题归类，如一些人数、假期等等。归类之后将其作为24维的输入即7×26×24，送到NasNet等卷积神经网络中进行训练，通过将图片数据和用户数据送到同一个网络中进行训练，得到了的0.68的效果。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过参加此次竞赛，我基本了解了大数据相关竞赛的参赛思路，如何去构建模型，如何去调整参数，如何从loss及accuracy等的变化中读取模型构建的情况，是否产生了过拟合等等。也了解了当前<a href="http://baijiahao.baidu.com/s?id=1599943447101946075&amp;wfr=spider&amp;for=pc">比较流行的几个深度学习框架</a>同时，我也认识到了讨论区的重要性，有些大佬会把最初的demo分享在github上， 通过学习、讨论及复现能够了解别人的思路，能够发现自己忽略的问题。竞赛是了解相关知识的较好途径，大佬们分享的代码简直就是宝物。</p>
<p>下面附上几版代码以便自己和别人后续的学习使用：</p>
<ol>
<li><a href="https://github.com/czczup/UrbanRegionFunctionClassification">baseline</a></li>
<li><a href="https://github.com/SeaEagleI/2019_Baidu-XJTU_BigData_Contest">69.4成绩</a> </li>
</ol>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://blog.csdn.net/qq_34919792/article/details/93976813">第五届百度&amp;西安交通大学大数据竞赛初赛思路总结</a> </p>
]]></content>
      <tags>
        <tag>深度学习</tag>
        <tag>比赛</tag>
      </tags>
  </entry>
  <entry>
    <title>K-means与MeanShift</title>
    <url>/2019/04/04/18K-means&amp;MeanShift/</url>
    <content><![CDATA[<p><img src="/images/machine.jpg" alt="cover"><br><a id="more"></a></p>
<h1 id="k-means"><a href="#k-means" class="headerlink" title="k-means"></a>k-means</h1><p>k-means算法是机器学习中的一种常见聚类算法。聚类算法属于无监督学习，相比于回归、朴素贝叶斯等少了标签y的信息。K-means算法是将样本聚成k个簇，具体执行步骤如下</p>
<p>（1）      随机选区k个对象作为初始聚类中心</p>
<p>（2）      计算每一个样本到簇的距离来划分</p>
<p>（3）      再次计算每个聚类中心</p>
<p>（4）      计算标准测度函数，直到达到最大迭代次数，则停止，否则，继续操作</p>
<p>通过不断地调整聚类中心的位置，使得聚类中心逐渐转移到与附近样本距离和最小的位置，这里通过标准测度函数进行计算。这里的距离有很多种计算方式，常见的有欧式距离和曼哈顿距离。</p>
<p>​       该算法通过调用sklearn.cluster的Kmeans类实现模型的训练，再通过简单的绘图来表示聚类中心与样本的关系，如图所示。</p>
<p><img src="/assets/20180228115245278-1554340564954.gif" alt="20180228115245278"></p>
<p>图6-1 K-means算法确定的4个聚类中心</p>
<p><strong>算法优点：</strong></p>
<ul>
<li><p>速度快，计算简便</p>
</li>
<li><p>聚类效果较优</p>
</li>
<li><p>算法的可解释度比较强</p>
</li>
</ul>
<p><strong>算法缺点：</strong></p>
<ul>
<li><p>必须提前知道数据有多少类/组</p>
</li>
<li><p>对于不是凸的数据集比较难收敛</p>
</li>
<li><p>采用迭代方法，得到的结果只是局部最优</p>
</li>
<li><p>初始聚类中心的选择</p>
</li>
<li><p>对于离群点和噪声点比较敏感，模型受影响较大</p>
</li>
</ul>
<p><strong>算法延伸：</strong></p>
<p>​             对初始聚类中心的选择进行改进，有了K-means++、二分K-means等等<br>  采用MeanShift避开对数据集聚类中心K的选择</p>
<h1 id="MeanShift均值漂移"><a href="#MeanShift均值漂移" class="headerlink" title="MeanShift均值漂移"></a>MeanShift均值漂移</h1><p>​       MeanShift均值漂移算法也是一种常见的聚类算法，它的工作方式跟K-means很相似，两者都是通过不断地调整位置，进而逼近样本密度最大的区域中心。它常被用在图像识别中的目标跟踪，数据聚类、分类等场景，前者的核函数使用了Epannechnikov核函数，后者使用了Gaussian(高斯核函数)</p>
<p>​       <strong>算法执行步骤：</strong></p>
<ul>
<li><p>确定滑动窗口半径r，以随机选取的中心点C半径为r的圆形滑动窗口开始滑动。均值漂移类似一种爬山算法，在每一次迭代中向密度更高的区域移动，直到收敛。</p>
</li>
<li><p>每一次滑动到新的区域，计算滑动窗口内的均值来作为中心点，滑动窗口内的点的数量为窗口内的密度。在每一次移动中，窗口会想密度更高的区域移动。</p>
</li>
<li><p>移动窗口，计算窗口内的中心点以及窗口内的密度，知道没有方向在窗口内可以容纳更多的点，即一直移动到圆内密度不再增加为止。</p>
</li>
<li><p>步骤一到三会产生很多个滑动窗口，当多个滑动窗口重叠时，保留包含最多点的窗口，然后根据数据点所在的滑动窗口进行聚类</p>
</li>
</ul>
<p>迭代过程如下图</p>
<p>   <img src="/assets/201802281615434.gif" alt="201802281615434"></p>
<p>图6-2 MeanShift算法迭代过程</p>
<p><strong>算法优点：</strong></p>
<ul>
<li><p>不同于K-Means算法，均值漂移聚类算法不需要我们知道有多少类/组</p>
</li>
<li><p>基于密度的算法相比于K-Means受均值影响较小</p>
</li>
</ul>
<p><strong>算法缺点：</strong></p>
<ul>
<li>窗口半径r的选择可能是不重要的</li>
</ul>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><p>​    随机森林就是通过集成学习的思想将多棵树集成的一种算法，它的基本单元是决策树，而它的本质属于机器学习的一大分支——集成学习（Ensemble Learning）方法。</p>
<p>​    其实从直观角度来解释，每棵决策树都是一个分类器（假设现在针对的是分类问题），那么对于一个输入样本，N棵树会有N个分类结果。而随机森林集成了所有的分类投票结果，将投票次数最多的类别指定为最终的输出，这就是一种最简单的 Bagging 思想。</p>
<p><strong>每棵树的按照如下规则生成：</strong></p>
<p>（1）   如果训练集大小为N，对于每棵树而言，随机且有放回地从训练集中的抽取N个训练样本（这种采样方式称为bootstrap sample方法），作为该树的训练集；</p>
<p>（2）   如果每个样本的特征维度为M，指定一个常数m&lt;&lt;M，随机地从M个特征中选取m个特征子集，每次树进行分裂时，从这m个特征中选择最优的;</p>
<p>（3）   每棵树都尽最大程度的生长，并且没有剪枝过程</p>
<p><strong>算法优点：</strong></p>
<ul>
<li><p>在当前所有算法中，具有极好的准确率</p>
</li>
<li><p>能够有效地运行在大数据集上</p>
</li>
<li><p>能够处理具有高维特征的输入样本，而且不需要降维</p>
</li>
<li><p>对于缺省值问题也能够获得很好得结果</p>
</li>
</ul>
<p><strong>错误率影响：</strong></p>
<ul>
<li><p>森林中任意两棵树的相关性：相关性越大，错误率越大</p>
</li>
<li><p>森林中每棵树的分类能力：每棵树的分类能力越强，整个森林的错误率越低</p>
</li>
</ul>
<h1 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h1><p><a href="https://blog.csdn.net/Katherine_hsr/article/details/79382249">常见的六大类聚类算法</a></p>
<p><a href="https://www.cnblogs.com/gczr/p/7097704.html">随机森林</a></p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>k-means</tag>
      </tags>
  </entry>
  <entry>
    <title>浅谈深度学习</title>
    <url>/2019/04/04/19Deep-Learning/</url>
    <content><![CDATA[<p><img src="/images/nuralNetwork.jpg" alt="cover"></p>
<a id="more"></a>
<h2 id="浅谈深度学习"><a href="#浅谈深度学习" class="headerlink" title="浅谈深度学习"></a>浅谈深度学习</h2><p>这几年深度学习真的很火，其热门程度渐渐超过了传统的机器学习算法。很多学校都专门开设了深度学习这样一门学科，通过了解后才渐渐感受到其思想。</p>
<p>我最初对深度学习的印象一步步的发生了变化，这个变化通常是当下学习新东西的整体脉络。每当我一搜深度学习，总是会有很多资料铺天盖地迎面而来，水文好文参差不齐，总之给我的印象就是繁杂。繁杂到我不知道从哪里入手，不知道如何迈出我的第一步。资料确实是太多了，我看到有推荐Coursera上deeplearning.ai的视频，有推荐AlexNet、GooleNet等网络的专业论文，还有推荐的其他各种各样的文档资料及培训课。正是这些东西让我难以下手，其实我只想一窥其全貌，看看适不适合我，决定深入多深。</p>
<p>于是我自己找了本书，在图书馆简单的浏览了一遍，就是下面这本。我不能说它有多好，因为这是我看的第一本深度学习书籍。但我觉得对入门还是比较有帮助的。</p>
<p><img src="/assets/1561272851686.png" alt="1561272851686"> </p>
<p>在看完这本书后，我感叹科学家的伟大，深度学习模拟人脑的工作方式，搭建出了一个神经网络。举个例子：当我们在看到一只猫时，我们是如何判断出它是一直猫的。在这个过程中，我们的眼睛把看到的景象通过一层一层的神经元传到大脑，在大脑又拿出其对各类动物体态特征的记忆进行对比，通过不断的比较验证，最终判断出它是一只猫。而神经网络的工作方式也很类似，为了量化我们的输入的各维特征，才出现了权重，同时为了能够更深入的分析各个神经元的内在关系，出现了激活函数等。</p>
<p>我是通过百度电石上的一个大数据比赛来入手深度学习的，身边有几位大佬，很少但很宝贵。我通过学习他们的源代码，渐渐明白了在python语言中，神经网络的搭建过程。我看到他们设计的一百多层的网络都惊呆了，感觉这没有个三五年功夫是很难弄出来的，问他们也都说是经验，让人无从下手，难以琢磨。</p>
<p>但事实上，要想一窥其全貌还是比较容易的，因为有很多经过多层封装的深度学习函数库，如keras、pytorch、caffe等等，他们的使用就会相对容易一些。在这里要介绍一下网络，常用的网络组成有全连接层、池化层、压平层等等，而我们经常见到的AlexNet、GoogleNet、NasNet则大多数都是在比赛中提出来的已经设计层次结构的神经网络，对于我们小白而言，只需要将他们设计好的神经网络拿过来用一用就能学到不少东西了，而我们只需要修改一下输入输出。有一份大佬的代码真是非常宝贵，如果你也想入门，建议你到大数据平台上看看题目，下载几份源码学习。认真的把每个函数搞懂，每个参数的意思搞清楚，再慢慢深入去研究原理公式，我觉得这才是学习的正确思路。我觉得一上来就学习深层的理论知识很容易磨灭人的兴趣和意志，不利于长期学习。</p>
<p>深度学习如今的应用也是很广泛，新的网络结构和技术也是层出不穷，进入这行确实需要勇气，但是在深入学习理论知识之前，一定要先学习工具包怎么用，然后尝试自己写，最后再去推倒公式。大佬们由于都已经经历过这个过程，所以他们听说要学习深度学习一上来就推荐看西瓜书、花书等等，这些书确实囊括了很多精华知识点，却不一定适合当下的我们。</p>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>自我反思总结</title>
    <url>/2019/04/02/17SelfSummary/</url>
    <content><![CDATA[<script src="/crypto-js.js"></script><script src="/mcommon.js"></script><h3 id="encrypt-message">Please enter the password to read the blog.</h3><link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap.min.css"> <link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap-theme.min.css"> <script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script> <script src="//cdn.bootcss.com/bootstrap/3.3.5/js/bootstrap.min.js"></script> <div id="security"> <div> <div class="input-group"> <input type="text" class="form-control" aria-label="Enter the password." id="pass"/> <div class="input-group-btn"> <button type="button" class="btn btn-default" onclick="decryptAES()">Decrypt</button> </div> </div> </div> </div> <div id="encrypt-blog" style="display:none"> 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 </div>]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>蓝桥杯和软微</title>
    <url>/2019/03/25/16LanQiao&amp;SS/</url>
    <content><![CDATA[<p><img src="/images/contest.jpg" alt="cover"><br><a id="more"></a></p>
<p>时隔一月，尤其是在考完蓝桥杯之后又有一些体会，在此记录，整理思路。</p>
<h2 id="第十届蓝桥杯初赛"><a href="#第十届蓝桥杯初赛" class="headerlink" title="第十届蓝桥杯初赛"></a>第十届蓝桥杯初赛</h2><p>为这个蓝桥杯，准备了将近一个月的时间，这一个月数学没看、英语没背、课也没有好好上，将历年的题大部分都敲了一遍，视频也过了一遍。可是在那天的发挥却不尽人意，找不到问题出在哪，考试的时候就是不知道什么原因就自己绕进去了，丢了两道很简单的题的分数，这让我郁闷了好久。</p>
<p>其实，这应该是很正常的事情，就像孙兰昌学长跟我说的那样，付出并不一定有回报，有些事情就不是自己想的那样。但是不付出，肯定是一点机会都没有的，其实这一个月自我感觉编程能力还是有一定程度的提高的。然而由于一部分原因，让我没有完全发挥出自己的水平，这可能是因为紧张的缘故？其实我自己考完试都难以相信，自己怎么会在那么简单的问题上兜圈子（没错，就是那个BYQ）。</p>
<p>我起初的想法是，这次可能是最后一次参加蓝桥杯了，我希望能够突破一下自我，能够进一次决赛，我相信大学到现在的积累应该给我尝试的机会，可是现在看来，多半是没希望了。不过我也不应该在这件事上纠结太久，毕竟还有其他的事情等着我去做。</p>
<h2 id="本学期课程吐槽"><a href="#本学期课程吐槽" class="headerlink" title="本学期课程吐槽"></a>本学期课程吐槽</h2><p>接下来在聊聊对这学期课程的感受，这学期从开学到现在，让我最期待的无非就是机器学习课程了，可是当我听了一节课、两节课之后，失望的表情溢于言表。老师只是很简单很简单的介绍了一下概念性的知识，这些东西去了解是很快的、毫不费力的，我不理解这样授课有什么价值。外聘的老师都这么水，更不用提专业的老师了，除了马丽老师的课（不爱听），再找个有水准的就很难了。</p>
<p>可能这仅仅是我的体会，不过这种体会预示着我应该做出一些改变，而不是按部就班的跟着浪费时间，我觉得应该用这些时间做些更有价值的事情。但其实这些课程的初衷是非常好的，计算机英语无处不在、操作系统是考研必考课程、机器学习当下非常流行等等，可是我从我们专业的老师那里体会不到半点水平。所以我还不能直接略过这些课、考虑到又不能听，所以解决办法只有一个，那就是上课自学或者上课补作业，然后课下按照自己的复习计划进行，这是我目前想到让自己感觉好一些的解决措施。</p>
<h2 id="软微复试交流"><a href="#软微复试交流" class="headerlink" title="软微复试交流"></a>软微复试交流</h2><p>在3月19日下午，我跟董慧芹一同去了趟北大的软微学院，那天是复试的第一天，我们打算去碰碰运气，看能不能认识一两个大佬。软微距离北石化也就三公里，坐公交十多分钟就到。到了那，先冷静的观察了一波，问了问，才知道技术组在一层面试。于是在一层门口观望，正好遇到了一个提前来打探情况的复试大佬，他是化学专业跨考，还是二战考生。</p>
<p>他跟我分享了很多自己准备软微的体会，还跟我聊了面试老师的问题以及需要注意的事项，他跟我说了好几个专业方向的面试问题，我竟然一个都答不上来。虽然有一部分知识是还没学，但另一部分知识确实是没接触过！学校的课程里从来就没有提过，自己也没用过，因为没有那样的需求，平时接触到的都是很简单的操作，基本都没有优化问题。后来那个师兄还跟我讲了很多自己复习的经验，以及复试群里讨论的内容，我真的十分庆幸，我认识了这样一个师兄，我特别希望他能顺利上岸，也能给我树立个榜样，让我更有动力去准备。</p>
<p>这让我意识到，我之前学的东西都太shallow了，其实自己能接收的知识还能再多一些，可是课堂上却给不了了，在课下又想着做各种各样的事情，于是就被死死的限制而出不来，并且无论是学分绩还是在同学中的威望，让我很难去摆脱这样的瓶颈。这是我近期一度困惑的问题，我不知道该怎么去调整了。</p>
<h2 id="继续考研复习规划"><a href="#继续考研复习规划" class="headerlink" title="继续考研复习规划"></a>继续考研复习规划</h2><p>现在都已经三月底了，已经耽误了不少复习时间了，下面我要开始认真的复习考研内容了。对于放下的数学，我目前的想法是将寒假讲的知识先过一遍，做做例题。过完一遍之后，再从微分方程那块继续往后复习，得赶紧把高数先整体过一遍，然后再选择重复或者是看线代。</p>
<p>对于英语，要开始背单词，回到高中那会手写纸上两排，捂着复习、重复的记忆。我在这种方式下记单词的效率还是挺高的，为期21天，如果不能坚持，那就刷题。专业课上课时间补，就这些了，希望自己继续坚持，继续加油！！！</p>
]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>京东手机评论爬虫</title>
    <url>/2019/02/26/15JDComment-Spider/</url>
    <content><![CDATA[<p><img src="/images/jdSpider.jpg" alt="cover"><br><a id="more"></a></p>
<h2 id="所用工具"><a href="#所用工具" class="headerlink" title="所用工具"></a>所用工具</h2><ul>
<li>Chrome 版本 72.0.3626.109（正式版本） （64 位）</li>
<li>Python 3.5.2 :: Anaconda 4.2.0 (64-bit)</li>
</ul>
<h2 id="数据采集"><a href="#数据采集" class="headerlink" title="数据采集"></a>数据采集</h2><h3 id="确定待采集数据"><a href="#确定待采集数据" class="headerlink" title="确定待采集数据"></a>确定待采集数据</h3><p>对评论所含内容进行简单的分析，初步确定所需要抓取的内容。首先，在京东商城手机信息界面的用户评价中含有昵称、会员等级、评价星级，评价内容、手机型号、购买时间等等。</p>
<p>其中通过分析会员等级与购买的关系，可以给为不同会员提供不同的产品做参考。分析评价内容可以大概可以推断出消费者对该产品的态度、以及哪些回复关注度比较高等等。分析购买时间可以了解到消费者集中的购买时间段。<strong>这些分析对商品广告的精准投放以及为消费者提供更个性化的服务提供了重要参考</strong>。 </p>
<h3 id="确定采集对象"><a href="#确定采集对象" class="headerlink" title="确定采集对象"></a>确定采集对象</h3><p>选择按评论数降序排列的手机型号，选择Apple iPhone 8 Plus(A1864) 64GB的评论数据进行采集</p>
<h3 id="采集准备"><a href="#采集准备" class="headerlink" title="采集准备"></a>采集准备</h3><p>（robots协议说明：robots是网站对爬虫的限定规则，它规定了那些爬虫可以爬，那些数据可以爬）</p>
<p>因此在采集之前，查看京东商城的robots协议，如下图</p>
<p><img src="/assets/1551319945219.png" alt="1551319945219"> </p>
<p>参考robots协议规则</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">User-agent: 指定对哪些爬虫生效</span><br><span class="line">Disallow: 指定不允许访问的网址</span><br><span class="line">Allow: 指定允许访问的网址</span><br></pre></td></tr></table></figure>
<p>通过分析robots协议的内容，而下面即将采集的目录在根目录的comment的子目录下，不涉及到用户的个人隐私，因此可以继续进行采集。</p>
<p>但是在采集过程中，添加sleep函数，既为了防止频繁访问ip被封，也防止高频度访问对网站带来的负荷。</p>
<h3 id="开始采集数据"><a href="#开始采集数据" class="headerlink" title="开始采集数据"></a>开始采集数据</h3><h4 id="分析网页"><a href="#分析网页" class="headerlink" title="分析网页"></a>分析网页</h4><p>首先选择一款评论数目多的手机，按照评论数降序排列</p>
<p><img src="/assets/1551163850458.png" alt="1551163850458"></p>
<p>点击进入手机信息页面，在默认手机参数选择下</p>
<p>按F12打开调试界面，打开network面板并在过滤器中填入“comment”，如下图<img src="/assets/1551164094744.png" alt="1551164094744"></p>
<p>此时，点击商品评价，筛选到如下结果</p>
<p><img src="/assets/1551164279099.png" alt="1551164279099"></p>
<p>含有pageComment字段的即为服务器返回的页面评论数据，右键该文件-&gt;copy-&gt;Copy link address复制url并在url地址栏进行访问。访问结果如下图</p>
<p><img src="/assets/1551164441005.png" alt="1551164441005"></p>
<p>可以很容易的看到，服务器返回给页面的数据是JSON格式的数据。</p>
<p>可以先使用<a href="http://www.bejson.com/jsoneditoronline/">JSON在线编辑器</a>进行json解析，在解析时发生错误，这是由于页面的数据的头部和尾部有一些其他的字符使得页面内容不完全是json数据，去掉第一个’(‘以及其之前的字符，同时去掉最后一个’)’以及其之后的字符即可。整理之后的结果如下图<img src="/assets/1551164892027.png" alt="1551164892027"> </p>
<p>从图中可以清楚的看到，评论共有100页，每页的comment有10条。单独点开其中一条评论数据如下图</p>
<p><img src="/assets/1551164975991.png" alt="1551164975991"> </p>
<p>可以清楚的看到我们所需要的数据。</p>
<p>那么新的问题来了，京东界面所写评论有163万+条，那其他的数据都去哪了？查看一下第100页后面，看有没有发现</p>
<p><img src="/assets/1551165225666.png" alt="1551165225666"> </p>
<p>看了之后才发现，还有114万+用户给了默认评价，为了分析更准确，加上这部分数据(其实点开也就100页，其他的可能服务器就没留着)。按照同样得方式，获取这部分评论的通用url<img src="/assets/1551165875856.png" alt="1551165875856"> </p>
<p>尽管如此，也才仅有1500条左右的数据，不过在评论的菜单中还有追评、好评、中评、差评等，把这些也算进来，对比比较差异</p>
<p><img src="/assets/1551167389012.png" alt="1551167389012"></p>
<p>发现不同评价的score不同，综合大约有4000~5000条数据</p>
<p>继续统计手机不同参数所含的评论。在这里我将手机颜色从“金色”改为了“深空灰色”，按照同样的方式查看url。并与之前获取的进行对比。如下图</p>
<p><img src="/assets/1551166489422.png" alt="1551166489422"></p>
<p>对比之后发现，不同颜色的产品ID(productid)发生了变化。但其实评论区域还是各种颜色都有，所以这也是手机评论数据，只不过为了美观，在每次更改手机参数选择时进行了刷新(动态生成)。</p>
<p>根据这些url参数，就可以尽可能多的爬取该款手机的评论数据，具体代码请移步<a href="https://github.com/YuleZhang/JDComment_Spider"><strong>JDComment_Spider</strong></a>，里面的SpiderScript是一个完整的京东评论爬虫脚本，并且采用了随机浏览器和延时访问来防止爬虫被封，为了获取完整的数据，加入了try…except防止程序中断崩溃。</p>
<h4 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h4><p>​    经过上面的分析，可以看到数据量非常有限，远远没有达到163万条。经分析，有以下两种可能：</p>
<ol>
<li>出现了数据造假，这个数字可能是刷出来的（机器或者水军）</li>
<li>真的有这么多的评论，但这时候系统可能只显示其中比较新的评论，而对比较旧的评论进行了存档。</li>
</ol>
<h3 id="拓展采集"><a href="#拓展采集" class="headerlink" title="拓展采集"></a>拓展采集</h3><p>通过采集之后发现京东的评论数据没有达到要求，于是到淘宝上看同款产品的评价进行搜集。</p>
<p><img src="/assets/1551336637383.png" alt="1551336637383"> </p>
<p>能找到包含json格式的评论数据，但是使用python进行访问时，却没有跳转到应该有的数据界面，而且跳到了其他界面，如下图</p>
<p><img src="/assets/1551336746478.png" alt="1551336746478"> </p>
<p>这意味着，没有登陆授权，无法查看评论信息(上面能看到评论信息，也是因为事先登陆过了)。因此只能采取selenium模拟浏览器行为来先登录，然后再获取这部分评论信息。</p>
<p>python+selenium+webdriver的探索及问题：</p>
<p>通过一系列的碰壁探索，发现selenium无法绕过淘宝登陆界面的验证，淘宝网应该是有识别自动化脚本登陆的反爬机制，根本无法获取登陆状态，无法登陆。</p>
<p>通过伪造请求头来获取淘宝数据：</p>
<p>登陆淘宝后，在淘宝主界面刷新，来获取登陆的cookies信息，如下图</p>
<p><img src="/assets/1552033319705.png" alt="1552033319705"></p>
<p>随后用这部分cookies来构造请求头，如下图所示</p>
<p><img src="/assets/1552033572299.png" alt="1552033572299"></p>
<p>这样，就能访问淘宝上需要登陆才能获取的页面信息，不过当你尝试就会发现，即使这样，在短时间连续访问多次，也很容易被检测到，从而限制页面的获取数量。我使用该爬虫在不同的时间段爬了六七次，每次requests到第17次就会出错了，有待完善。详细代码见<a href="https://github.com/YuleZhang/JDComment_Spider/blob/master/Taobao_Spider.ipynb">淘宝数据爬取</a> （预览不了的可以下载看）。</p>
<p>参考：</p>
<p><a href="https://www.cnblogs.com/whatisfantasy/p/6440585.html">搞定python多线程和多进程</a></p>
<p><a href="http://www.bejson.com/oldbejson/jsoneditoronline/">JSON在线编辑器</a> </p>
<p><a href="https://www.cnblogs.com/qun542110741/p/9221040.html">Python爬虫，抓取淘宝商品评论内容</a></p>
<p><a href="https://github.com/lining0806/PythonSpiderNotes">Python入门网络爬虫之精华版</a> </p>
<p><a href="https://www.cnblogs.com/taceywong/p/6602736.html">Selenium Python文档：四、元素定位</a> </p>
<p><a href="https://www.cnblogs.com/junrong624/p/5533655.html">为何大量网站不能抓取?爬虫突破封禁的6种常见方法</a>  </p>
<p><a href="https://blog.csdn.net/LaoChengZier/article/details/80705298">处理Jupyter Notebook报错：IOPub data rate exceeded</a></p>
]]></content>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>关于日记</title>
    <url>/2019/01/20/13Diary/</url>
    <content><![CDATA[<script src="/crypto-js.js"></script><script src="/mcommon.js"></script><h3 id="encrypt-message">Please enter the password to read the blog.</h3><link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap.min.css"> <link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap-theme.min.css"> <script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script> <script src="//cdn.bootcss.com/bootstrap/3.3.5/js/bootstrap.min.js"></script> <div id="security"> <div> <div class="input-group"> <input type="text" class="form-control" aria-label="Enter the password." id="pass"/> <div class="input-group-btn"> <button type="button" class="btn btn-default" onclick="decryptAES()">Decrypt</button> </div> </div> </div> </div> <div id="encrypt-blog" style="display:none"> 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 </div>]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>读书笔记——福尔摩斯思考术(2)</title>
    <url>/2019/01/20/14HolmesThinking/</url>
    <content><![CDATA[<p><img src="/images/HolmesThinking.jpg" alt="cover"><br><a id="more"></a></p>
<h4 id="福尔摩斯思考术（2）——如何形成深具洞察力及自我认知的思维模式"><a href="#福尔摩斯思考术（2）——如何形成深具洞察力及自我认知的思维模式" class="headerlink" title="福尔摩斯思考术（2）——如何形成深具洞察力及自我认知的思维模式"></a>福尔摩斯思考术（2）——如何形成深具洞察力及自我认知的思维模式</h4><p>每件事情不是只有继续和放弃两个选项，还可以选择“暂时放弃”</p>
<p>人生的岔路千千万万，走错一步太正常了，没必要在更窄的方案里做选择，当发现走的很难的时候，不如试试后退一步重新来过，或许就有新的解法。</p>
<p>做各种各样别的事情，能让我们有更大概率获取到相关的弱连接提示。(后台运行)</p>
<p>你永远不知道什么样的若连接可以触动正确解题的开关，你只能做到<strong>让尽可能多的弱连接进来</strong>。</p>
<p>把脑子里的单纯的抽象推理转化为视觉，就能让脑子有更多空余进程去思考别的事情。例如写题要把式子列出来一步步计算、福尔摩斯往往会在现场根据蛛丝马迹进行推理都是这个意思。</p>
<p>尤其是结论“好”的时候，我们尤其会让大脑放松在过程审视上的警惕性。会导致的后果是，无法分辨好的结恶果究竟是不是运气导致的，因此结果越好，反而越难以学到东西。</p>
<p>关于过程和结果举例：</p>
<ol>
<li>所有植物都需要水</li>
<li>玫瑰需要水</li>
<li>所以玫瑰是植物</li>
</ol>
<p>如果没有看出这个推理哪有问题，就说大脑关注结论太久，所以“玫瑰是植物”这个正确结论对他们有太大的影响。</p>
<p>换几个字之后</p>
<ol>
<li>所有动物都需要水</li>
<li>玫瑰需要水</li>
<li>所以玫瑰是动物</li>
</ol>
<p>一对比就知道问题，在第二个例子中，发现结果不对，才会去思考整个推理过程，而第一个例子，则往往让人们忽视其逻辑中的漏洞。</p>
<p>所以你会发现算命的除非能确定引发你的焦虑，让你掏钱消灾，否则通常之说好话，不是我们认不清，是我们不愿意认(不愿去思考过程)，因为如果他说了不好的呢？你就突然变“聪明”了， 开始会去抓他的逻辑漏洞了。</p>
<p><strong>大脑在推理时一直有一种倾向，就是试图抓住与之相关的所有信息，并尽可能将其合理化从而应用到自己的推理过程之中。</strong></p>
<p>思维训练导致的个人思维能力的提升本身就已经是一种回报，只是很难被感知力差的人量化而已。</p>
<p>衡量学习和实践性价比的“性”的一端最好的标不是能得到多少显而易见的收益，而是自身能力有多大程度的提高，这才是最大的隐形收益。</p>
<p>有些人总能在学习新鲜事物的时候得到多巴胺的反馈，因为进步的够快，因此这些人对新的东西就保持可一种习惯性渴望——潜意识告诉它们，又可以获得奖赏中枢分泌的奖赏物质了；而另一些人学东西相对较慢，他们的进度就会落后于别人。如此，它们就没有这种渴望。</p>
<p>值得一提的是：</p>
<ol>
<li>想坚持做一件事，就要尽快<strong>试图从中获取到多巴胺的奖励</strong>，慢了就没动力</li>
<li>坚持做1，能让自己<strong>对新事物保持旺盛的好奇心，从而获得更多的红利</strong>。</li>
</ol>
<p>我们曾经说过“分享是最好的学习”，大抵也是如此，尤其是当你要把一件事跟一些基础较弱的人讲明白时，你就不得不将那些原本显而易见的、自以为理所当然不需要思考的道理拉出来重新审视，在这个过程中，往往你会发现，其实那些最基础的概念你并没有全弄明白。</p>
<p><strong>挑战，是最大限度地激活我们思维的方式</strong></p>
<p>信息了解的多，一般情况下是只好不坏，最多就是无用，但由于他会影响到一个人的正常决策信息，因此如果是无用的话，反而就是累赘了，这会让一个一无所知的人对形式产生错判，从而进行非理性的下注。</p>
<p>有时候，我们的大脑会可以忘记自己在大多数情况下都很愚蠢的事实，只救助几次正确的不放，除此以外，大脑也很擅长将自己的推理往合理化的方向靠。此时，做笔记或记录的习惯会将自己的思维过程记录下来，来认清自己。</p>
<h4 id="自己的体会："><a href="#自己的体会：" class="headerlink" title="自己的体会："></a>自己的体会：</h4><p>在跟同学将程序的时候就发现，很多函数的参数自己也并不明白，完全是所见即所得，从网上找到的东西执行的通，就很少再去思考它的参数以及用法等等，这会让我忽视很多细节语法。然而在跟同学讲时，就发现了盲区。</p>
<p>然而对于这件事情，我却有自己的想法，尽管我不知道它是否客观。我觉得再程序这方面上，每个函数都有很多的参数，有各种各样的用法， 如果例子的用法就能满足我的当下需求，我就不需要再分散注意力去纠结那个东西，因为是否搞清它的所有用法对我当前追求的东西并没有联系。并且，这些东西在网上都可以轻易的获取到。我追求<strong>“所需即所得”</strong> ，即我在做项目或者东西时接触到需求，会让我选择性的了解项目的部分或者整体，界面或者原理等等。</p>
<p>并且在生活中，我也不是一个事无巨细的人，这就让我更难关注那些细节，那些基础的，不需要思考的东西，尽管我知道这是大脑在偷懒，不过我觉得它是该适当休息。不过在应对<strong>考试</strong>、<strong>比赛</strong>以及<strong>重大决策</strong>等事件上，我觉得应该还是遵循“<strong>分享是最好的学习</strong>”的原则，因为这些事件都需要细节、基础作为支撑。</p>
<hr>
]]></content>
      <tags>
        <tag>随笔</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机考研备考规划</title>
    <url>/2019/01/13/12CS-Preparation/</url>
    <content><![CDATA[<p><img src="/images/cs-preparation.jpg" alt="cover"><br><a id="more"></a></p>
<h2 id="院校选择"><a href="#院校选择" class="headerlink" title="院校选择"></a>院校选择</h2><h3 id="个人期望"><a href="#个人期望" class="headerlink" title="个人期望"></a>个人期望</h3><p>自己喜欢的方向或者专业方面，哪个学校的实力比较强，相关方向的老师比较多</p>
<h3 id="地域"><a href="#地域" class="headerlink" title="地域"></a>地域</h3><p>不同的地域在就业时会有不同的优势</p>
<p>在大城市接触到的人脉资源会很有用，但相应考试难度会相对较大</p>
<h3 id="考试难度"><a href="#考试难度" class="headerlink" title="考试难度"></a>考试难度</h3><p>统考</p>
<p>专业课</p>
<h3 id="准备知识"><a href="#准备知识" class="headerlink" title="准备知识"></a>准备知识</h3><ol>
<li>招生简章</li>
<li>保研名单</li>
<li>夏令营名单</li>
<li>录取名单</li>
</ol>
<p>通过集中的分析，对比不同学校的考试难度和自身的水平，认真理性的选择学校</p>
<h3 id="院校排名"><a href="#院校排名" class="headerlink" title="院校排名"></a>院校排名</h3><p>这个不是很重要</p>
<h3 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h3><p>学校歧视</p>
<p>这个问题不用担心，只要你初试成绩够，可以有不同的情况，可以在校绩点高一些，可以有很多小项目，即使跨考也不用担心。</p>
<p>选好大方向：人工智能还是网络，具体做什么跟导师有关    。</p>
<p>关于调剂</p>
<p>985院校不接受外校调剂，因此优先考虑该学校的其他相关专业。</p>
<h2 id="复习计划"><a href="#复习计划" class="headerlink" title="复习计划"></a>复习计划</h2><p><img src="/assets/复习计划-1547368635395.png" alt="复习计划"></p>
<p><img src="/assets/复习建议-1547368635395.png" alt="复习建议"></p>
<p>英语：注重阅读</p>
<p>政治：不同的科目对症下药，一定给时间给非主观题。</p>
<p>专业课：把基础打好，王道的复习书，如果是自主命题，早点开始复习把基础打好。必须做的几类题：</p>
<ol>
<li><p>历年真题。</p>
</li>
<li><p>买一些本科或研究生期末测试题。</p>
</li>
</ol>
<p><img src="/assets/1547368876265.png" alt="1547368876265"> </p>
<p>一定不要影响大的安排计划，养成一个固定的习惯。</p>
<p><img src="/assets/1547369569475.png" alt="1547369569475"> </p>
<p>第一轮以教材为主、第二轮慢慢以王道书为主，结合教程，多练习</p>
<p>每月有个大的计划，最后再进行细化到每天。</p>
]]></content>
      <tags>
        <tag>随笔</tag>
        <tag>考研</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络学习笔记</title>
    <url>/2018/11/18/11Computer-Neterwork/</url>
    <content><![CDATA[<p><img src="/images/network-note.jpg" alt="network-note"></p>
<a id="more"></a>
<h2 id="第一章-计算机网络概述"><a href="#第一章-计算机网络概述" class="headerlink" title="第一章 计算机网络概述"></a>第一章 计算机网络概述</h2><p><strong>局域网</strong> 覆盖范围小 自己花钱购买设备 宽带固定 自己维护<br><strong>Internet</strong> ISP  有自己的机房  对网民提供访问Internet连接<br><strong>广域网</strong> 距离较远 花钱买带宽、租服务 不用自己维护</p>
<p><img src="/assets/1542502423577.png" alt="1542502423577"> </p>
<h3 id="1-1数据包和数据帧"><a href="#1-1数据包和数据帧" class="headerlink" title="1.1数据包和数据帧"></a>1.1数据包和数据帧</h3><p><img src="/assets/1542503369329.png" alt="1542503369329"><br>​                                                          url解析过程实例</p>
<p>数据修改mac地址，一步一步转到目标ip<br>每台路由器的路由表中都记录有连接到同一台交换机的不同主机的ip、mac地址等等，在数据帧从源主机发送过程中，其包含的mac当前地址和下一跳地址会不断修改，在到达不同的路由时，路由器能够根据目标ip所在网段来给数据包指定mac地址，最终实现与目标主机的交互。</p>
<h3 id="1-2OSI参考模型"><a href="#1-2OSI参考模型" class="headerlink" title="1.2OSI参考模型"></a>1.2OSI参考模型</h3><p><strong>应用层</strong>  所有能产生网络流量的程序<br><strong>表示层</strong>  在传输之前是否进行加密 或 压缩处理  二进制 ASCII<br>表示层错误举例:</p>
<p><img src="/assets/1542504269207.png" alt="1542504269207"> </p>
<p>在更改语言之后，会看到网页出现乱码，这就是出现了表示层问题。服务器发送过来的编码格式与我当前网页的解码格式不一致，就会导致网页乱码问题。</p>
<p><strong>会话层</strong> 查看木马</p>
<p>cmd中使用<code>netstat -n</code>命令查看当前会话<br><code>netstat -nb</code>能够看到建立会话的程序，一下就能找出来木马。</p>
<p><strong>传输层</strong> 可靠传输 流量控制 不可靠传输</p>
<p>主机访问DNS服务器，只需要一个包就够了，不需要建立会话，这种类型称为不可靠传输。<br>qq聊天时也是使用的不可靠传输</p>
<p><strong>网络层</strong> 负责选择最佳路径 规划ip地址</p>
<p><strong>数据链路层</strong> 定义了帧的开始和结束     透明传输      差错校验(不纠正)</p>
<p><strong>物理层</strong> 接口标准   电器标准    如何在物理链路层传输更快的速度</p>
<p>每一层较为独立，每一层的变化不会影响其他层，从物理层到应用层，每一层都为上一层提供服务。</p>
<h3 id="1-3OSI参考模型和网络排错"><a href="#1-3OSI参考模型和网络排错" class="headerlink" title="1.3OSI参考模型和网络排错"></a>1.3OSI参考模型和网络排错</h3><ol>
<li>物理层故障   查看连接状态   发送和接收的数据包</li>
<li>数据链路层故障   MAC地址冲突   ADSL欠费    网速协商一致   计算机连接到错误的VLAN</li>
<li>网络层故障   配置了错误的ip地址   子网掩码   配置错误网关    路由器没有配置到达目标网络的路由</li>
<li>应用层故障    应用程序配置错误</li>
</ol>
<h3 id="1-4OSI参考模型和网络安全"><a href="#1-4OSI参考模型和网络安全" class="headerlink" title="1.4OSI参考模型和网络安全"></a>1.4OSI参考模型和网络安全</h3><ol>
<li>物理层安全    外面的网线接到内部交换机</li>
<li>数据链路层安全   ADSL账号密码    VLAN   交换机端口绑定MAC地址</li>
<li>网络层安全    在路由器上使用ACL控制数据流量包</li>
<li>应用层安全    开发的应用程序没有漏洞</li>
</ol>
<h3 id="1-5TCP-IP协议和OSI参考模型"><a href="#1-5TCP-IP协议和OSI参考模型" class="headerlink" title="1.5TCP/IP协议和OSI参考模型"></a>1.5TCP/IP协议和OSI参考模型</h3><p><img src="/assets/1542510257412.png" alt="1542510257412"> </p>
<p><img src="/assets/1542510441573.png" alt="1542510441573"> </p>
<p>FCS为校验核</p>
<p><img src="/assets/1542510552860.png" alt="1542510552860"> </p>
<h2 id="第二章物理层"><a href="#第二章物理层" class="headerlink" title="第二章物理层"></a>第二章物理层</h2><h3 id="2-1物理层基本概念"><a href="#2-1物理层基本概念" class="headerlink" title="2.1物理层基本概念"></a>2.1物理层基本概念</h3><ol>
<li>机械特性</li>
<li>电气特性</li>
<li>功能特性</li>
<li>过程特性</li>
</ol>
<h3 id="2-2数据通信的基础知识"><a href="#2-2数据通信的基础知识" class="headerlink" title="2.2数据通信的基础知识"></a>2.2数据通信的基础知识</h3><p><img src="/assets/1543143563956.png" alt="1543143563956"> </p>
<p>信道一般表示向一个方向传送信息的媒体。所以平常的通信线路往往包含一条发送信息的信道和一条接收信息的信道</p>
<h4 id="信道"><a href="#信道" class="headerlink" title="信道"></a>信道</h4><p><strong>单向通信</strong> 只能由一个方向的通信而没有反方向的交互</p>
<p><strong>双向交替通信</strong> （半双工通信）通信的双方都可以发送信息，但不能双方同时发送</p>
<p><strong>双向同时通信</strong> （全双工通信）通信的双方可以同时发送和接收信息。例：打电话</p>
<h4 id="基带信号和带通信号"><a href="#基带信号和带通信号" class="headerlink" title="基带信号和带通信号"></a>基带信号和带通信号</h4><p><strong>基带信号</strong> 像计算机输出的代表各种文字或图像的数据信号都属于基带信号。它直接表达了要传输的信息的信号，比如说话的声音也是基带信号。</p>
<p><strong>带通信号</strong> 把基带信号经过载波调制后，把信号的频率范围搬移到较高的频段以便再信道中传输。</p>
<p>因此，距离近用基带信号，如从计算机到监视器、打印机等外设的信号都是基带传输。</p>
<h4 id="调制方法"><a href="#调制方法" class="headerlink" title="调制方法"></a>调制方法</h4><p>调幅    调频    调相</p>
<h4 id="常用编码"><a href="#常用编码" class="headerlink" title="常用编码"></a>常用编码</h4><p>单极性不归零   双极性不归零   单极性归零码   双极性归零码   曼彻斯特编码</p>
<p><img src="/assets/1543146978208.png" alt="1543146978208"> </p>
<h4 id="信道的极限容量"><a href="#信道的极限容量" class="headerlink" title="信道的极限容量"></a>信道的极限容量</h4><p>香奈法则：没有信号干扰的情况下，码元的传输速率有上限</p>
<p><img src="/assets/1543147043150.png" alt="1543147043150"> </p>
<p>香农公式：有信号干扰   无差错传输速率，S/N为信噪比</p>
<p><img src="/assets/1543147112449.png" alt="1543147112449"> </p>
<h3 id="2-3物理层下面的传输媒体"><a href="#2-3物理层下面的传输媒体" class="headerlink" title="2.3物理层下面的传输媒体"></a>2.3物理层下面的传输媒体</h3><p>光纤的分类及工作原理。</p>
<p><img src="/assets/1543148711827.png" alt="1543148711827"> <img src="/assets/1543149062538.png" alt="1543149062538"></p>
<h3 id="2-4信道复用技术"><a href="#2-4信道复用技术" class="headerlink" title="2.4信道复用技术"></a>2.4信道复用技术</h3><p><strong>1.频分复用FDM（Frequency Division Multiplexing）</strong></p>
<p><img src="/assets/1543149527457.png" alt="1543149527457"></p>
<p><img src="/assets/1543149501357.png" alt="1543149501357"> 电话通信中的频分复用技术，通过一级一级的汇总，最终能产生更多的语音信号。</p>
<p><img src="/assets/1543149577579.png" alt="1543149577579"> <strong>2.时分复用 （Time Division Multiplexing）</strong></p>
<p>线路上的数据按照一定的顺序来发送数据</p>
<p><img src="/assets/1543149772049.png" alt="1543149685293"> 可能会造成资源浪费，如下图</p>
<p><img src="/assets/1543149905181.png" alt="1543149905181"> <strong>3.统计时分复用</strong></p>
<p>发的时候没有规律，凑够一个帧就发，但在内容上加上标记 </p>
<p><img src="/assets/1543149926590.png" alt="1543149926590"> <strong>4.波分复用WDM（Wavelength Division Multiplexing）</strong> </p>
<p><img src="/assets/1543150024141.png" alt="1543150024141"> </p>
<h3 id="2-5数字传输系统"><a href="#2-5数字传输系统" class="headerlink" title="2.5数字传输系统"></a>2.5数字传输系统</h3><p>脉码调制PCM也就是我们所说的广域网，已经提前铺设好了，这样在两个相距较远的局域网直接通信时，可以通过两个局域网的路由器接到广域网中，实现远距离通信。</p>
<p>PCM有两个互不兼容的国际标准，即北美的24路PCM（简称T1）和欧洲的30路PCM（简称E1）采用时分复用，我国采用E1标准。</p>
<p><img src="/assets/1543150295488.png" alt="1543150295488"> </p>
<h3 id="2-6宽带接入技术"><a href="#2-6宽带接入技术" class="headerlink" title="2.6宽带接入技术"></a>2.6宽带接入技术</h3><p>ADSL（用数字技术对现有的模拟电话用户线进行改造）</p>
<p>使用DMT技术，将频率主要分为三个部分，一部分用传统电话，一部分用于上行信道（向服务器请求数据），一部分用于下行信道（从服务器下载数据），下行信道最多，其特性是流量非对称。</p>
<p><img src="/assets/1543151033236.png" alt="1543151033236"> </p>
<p><img src="/assets/1543151225030.png" alt="1543151225030"> </p>
<h2 id="第三章-数据链路层"><a href="#第三章-数据链路层" class="headerlink" title="第三章 数据链路层"></a>第三章 数据链路层</h2><h3 id="3-1数据链路层基本概念"><a href="#3-1数据链路层基本概念" class="headerlink" title="3.1数据链路层基本概念"></a>3.1数据链路层基本概念</h3><p>下图是数据链路层的简单模型</p>
<p>应用层准备数据—&gt;运输层将其分段—&gt;网络层加ip地址—&gt;链路层加数据帧头帧尾<br>到了物理层之后，如何频分多路复用、时分多路复用等等、充分利用线路带宽，这是上面物理层已经解决的问题。 </p>
<p><img src="/assets/1543715662916.png" alt="1543715662916"> </p>
<p>数据链路层不关心物理层速度，不关心是模拟信号还是数字信号，不关心是光纤、铜线，带宽是1M还是10M。</p>
<p>数据链路层在上图中的作用概述起来是这样的：</p>
<p>物理层将数据传到数据链路层之后，数据链路层判断是否数据出错，如果数据正确，拆掉帧头帧尾，传到路由器的网络层，网络层根据ip地址选择路径，决定从路由器的哪个出口出去。随后再传到数据链路层，数据链路层修改MAC地址等信息，加上帧头帧尾，最后发给物理层进行传输。</p>
<p><strong>数据链路层的信道类型</strong></p>
<p>点对点信道：使用一对一的点对点通信方式</p>
<p>广播信道：使用一对多的广播通信方式，过程较复杂。广播信道上的主机数目多，必须使用专用的共享信道协议来协调这些主机的数据发送。</p>
<p><strong>链路与数据链路</strong></p>
<p>链路：点到点的物理线路段，中间没有其他任何的交换结点</p>
<p>数据链路：除了物理线路，还有通信协议控制数据的传输。</p>
<p><strong>帧</strong></p>
<p>把网络层信息加上帧头帧尾，加上物理层地址，加上校验值</p>
<p><img src="/assets/1543716980510.png" alt="1543716980510"> </p>
<h3 id="3-2数据链路层解决的三个基本问题"><a href="#3-2数据链路层解决的三个基本问题" class="headerlink" title="3.2数据链路层解决的三个基本问题"></a>3.2数据链路层解决的三个基本问题</h3><h4 id="1-封装成帧"><a href="#1-封装成帧" class="headerlink" title="1. 封装成帧"></a>1. 封装成帧</h4><p><img src="/assets/1543717172357.png" alt="1543717172357"> </p>
<h4 id="2-透明传输"><a href="#2-透明传输" class="headerlink" title="2. 透明传输"></a>2. 透明传输</h4><p>在数据段中出现了与帧头帧尾同样的二进制串，会造成误判。</p>
<p><img src="/assets/1543717298498.png" alt="1543717298498"> </p>
<p>ESC相当于转义字符，在收到数据之后去掉这些标识，跟没加一样。</p>
<h4 id="3-差错控制"><a href="#3-差错控制" class="headerlink" title="3. 差错控制"></a>3. 差错控制</h4><p>针对传输过程中可能发生的比特差错，不纠错，有错误就丢，没错误就发。</p>
<p>加上额外的帧检验序列CRC（循环冗余检验）。</p>
<p>CRC的计算过程如下图，除数是随机选取的一个值，在被除数后要补上比除数位数少一位数目的0，在下面例子中就是4位除数，补3个0.。之后在计算时，进行的不是减法，而是做异或运算，最终求出循环冗余码001</p>
<p><img src="/assets/1543718500043.png" alt="1543718500043"></p>
<p>在数据链路层收到这样的数据时，再进行除法的异或运算，但此时被除数后补上的不再是000，而是之前求出来并发送过来的CRC（001），判断最终余数是否为0即可确定数据是否发生了错误。</p>
<p><strong>帧检验序列FCS</strong></p>
<p>CRC是一种常用的检错方法，而FCS时添加在数据后面的冗余码</p>
<p>FCS可以用CRC方法的出，也可以用其他检验方法得出</p>
<p><img src="/assets/1543718652258.png" alt="1543718652258"></p>
<h3 id="3-3两种情况下的数据链路层"><a href="#3-3两种情况下的数据链路层" class="headerlink" title="3.3两种情况下的数据链路层"></a>3.3两种情况下的数据链路层</h3><h4 id="使用点对点信道的数据链路层-PPP"><a href="#使用点对点信道的数据链路层-PPP" class="headerlink" title="使用点对点信道的数据链路层 PPP"></a>使用点对点信道的数据链路层 PPP</h4><p>广域网使用PPP协议，通常用在用户拨号接入因特网，全世界使用最多的协议</p>
<p><img src="/assets/1543719271035.png" alt="1543719271035"> </p>
<p><img src="/assets/1543719458006.png" alt="1543719458006"> </p>
<p>PPP协议的透明传输：转义法、零比特填充法（只要发现5个连续1，就立即填入一个0）</p>
<h4 id="使用广播信道的数据链路层"><a href="#使用广播信道的数据链路层" class="headerlink" title="使用广播信道的数据链路层"></a>使用广播信道的数据链路层</h4><p>局域网  使用广播信道的数据链路层  什么协议？</p>
<p>下图中是总线型连接的拓扑结构，数据包发送到各个主机，主机判断目的MAC地址不是本机MAC地址后自动丢弃，是本机MAC地址则接受，当然也可以通过抓包工具捕获到这些数据包，因此说这种网络是不安全的。</p>
<p><img src="/assets/1543720760948.png" alt="1543720760948"> </p>
<p>当然，这样的方式也使得广播特性的总线实现了一对一的通信。</p>
<p>使用CSMA/CS（载波监听多点接入/碰撞检测）协议</p>
<p>多点接入：表示许多计算机以多点接入的方式连接在一根总线上</p>
<p>载波监听：就是用电子技术检测总线上有没有其他计算机发送的数据信号以免发生碰撞。</p>
]]></content>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP/IP协议数据包分析</title>
    <url>/2018/11/17/10Network-Package-Capture/</url>
    <content><![CDATA[<p><img src="/images/network.jpg" alt="cover"></p>
<a id="more"></a>
<h3 id="Wireshark抓包实验"><a href="#Wireshark抓包实验" class="headerlink" title="Wireshark抓包实验"></a><strong>Wireshark抓包实验</strong></h3><p><strong>1.1</strong>  <strong>学习Wireshark工具的基本操作</strong></p>
<p>学习捕获选项的设置和使用，如考虑源主机和目的主机，正确设置 Capture Filter；捕获后设置 Display Filter。</p>
<p><strong>1.2</strong>  <strong>PING</strong>命令的网络包捕获分析</p>
<p>PING命令是基于ICMP协议而工作的，发送4个包，正常返回四个包。以主机210.31.40.41为例，主要实验步骤为：</p>
<p>（1）设置“捕获过滤”：在 Capture Filter 中填写 host 210.31.40.41；</p>
<p>（2）开始抓包；</p>
<p>（3）在 DOS 下执行 PING 命令；</p>
<p>（4）停止抓包。</p>
<p>（5）设置“显示过滤”: IP.Addr=210.31.40.41</p>
<p><img src="/assets/clip_image002.jpg" alt="img"></p>
<p>（6）选择某数据包，重点分析其协议部分，特别是协议首部内容，点开所有带+号的内容。</p>
<p>（7）针对重要内容截屏，并解析协议字段中的内容，一并写入 WORD 文档中。</p>
<p><img src="/assets/1542435725203.png" alt="1542435715945"></p>
<p>​       通过简单的分析我们可以看到，Ping命令使用ICMP协议，每发送一个包到210.31.40.41后都会收到一个包，一共发送了四个包，收到四个包如所示。分析其中的一个包，可以看到其类型长度为8，数据长度为32byte，见图</p>
<p><strong>1.3</strong>  <strong>TRACERT</strong> <strong>命令数据捕获</strong></p>
<p>观察路由跳步过程。分别自行选择校内外 2 个目标主机。比如，</p>
<p>（1）校内：tracert    210.31.32.8</p>
<p>首先，在执行tracert命令之前，先在Wireshark中过滤选择出210.31.32.8的相关请求。之后，win+r打开cmd界面执行tracert命令</p>
<p><img src="/assets/clip_image005.png" alt="img"></p>
<p>​       截获到的数据如下图，</p>
<p><img src="/assets/clip_image007.jpg" alt="img"></p>
<p>通过对该抓包结果的简单分析，可以看出，抓到的协议类型主要有两种即ICMP和DNS协议，选择不同类型的协议来查看其具体内容。</p>
<p>DNS协议：</p>
<p><img src="/assets/clip_image009.jpg" alt="img"></p>
<p>通过上图简单的分析查看可以得知，DNS协议从10.10.215.246到210.31.32.8，同时包含了UDP协议，源端口为61149，目标端口为53。DNS对域名210.31.40.41进行了84次标准查询，可以看到在DNS的事务ID为：0xc39f，在DNS服务器中的查询结果在第185行。</p>
<p>ICMP协议：</p>
<p><img src="/assets/clip_image011.jpg" alt="img"></p>
<p>ICMP的内容在之前已经分析过了，在这里不在赘述，从图中对比可以看到，data的数据长度变为了64bytes。</p>
<p>（2）校外：tracert    <a href="http://www.sogou.com">www.sogou.com</a></p>
<p><img src="/assets/clip_image013.jpg" alt="img"></p>
<p><img src="/assets/clip_image015.jpg" alt="img"></p>
<p>​       通过简单的分析可以看出，在对搜狗进行抓包时出现了两种协议即ICMP和NBNS协议，其中NBNS协议是 TCP/IP 上的 NetBIOS (NetBT) 协议族的一部分，它在基于 NetBIOS 名称访问的网络上提供<a href="https://baike.baidu.com/item/%E4%B8%BB%E6%9C%BA%E5%90%8D/2836107">主机名</a>和<a href="https://baike.baidu.com/item/%E5%9C%B0%E5%9D%80%E6%98%A0%E5%B0%84/7205014">地址映射</a>方法。</p>
<p><img src="/assets/clip_image017.jpg" alt="img"></p>
<p><strong>1.4</strong>  <strong>端口扫描数据捕获与分析</strong></p>
<p>（1）各组自行下载和安装某个端口扫描工具，比如 NMAP、SUPERSCAN、SCANPORT、</p>
<p>SSPORT、TCPVIEW。</p>
<p>（2）扫描对方的主机，获得开放的端口号。捕获其所有相关信息和协议内容。显示过滤举例：</p>
<p>在这里，使用Zenmap对本机进行端口扫描，扫描结果如下图。</p>
<p><img src="/assets/clip_image019.jpg" alt="img"></p>
<p>可以看到，本机开放了6个端口，不同端口提供不同的服务，可以看到其中的80端口为Http服务，说明在本机上部署了自己的网站，用80作为端口。</p>
<p>查看Wireshark对该端口的抓包情况</p>
<p><img src="/assets/clip_image021.jpg" alt="img"></p>
<p>从图中看到两种协议，TCP和HTTP，这也印证了我之前部署网站的说法。</p>
<p>（3）关闭某一开放的端口，重新扫描，观察捕获效果。</p>
<p><img src="/assets/1542500979517.png" alt="1542500979517"></p>
<p>​       关闭端口后进行扫描，可以看到被关闭的端口扫描不到了。</p>
<p><strong>1.5</strong>  <strong>FTP</strong> <strong>协议包捕获与分析</strong></p>
<p>登录FTP 服务器：<a href="ftp://ftp.scene.org">ftp.scene.org</a>，重点捕获其 3 个关键过程：</p>
<p>（1）FTP 服务器的登录</p>
<p>捕获 USER 和 PWD 的内容，分析 FTP、TCP、IP 协议的首部信息。FTP 服务器的端口号为 21，用于控制连接。</p>
<p><img src="/assets/clip_image025.jpg" alt="img"></p>
<p>在这里使用的是filezilla登陆的FTP服务器，通过对登陆过程的捕获可以看到，登陆的账号为anonymous，密码为<a href="mailto:anonymous@example.com">anonymous@example.com</a>（默认）。</p>
<p>用Wireshark查看FTP、TCP、IP协议的首部信息，如下图。</p>
<p><img src="/assets/clip_image027.jpg" alt="img"></p>
<p>（2）FTP 文件的下载过程</p>
<p>要求分别下载三个大小不同的文件（小于 1MB、1MB—10MB、10MB 以上），观察 FTP、TCP 和 IP 协议中的数据分片过程。</p>
<p><img src="/assets/clip_image029.jpg" alt="img"></p>
<p>从图5-3中可以简单看出，下载文件的请求命令为”RETA ”，文件字节大小也不一样。</p>
<p>从发送时间也可以看出来一些差别。介于1MB—10MB的文件可能由于其格式或其他原因，没有正常显示出包的大小和传输时间。不过，通过对比不同的大小的文件，可以得出文件越大TCP切片长度越小，传输的字节越多，所用的传输时间越长。</p>
<p>（3）FTP 服务的退出过程</p>
<p>分析 FTP、TCP、IP 协议的不同内容。</p>
<p>FTP的退出过程在Wireshark的抓包过程中没有捕获到。</p>
<p><strong>1.6</strong>  <strong>HTTP</strong> <strong>协议包的捕获与分析</strong></p>
<p>登录到国内外的一些门户网站上，将主页浏览过程捕获下来，分析其 HTTP、TCP、UDP、</p>
<p>IP 协议的内容。注意 TCP 协议中的端口号。</p>
<p>补充一下HTTP的工作流程：</p>
<p>（1）    客户端通过TCP三次握手与服务器建立连接。</p>
<p>（2）    TCP建立连接成功后，向服务器发送http请求</p>
<p>（3）    服务器收到客户端的http请求后，将返回应答，并向客户端发送数据。</p>
<p>（4）    客户端通过TCP四次握手，与服务器断开TCP连接。</p>
<p>国内网站：</p>
<p>国内这里以京东商城为列jd.com（111.13.28.118），捕获主页浏览过程，抓包结果如图。从图中可以看出，No分别为1950、1951、1958时进行了TCP三次握手，此时使用的是TCP协议的80端口。（说明：Wireshark抓包仅限于http，对于https其无法解密识别，国内大部分网站主页都是http，只有在登陆界面或者少数主页是https加密，不过为了掩盖性，大部分网站的头部都以https开头，尽管他们没有发挥任何作用。）</p>
<p><img src="/assets/clip_image031.jpg" alt="img"></p>
<p><img src="/assets/clip_image033.jpg" alt="img"></p>
<p>从包的数据中可以分析得出(见图6-2)，本机地址10.10.215.246，捕获端口为19651。目标地址为111.13.28.118，开放端口为80，TCP协议数据切片长度为382。在看看HTTP协议，其中http请求头为Mozilla/5.0（Windows NT 10.0；Win64; X64）…以及它的接受语言为中文等等，是正常访问url时向服务器发送的一些数据信息。</p>
<p><strong>1.7</strong>  <strong>EMAIL</strong> <strong>协议包的捕获与分析</strong></p>
<p>登录到校内外的邮件系统，捕获自己的登录信息，重点分析其 SMTP、POP3 协议的内容。注意其端口号分别是 25 和 110。</p>
<p>国内外大部分邮箱采用ssl加密，即https协议，其中http常用端口为80，https常用端口号为443。下面我使用的是foxmail客户端来进行EMAIL协议包的捕获，捕获内容如下图</p>
<p><img src="/assets/clip_image035.jpg" alt="img"></p>
<p>在Protocol列中可以看到显示的协议有TCP和SMTP。由于SMTP是基于TCP协议的，所以在使用SMTP协议发送邮件之前，首先要通过TCP三次握手建立连接。从图中倒数第三个SMTP包的后面可以看到我发送邮件的邮箱账号。第75帧表示成功登陆邮箱，第78帧表示发送邮件的账户，本例中是<a href="mailto:yulezhang321@qq.com">yulezhang321@qq.com</a>。第81帧表示接受邮件的账户，本例中是<a href="mailto:2592879772@qq.com">2592879772@qq.com</a>。第83帧是客户端发送的内容，84帧使用<CR><LF>接收了文本的内容。</p>
<p><img src="/assets/clip_image037.jpg" alt="img"></p>
<p>该界面较为清晰的展示了邮件信息（右键一个SMTP包，选择follow-&gt;TCP Stream查看），红色部分为客户端发送的信息，蓝色部分是服务器相应信息。在该界面可以看到客户端的主机名、邮件账户、使用的邮件客户端、邮件内容类型和传输格式等等。也可以看见发送的信息内容，由于内容被转换为base64位格式的信息，进行了加密。</p>
<h2 id="四、-思考题"><a href="#四、-思考题" class="headerlink" title="四、 思考题"></a>四、 思考题</h2><p>（1）在 FTP 服务中，FTP 数据长度为什么是 1460 字节？</p>
<p>最大传输单元是1460字节是TCP层的报文段(segment)的长度限制。</p>
<p>（2）如何捕获 FTP 服务的结束数据包？</p>
<p>在过滤器中输入ftp，会看到在Information信息列中出现Request：QUIT的内容，表示为ftp的结束包</p>
<p>（3）在端口扫描中，对应的协议有 TCP 和 UDP。应该如何查找某端口对应的服务类型？</p>
<p>在cmd命令行中使用netstat -a -n命令查看。 </p>
<p>（4）不指定 IP 地址时，为什么有的邻近主机捕获不到？</p>
<p>每个信息包能够通过网络不同的路径发送，信息包能按照与它们发送时的不同顺序到达。网络协议（IP）仅仅是递送他们，TCP才是能够将它们按照正确顺序组合回原样。IP是一个无连接协议，这就意味着在通信的终点之间没有连续的线路连接。这就导致了会有一些主机捕获不到信息。</p>
<p>（5）PING 命令操作时，为什么会捕获 ARP 协议的数据包？</p>
<p>因为ARP协议是“Address Resolution Protocol” 的缩写。在局域网中，网络中实际传输的是帧，帧里面是有目标主机的MAC地址的。ARP协议的基本功能就是通过目标设备的IP地址，查询目标设备的MAC地址以保证通信的顺利进行。</p>
<p>参考文章：</p>
<p><a href="https://jingyan.baidu.com/article/d621e8da0abd192865913f1f.html">如何关闭139端口及445端口等危险端口</a></p>
<p><a href="https://segmentfault.com/a/1190000006199237">聊一聊HTTPS那些事</a></p>
<p><a href="https://blog.csdn.net/lalalahaitang/article/details/81119336">TCP协议(1)–TCP首部</a></p>
<p><a href="https://blog.csdn.net/wojiaopanpan/article/details/69944970">wireshark过滤规则及使用方法</a></p>
<p><a href="https://jingyan.baidu.com/article/c35dbcb0866b698916fcbc81.html">wireshark抓包教程</a></p>
<p><a href="https://www.cnblogs.com/superdo/p/4712787.html">电子邮件抓包分析</a></p>
]]></content>
      <tags>
        <tag>Wireshark</tag>
      </tags>
  </entry>
  <entry>
    <title>局域网通信</title>
    <url>/2018/10/21/09LAN-Communicate/</url>
    <content><![CDATA[<p><img src="/images/communication.jpg" alt="cover"></p>
<a id="more"></a>
<h3 id="主机相互发送消息"><a href="#主机相互发送消息" class="headerlink" title="主机相互发送消息"></a>主机相互发送消息</h3><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>本学期的计算机网络课非常有意思，它与我们的生活息息相关，曾经我也为电脑发生的网络问题而困惑，总是没有根据的瞎尝试来试图解决问题。但是在老师的一些简单指导之后，有了一个基本的ip之间通信以及局域网的概念。于是就想，既然局域网内部不用通过路由器就能发送数据，那我就可以给同学的电脑发消息了呀，带着这样的兴趣，我开始了本次尝试。</p>
<h4 id="发送消息"><a href="#发送消息" class="headerlink" title="发送消息"></a>发送消息</h4><ol>
<li>关掉发送消息电脑及接受电脑360安全卫士等杀毒软件</li>
<li>关掉两电脑域防火墙、专用网络防火墙、公用网络防火墙等，如图1</li>
</ol>
<p><img src="/assets/1540101899894.png" alt="1540101899894"></p>
<ol start="3">
<li>打开控制面板-&gt;凭据管理器-&gt;Windows凭据<br> 单击添加Windows凭据，输入要连接的ip以及用户名密码（每台主机可以同时拥有多个用户，尽量不要用Adminsitrator用户）<br><img src="/assets/1540102133297.png" alt="1540102133297"></li>
<li>添加之后，点击确定即可。同时按住win+r打开运行界面，输入cmd后回车</li>
<li>在cmd命令行中输入<code>msg server:(ip) * &quot;消息内容&quot;</code>如下图所示<br><img src="/assets/1540102455111.png" alt="1540102455111"></li>
<li>目标电脑收到所发送的消息，如图<br><img src="/assets/1540102669781.png" alt="1540102669781"><h4 id="可能存在的一些问题"><a href="#可能存在的一些问题" class="headerlink" title="可能存在的一些问题"></a>可能存在的一些问题</h4><h5 id="获取会话名称时的错误1722"><a href="#获取会话名称时的错误1722" class="headerlink" title="获取会话名称时的错误1722"></a>获取会话名称时的错误1722</h5></li>
</ol>
<p>这种情况说明RPC服务器不可用，win+r运行regedit.exe，找到”计算机\HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Terminal Server”把AllowRemoteRPC的值从0改为1就能接受信息了。</p>
<h5 id="获取会话名称时的错误5"><a href="#获取会话名称时的错误5" class="headerlink" title="获取会话名称时的错误5"></a>获取会话名称时的错误5</h5><p>尝试以管理员身份运行cmd，或者就是没有添加用户凭据，或者是用户凭据添加出错了，重新添加一下用户凭据</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol>
<li><a href="https://www.cnblogs.com/mq0036/p/3574555.html">MSG命令使用详解</a></li>
<li><a href="http://codewa.com/question/70756.html">错误：1722获取会话名称l</a></li>
<li><a href="https://blog.csdn.net/qq_24264221/article/details/70980123">错误：5获取会话名称</a></li>
</ol>
]]></content>
      <tags>
        <tag>局域网通信</tag>
      </tags>
  </entry>
  <entry>
    <title>以梦为马，不负韶华</title>
    <url>/2018/10/08/07College-Process-Of-Thought/</url>
    <content><![CDATA[<script src="/crypto-js.js"></script><script src="/mcommon.js"></script><h3 id="encrypt-message">Please enter the password to read the blog.</h3><link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap.min.css"> <link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap-theme.min.css"> <script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script> <script src="//cdn.bootcss.com/bootstrap/3.3.5/js/bootstrap.min.js"></script> <div id="security"> <div> <div class="input-group"> <input type="text" class="form-control" aria-label="Enter the password." id="pass"/> <div class="input-group-btn"> <button type="button" class="btn btn-default" onclick="decryptAES()">Decrypt</button> </div> </div> </div> </div> <div id="encrypt-blog" style="display:none"> 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 </div>]]></content>
      <tags>
        <tag>随笔</tag>
        <tag>国奖</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机院校信息整合</title>
    <url>/2018/09/28/08Graduate-School/</url>
    <content><![CDATA[<p><img src="/images/schoolChoice.jpg" alt="cover"></p>
<a id="more"></a>
<h3 id="北京航空航天大学计算机学院招生"><a href="#北京航空航天大学计算机学院招生" class="headerlink" title="北京航空航天大学计算机学院招生"></a>北京航空航天大学计算机学院招生</h3><h4 id="招生简章-2019年"><a href="#招生简章-2019年" class="headerlink" title="招生简章(2019年)"></a>招生简章(2019年)</h4><p>北航计算机学院推免生招生情况</p>
<p><img src="/assets/北航推免生.png" alt="北航推免生"></p>
<p>201803统考硕士招生情况</p>
<p>全日制学硕：54人，其中计算机科学与技术38人，软件工程7人，网络空间安全9人</p>
<p>全日制专硕：123人</p>
<p>非全日制专硕：53人</p>
<h4 id="考研大纲"><a href="#考研大纲" class="headerlink" title="考研大纲"></a>考研大纲</h4><p>961计算机基础综合共包括三门课程的内容：计算机组成原理、操作系统、计算机网络技术，分别占60分，50分、40分。所有课程均不指定参考书。具体要求见<a href="http://scse.buaa.edu.cn/info/1102/5423.htm">北航研究生入学专业课考试大纲</a></p>
<h4 id="联系方式"><a href="#联系方式" class="headerlink" title="联系方式"></a>联系方式</h4><p>北航研究生招生办公室（学历硕士）办公地址：北航行政办公楼东楼二层。</p>
<p>联系电话：010-82317637传真电话：010-82328059</p>
<p>E-mail: <a href="mailto:yzb@buaa.edu.cn">yzb@buaa.edu.cn</a></p>
<p>微信号：buaayzb</p>
<h3 id="北京邮电大学计算机招生"><a href="#北京邮电大学计算机招生" class="headerlink" title="北京邮电大学计算机招生"></a>北京邮电大学计算机招生</h3><p>主要参考<a href="https://ningzimu.github.io/See_you_in_BUPT/#%E6%8B%9B%E7%94%9F%E4%B8%93%E4%B8%9A%E7%9B%AE%E5%BD%95">北邮考研相关信息查阅宝典</a></p>
<h4 id="2019年硕士研究生硕士专业目录-计算机学院"><a href="#2019年硕士研究生硕士专业目录-计算机学院" class="headerlink" title="2019年硕士研究生硕士专业目录(计算机学院)"></a><a href="https://yzb.bupt.edu.cn/content/content.php?p=8_4_67">2019年硕士研究生硕士专业目录(计算机学院)</a></h4><p>推免生比例不超过50%。</p>
<p>计算机学院招生408人，其中计算机科学与技术118人、智能科学与技术12人、计算机技术278人(专业学位，含180非全日制)</p>
<h4 id="考研大纲-1"><a href="#考研大纲-1" class="headerlink" title="考研大纲"></a>考研大纲</h4><p><a href="https://yzb.bupt.edu.cn/content/content.php?p=8_4_269">803计算机学科基础综合</a></p>
<h4 id="往年报考录取情况"><a href="#往年报考录取情况" class="headerlink" title="往年报考录取情况"></a><a href="https://yzb.bupt.edu.cn/list/list.php?p=3_22_1">往年报考录取情况</a></h4><p>2017</p>
<p><img src="/assets/2017北邮.png" alt="2017北邮"></p>
<h3 id="北京大学计算机招生2018"><a href="#北京大学计算机招生2018" class="headerlink" title="北京大学计算机招生2018"></a>北京大学计算机招生2018</h3><p>2018专业目录</p>
<h4 id="信科"><a href="#信科" class="headerlink" title="信科"></a>信科</h4><p><img src="/assets/1547376642700.png" alt="1547376642700"></p>
<h4 id="软件与微电子学院"><a href="#软件与微电子学院" class="headerlink" title="软件与微电子学院"></a>软件与微电子学院</h4><p><img src="/assets/1547344481109.png" alt="1547344481109"></p>
<p>软微对比信科优势如下，学费较贵，3年6万</p>
<p><img src="/assets/1547376711834.png" alt="1547376711834"></p>
<p><img src="/assets/1547377172407.png" alt="1547377172407"> </p>
<p>18年招了119人，19年计算机技术方向预估150来人</p>
<p><img src="/assets/1547377358782.png" alt="1547377358782"> </p>
<p><img src="/assets/1547377638493.png" alt="1547377638493"> </p>
<h5 id="复习规划"><a href="#复习规划" class="headerlink" title="复习规划"></a>复习规划</h5><p>​    不用看慕课、不用看网上流传的各种视频、不用花钱买北大ppt</p>
<p>只用看书+做题，书指的是王道的单科书或天勤的单科书。</p>
<p><strong>考试科目</strong>：数据结构、计算机网络、操作系统</p>
<p><strong>适用专业</strong>：软件工程专硕、计算机技术中的技术类</p>
<p><strong>获取地点</strong> ：王道论坛经验帖、备考软微的QQ群</p>
<p><strong>题目特点</strong>：18年变化比较大，模拟卷做到原题</p>
<p>30到选择题，每科10题，每题2分（共60分）</p>
<p>9道大题，每科3题，每题10-20分（共90分）</p>
<p>大题每年都会有变动</p>
<p><strong>策略</strong>：单科书一定要反复多次全面</p>
<p>第一遍做题建议所有题都做，错的标记，第二次做再标记。第三次只做错题</p>
<p>边回忆边做总结笔记和高频错题，采用索引结构不用全记</p>
<p>后期做真题（王道难度完全超过真题难度），记得总结，水题考前突击。</p>
<p>考前把自己做过的笔记错题拿出来反复看。可能考算法</p>
<p>408真题不需要看，王道很多题就是408的题，科班直接看两边</p>
<p><strong>复试</strong> 双非歧视?三跨生不要？往届生吃亏？学长三重身份。。。</p>
<p>王道者？初始分高者也！</p>
<p>政治抱好肖老师大腿。</p>
<p>录取之后第一周可以转方向，没有四六级要求</p>
<p>学长在复试的时候没有机试，开学的时候增加机试，没过的话增加一门语言课。软工4万，计算机6万，都是3年。</p>
<p>并且北大的专硕还可以正常申请读博士，提前联系好导师。</p>
<p>学长复习早上6点，晚上到11点</p>
<p>软微是开学导师双选，你提前联系导师对你复试毫无帮助，不如好好准备复试。 </p>
<p>软微9月份公布参考书目，9月份之前完成一轮复习</p>
<p><img src="/assets/1547383663254.png" alt="1547383663254"></p>
]]></content>
      <tags>
        <tag>随笔</tag>
        <tag>考研</tag>
      </tags>
  </entry>
  <entry>
    <title>一种新的基于小阴影图像的彩色图像秘密共享方案</title>
    <url>/2018/09/03/06URT-ScienceDirect/</url>
    <content><![CDATA[<p><img src="/images/secretImage.jpg" alt="cover"></p>
<a id="more"></a>
<hr>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>在过去几年，秘密图像分存技术变成了除了传统密码学的另一个努力的方向去防止秘密图像被窃取。由于小的影子图像可以加快秘密颜色图像的传播，在这篇文章中我们结合了Chang和Wu的单位图BTC（GSBTC）的渐进式搜索算法和Shamir的（k,n）门限概念提出一种新的秘密彩色图像共享方案来生成更小的影子。实验结果证实了提出的架构成功减小了影子的大小，并且每个影子表现为一个随机类的图像，这个图像能防止秘密彩色图像的信息泄露。此外，每个影子中两个纵向或横向相邻像素的关联性明显小于秘密彩色图像。提出的方案也实现了，平均来看，NPCR值为0.414%、AUCI值为32.78%。因此，在我们的方案中，一个像素差异会导致相应阴影的显著差异。因此，该方案的安全性也得到了证实。</p>
<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>随着电脑技术的成长，数字相机之类的多媒体变得越来越受欢迎，使得越来越多的数字图像在网上广泛的分享和传播。然而，在网上传输那些秘密或者重要的图像，例如被用于军事或者企业重要秘密图像，则面临一定的危险。恶意的人监视互联网并试图检测并获取这些有价值的图像。为了使这些传输图像免于获取或篡改，秘密分寸技术提出了继传统密码学和隐写术之外的一个新的分支来从掠夺行为中保护重要图像。在这个秘密共享技术后的概念，也叫做（k，n）门限方案，它是Blakley和Shamir独立提出的。这些（k，n）门限方案有三个性质。                                                       当 $k \leq n$ ：<br>（1）：这个秘密图像可以被分成n个部分<br>（2）：任意k或者大于k个部分都能恢复秘密图像<br>（3）：任意k - 1 或者小于k个部分不能计算秘密值<br>Naor和Shamir在1995年第一次使用(k, n)门限方案介绍了聚焦于图像数据的秘密图像共享技术。本质上，秘密图像分存技术使用了几个随机性的被称为影子的图像来代替原始图像在网络上传输数据。影子可以阻挡恶意的攻击者并防止秘密图像被直接访问。秘密共享方案继承了(k, n)门限方案的三个属性。</p>
<p>在过去十年里，许多秘密共享方案被提出。它们有一个共同的特点，即秘密图像可以通过叠加阴影来恢复，换句话说，这些秘密图像可以很容易地恢复，而无需复杂的计算。然而，在这些方案中，阴影的大小通常大于或等于秘密图像的大小。已经提出了许多方案来克服这个问题。在2002，Thien和Lin提出了一种生成更小阴影的（k，n）秘密图像共享方案。他们的方案通过将K - 1作为K像素的灰度值和模251来生成K—1度多项式。通过模251，它们截断大于250的所有灰度值，这导致将所有秘密图像灰度值连接至0-250范围。然后使用Akey生成一个置换序列来置乱秘密图像的像素，从而隐藏相邻像素之间的任一相关性。然后，对秘密图像的k个非共享像素进行采集，成为k  - 1次多项式的k个系数。这些系数和k - 1次多项式为n个阴影图像生成n个像素，直到对秘密图像中的所有像素进行处理。使用此过程，Thien和Lin成功地将每个阴影的大小减小到秘密图像的1 / k大小。</p>
<p>受Thien和Lin的启发，Wang和Su后来设计了一个秘密图像共享方案，改进了Thien和Lin的方案。首先，它们的方案生成一个t比特秘密图像的二值图像。接着，利用Huffman编码对二值图像进行编码，得到的t比特形成共享码。然后，<br>k共享系数用作k -1次多项式共享函数的共享系数，直到处理完所有的Huffman编码结果。用Wangf和Su的方案进行的实验表明，生成的阴影小于Thien和Lin的阴影。然而，两种方案都不能直接应用于彩色图像，因为生成的彩色阴影的大小是灰度阴影的三倍。</p>
<p>由于秘密图像可能是彩色图像，本文提出了一种有损秘密彩色图像共享方案，扩展了秘密图像共享的应用。在我们的方案中，阴影的大小取决于K的数量和较大的K产生较小的阴影。实验结果表明，该方案能有效地减小阴影的大小。本文的其余部分整理如下。第2节包含了（k，n）门限方案和GSBTC的简要回顾。第3节详细介绍了我们的方案。第4节给出了实验结果，并对所提出的方案进行了统计分析和安全性分析。在第5节中描述了未来的工作和一些结论。</p>
<h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3><p>采用两个重要的技术来设计我们的方案：（k，n）门限方案和GSBTC。前者允许将一个秘密图像分解成n个阴影图像，仅需要k个阴影来构造原始秘密图像。后者可以将一个秘密的彩色图像压缩成更小的尺寸，并具有可接受的失真。换言之，通过采用(k，n)阈值方案和GSBTC，可以克服数据传输过程中的潜在损耗，并且可以成功地减小阴影大小。为了给出所提出的方案的背景知识，这些技术在以下各节中说明</p>
<h4 id="基于多项式插值的Shamir（k，n）门限方案"><a href="#基于多项式插值的Shamir（k，n）门限方案" class="headerlink" title="基于多项式插值的Shamir（k，n）门限方案"></a>基于多项式插值的Shamir（k，n）门限方案</h4><p>1979，Shamir提出了一种基于多项式插值的（k，n）门限方案。他的方案假定数据D被分成n个片段D1，D2，.…D n，并且仅需要任何D的k个部分，其中$k \leq n$，才能重建原始秘密数据D。因此，如果仅接收（k  - 1）或小于（k -1）个片段，则仍然不能显示秘密数据D。</p>
<p>假设秘密数据D是一个数字。在Shamir的方案中，素数g是随机选择的，K - 1的多项式分担函数是在等式（1）中被划分为N个阴影。<br>​          f(x) = (a<sub>0</sub> + a<sub>1</sub>x + ……+a<sub>k-1</sub>x<sup>k-1</sup>)%g<br>其中a<sub>1</sub>，a<sub>2</sub>，……a<sub>k - 1</sub>都是随机数，并且a<sub>0</sub>=D。i＝1～n的每个D<sub>i</sub>可由方程导出。<br>D<sub>i</sub> = f(i)<br>其中i＝1 -n，并且每一个D1，D2，。…Dn被视为阴影。为了获得秘密数据D，D<sub>i</sub>的任何k个或更多阴影可以重构f（x）。多项式函数f(x)的所有系数可由拉格朗日插值公式导出，并可计算秘密数据D=a0=f(0)。<br>本文提出的秘密彩色图像共享方案基于Shamir(k，n)阈值方案，使得秘密图像D被划分为n个阴影(D1，D2，.…，Dn）然而，在所提出的方案中，每份的大小随着分享数量的增加而减少。</p>
<h4 id="一个单位图BTC的渐进搜索算法"><a href="#一个单位图BTC的渐进搜索算法" class="headerlink" title="一个单位图BTC的渐进搜索算法"></a>一个单位图BTC的渐进搜索算法</h4><p>在采用Shamir（k，n）阈值方案将一个秘密图像分割成若干个阴影以克服数据传输过程中可能出现的任何损失之前，我们需要解决另一个问题，即如何减小原始彩色图像的大小，从而减小阴影大小。Chang和Wu设计的一个单位图BTC（GSBTC）的渐进搜索算法是我们的解决方案。块截断编码（BTC）变体GSBTC是一种简单而简单的彩色图像压缩算法。</p>
<p>在传统BTC中，图像首先被分成几个非重叠的方块，每个块可以是4×4、8×8等。然后计算每个块的平均像素值x。一般来说，$ \bar{x} $是量化阈值。在块中，将每个像素值X<sub>i</sub>与$ \bar{x} $进行比较，从而生成由两个组组成的位图。如果$ \bar{x} $&lt;X<sub>i</sub>，则位图中的相应位属于组-1，表示为“1”；否则，该位属于组-0，表示为“0”。虽然BTC被设计为压缩灰度图像而不是彩色图像，但同样的过程可以应用于彩色图像。不幸的是，压缩比不是<br>当使用BTC压缩彩色图像时，也是如此，因为彩色图像由三个平面R、G和B组成，并且当使用BTC时，这三个平面形成三个位图。</p>
<p>为了提高彩色图像中的BTC压缩比，通常的方法是生成一个公共位图，该位图使三个单独的位图的失真最小。然而，设计一个生成一个公共位图的算法是一个很难的问题。Chang和Wu的GSBTC算法生成一个等价的公共位图，该位图在保持低计算复杂度的同时，提供解压缩图像的可接受的图像质量。在本文中，我们使用GSBTC对秘密彩色图像进行压缩，然后给出一个秘密图像。有损秘密彩色图像共享方案。为了更好地解释我们提出的方案，我们首先在以下段落中详细介绍Chang和Wu的GSBTC算法。</p>
<p>假设彩色图像被划分成几个具有m × m像素的非重叠块。首先，每个块用传统的BTC处理。换句话说，每个块由三个位图组成，它们映射到三个平面R、G和B。大于平均像素值。为了为每个块生成一个公共位图B<sub>C</sub>，R、G和B位图中相同的位称为确定元素，并保留在公共位图B<sub>C</sub>中。在三位图中具有二元值的位，称为非确定元素，不在公共位图B<sub>C</sub>中保留。也就是说，一个共同的位图B<sub>C</sub>的元素由两个组组成，D<sub>C</sub>和ND<sub>C</sub>，如下：<br>$D_C = {c_i|c_i \in B_C 且 c_i\neq 未定义}$<br>其中D<sub>C</sub>是确定的集合，ND<sub>C</sub>是非确定的集合。R、G和B平面的位图和公共位图被定义为<br>B<sub>R</sub> = {r<sub>1</sub>,r<sub>2</sub>,}<br>$f(x_1,x_2,\ldots,x_n) = x_1^2 + x_2^2 + \cdots +x_n^2 ​$</p>
]]></content>
      <tags>
        <tag>(k,n)门限</tag>
      </tags>
  </entry>
  <entry>
    <title>pyecharts可视化学生信息</title>
    <url>/2018/09/02/05Pyecharts/</url>
    <content><![CDATA[<p><img src="/images/pyechart.gif" alt="cover"></p>
<a id="more"></a>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><hr>
<p>pyecharts是python的一个包，里面封装了echarts的接口，而echarts是一个功能非常强大的绘图工具，图形非常简洁、美观。相比于matplotlib还是有很多优势的，比如echarts的交互功能。如图：<br><img src="https://user-images.githubusercontent.com/19553554/35104157-fa39e170-fca2-11e7-9738-1547e22914a6.gif" alt="动画演示"> </p>
<p><img src="\img\pyecharts\pyecharts.gif" alt="pyecharts"></p>
<p>所以它可以用来演示功能、或者数据分析报告等等。</p>
<h2 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h2><hr>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">df = pd.read_csv(<span class="string">&quot;Student Info.csv&quot;</span>) <span class="comment">#读取csv文件</span></span><br><span class="line">df.info()  <span class="comment">#查看学生各个属性有无缺失值</span></span><br></pre></td></tr></table></figure>
<h2 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h2><hr>
<p>在加载到数据集之后，我们首先统计一下学生的生源地分布情况。要统计生源地情况，即我们要得到两个列表，第一个为各省份名称，第二个列表为对应名称在数据集中出现的次数(频率)。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">region_num = df[<span class="string">&#x27;生源地&#x27;</span>].value_counts() <span class="comment">#统计各类别频率</span></span><br><span class="line">region_num = region_num.values.tolist() <span class="comment">#将频率转换为列表</span></span><br><span class="line">region = df[<span class="string">&#x27;生源地&#x27;</span>].value_counts().keys() <span class="comment">#统计各类别频率对应的键值</span></span><br><span class="line">region = region.values.tolist() <span class="comment">#将键值转换为列表</span></span><br><span class="line">print(region_num) <span class="comment">#打印频率查看</span></span><br><span class="line">print(region)  <span class="comment">#打印地区查看</span></span><br></pre></td></tr></table></figure>
<h2 id="绘图-柱状图-地域"><a href="#绘图-柱状图-地域" class="headerlink" title="绘图-柱状图-地域"></a>绘图-柱状图-地域</h2><hr>
<p>我们用pyecharts的柱状图来绘制图形，同时将上面得到的region_num和region作为参数传到绘图函数中。在这里add采用了多个参数，如无需要可以去掉。</p>
<blockquote>
<ul>
<li><code>add()</code><br>主要方法，用于添加图表的数据和设置各种配置项</li>
<li><code>print_echarts_options()</code><br>打印输出图表的所有配置项</li>
<li><code>render()</code><br>默认将会在根目录下生成一个 render.html 的文件，支持 path 参数，设置文件保存位置，如 render(r”e:\my_first_chart.html”)，文件用浏览器打开。</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> Bar <span class="comment">#引用直方图</span></span><br><span class="line">bar = Bar(<span class="string">&quot;信息工程学院&quot;</span>,<span class="string">&quot;信息2018级新生生源地统计&quot;</span>,width=<span class="number">1000</span>, height = <span class="number">500</span>)</span><br><span class="line"></span><br><span class="line">bar.use_theme(<span class="string">&#x27;dark&#x27;</span>)  <span class="comment">#背景主题</span></span><br><span class="line"></span><br><span class="line">bar.add(<span class="string">&quot;生源地&quot;</span>, region, region_num, is_stack=<span class="literal">False</span>, bar_category_gap=<span class="string">&#x27;20%&#x27;</span>,xaxis_interval =<span class="number">0</span>,xaxis_rotate=<span class="number">20</span>, is_more_utils=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#bar.render() #导出为网页</span></span><br><span class="line">bar <span class="comment">#查看</span></span><br></pre></td></tr></table></figure>
<p>通过以上步骤就能看到如下图所示结果</p>
<p><img src="\img\pyecharts\pyecharts01.png" alt="pyecharts01"> </p>
<h2 id="绘图-饼图-第一志愿"><a href="#绘图-饼图-第一志愿" class="headerlink" title="绘图-饼图-第一志愿"></a>绘图-饼图-第一志愿</h2><p>同样要先进行数据清洗，查看有无缺失值</p>
<p><img src="\img\pyecharts\pyecharts02.png" alt="pyecharts02"></p>
<p>可以看到，第一志愿数据是不全的，需要进行缺失值处理。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">choice = df[<span class="string">&#x27;第一志愿&#x27;</span>].fillna(<span class="string">&#x27;&#x27;</span>) <span class="comment">#缺失值填充为空</span></span><br><span class="line">volunteer_first_num = df[<span class="string">&#x27;第一志愿&#x27;</span>].value_counts() <span class="comment">#统计各类别频率</span></span><br><span class="line">volunteer_first_num = region_num.values.tolist() <span class="comment">#将频率转换为列表</span></span><br><span class="line">volunteer_first = df[<span class="string">&#x27;第一志愿&#x27;</span>].value_counts().keys() <span class="comment">#统计各类别频率对应的键值</span></span><br><span class="line">volunteer_first = region.values.tolist() <span class="comment">#将键值转换为列表</span></span><br><span class="line">print(volunteer_first_num) <span class="comment">#打印频率查看</span></span><br><span class="line">print(volunteer_first)  <span class="comment">#打印地区查看</span></span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li><p>name -&gt; str<br>图例名称</p>
</li>
<li><p>attr -&gt; list<br>属性名称</p>
</li>
<li><p>value -&gt; list<br>属性所对应的值</p>
</li>
<li><p>radius -&gt; list<br>饼图的半径，数组的第一项是内半径，第二项是外半径，默认为 [0, 75]<br>默认设置成百分比，相对于容器高宽中较小的一项的一半</p>
</li>
<li><p>center -&gt; list<br>饼图的中心（圆心）坐标，数组的第一项是横坐标，第二项是纵坐标，默认为 [50, 50]<br>默认设置成百分比，设置成百分比时第一项是相对于容器宽度，第二项是相对于容器高度</p>
</li>
<li><p>rosetype -&gt; str</p>
<p>是否展示成南丁格尔图，通过半径区分数据大小，有’radius’和’area’两种模式。默认为’radius’</p>
<ul>
<li>radius：扇区圆心角展现数据的百分比，半径展现数据的大小</li>
<li>area：所有扇区圆心角相同，仅通过半径展现数据大小</li>
</ul>
</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> Pie <span class="comment">#饼图</span></span><br><span class="line"></span><br><span class="line">pie = Pie(<span class="string">&quot;第一志愿&quot;</span>) <span class="comment">#标题</span></span><br><span class="line"></span><br><span class="line">pie.add(<span class="string">&quot;&quot;</span>, choice, choice_num, radius=[<span class="number">30</span>, <span class="number">75</span>], is_legend_show=<span class="literal">False</span>, is_label_show=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#radius半径范围</span></span><br><span class="line"><span class="comment">#is_legend_show是否显示图例</span></span><br><span class="line"><span class="comment">#is_label_show是否显示标签</span></span><br><span class="line">pie</span><br></pre></td></tr></table></figure>
<p><img src="\img\pyecharts\pyecharts03.png" alt="pyecharts03"> </p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上就是我对pyecharts的简单使用以及探索，在这个过程中我发现参阅文档是极其重要的，在网上闷着头找解决方案不如认真仔细的读一读<a href="http://pyecharts.org/#/zh-cn/prepare">pyecharts文档</a> ，里面绝对有你想要找的地方，起初我是找一个字体倾斜的解决方案，找了半天，给的都不是特别全面，在看了文档之后才发现，许多问题作者都是考虑在内了的，这会让你事半功倍。而且，pyecharts的封装是由我们国人完成的，文档阅读起来非常方便，所以必须支持下。</p>
]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>北京林业大学-掌上医生APP开发</title>
    <url>/2018/08/09/03App-Paldoctor/</url>
    <content><![CDATA[<p><img src="/images/PalDoctor.jpg" alt="cover"></p>
<a id="more"></a>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>这个项目由来来的比较有意思，通过曾经在爱未来指导我的老师，我与北京工业大学以宫明昊为队长的小队走到了一块。起初是想在暑假找份实习，通过王帅老师投了两份，没反应，就把此次项目当作一份实习了，同时也接触一下其他学校的学生。团队中只有我一个人负责APP的开发，让第一次接触211学校同学的我有些压力。</p>
<h1 id="项目信息"><a href="#项目信息" class="headerlink" title="项目信息"></a>项目信息</h1><p>2018年7月中旬，组内开了第一次会，整体了解了一下项目背景、项目制作初衷以及小组成员的工作分配。这个项目，主要针对互联网+创新类比赛，而且已经拿到了专利并获得比赛创办者的支持。 我还是第一次接触到这么优秀的项目，因此在我跟队长宫明昊谈完之后，我就决定做好它了。   </p>
<p>紧接着项目指导老师在北京林业大学工学院实验楼给各小队成员开了一个会议，会议上老师对各小组的工作提出了要求，同时也对比赛的进行做了介绍，之后，我就要正式开始我的工作了。  </p>
<h1 id="项目开展"><a href="#项目开展" class="headerlink" title="项目开展"></a>项目开展</h1><p>前期队里其他成员已经将他们设计好的界面图发到群里了，我只需要一个个实现就行了。  </p>
<h2 id="项目的开发环境"><a href="#项目的开发环境" class="headerlink" title="项目的开发环境"></a>项目的开发环境</h2><p>Windows10，软件为andorid studio3.1.0，数据库使用android studio自带的sqlite  </p>
<h2 id="项目基础页面设计"><a href="#项目基础页面设计" class="headerlink" title="项目基础页面设计"></a>项目基础页面设计</h2><p>项目前期设计的还算比较顺利，完成立一系列的的界面设计，同时以易通行app做参照，在界面设计方面有所提高，学会了利用分割线来设计界面。其他的都是一些基础设计，具体设计如下图<br><img src="/img/paldoctor/selfInfo.jpg" alt="Alt text"><br><img src="/img/paldoctor/login2.jpg" alt="Alt text"><br>不过跟我们生活中用的APP比起来，简直LOW到爆了，还要很多东西要去学习。  </p>
<h2 id="短信验证码的实现"><a href="#短信验证码的实现" class="headerlink" title="短信验证码的实现"></a>短信验证码的实现</h2><p>在设计注册界面时按照需求通过给手机发送短信验证码，从而进行注册  </p>
<p>面向用户的话，为了安全性的考量，应该是通过给短信验证码平台发送消息，再有验证码平台对移动商服务器请求，最后手机才收到短信。而这里就是用简单生成的六位随机数来模拟验证码，同时调用手机的短信服务接口，来进行短信的发送。  </p>
<p><img src="/img/paldoctor/login1.jpg" alt="Alt text">  </p>
<h2 id="上传本地文件到服务器"><a href="#上传本地文件到服务器" class="headerlink" title="上传本地文件到服务器"></a>上传本地文件到服务器</h2><p>在进行上传时，涉及到很多盲区，包括网络传输协议、网络信息发送方式、java输入输出流、java的多线程以及阿里云服务器的使用。这个过程我主要时通过以下拆分来完成的<br><img src="/img/paldoctor/process.png" alt="Alt text">  </p>
<p>起初我大致了解了Android通信的几种方式socket(套接字),Internet协议、常见Http处理等  </p>
<p>从java端到java端并没有什么难度，网上也给出了很多的经典例子。因此开始我就忽略了对java流实现的研究，直接进行文件的发送。开始还比较顺利，可是到了阿里服务器就坏了，通过对服务器Ubuntu的命令始终无法打开其端口，最终通过登陆阿里云平台的开放端口，最终才实现文件的发送。这一问题解决，其他就顺利的实现了手机端到服务器文件的发送。</p>
<h2 id="下载服务器文件到本地"><a href="#下载服务器文件到本地" class="headerlink" title="下载服务器文件到本地"></a>下载服务器文件到本地</h2><p>在网上并没有对应上传下载同时进行，而只开一个端口的操作。于是自己看了一下java的IO流操作。<br>主要有Output、Input、Writer和Reader。其他的FileInput之类的属于从这些基类上派生出来的具体的操作。  </p>
<p>我主要使用Output及Input来分别操控四个地方的文件即手机本地文件、android读取到平台的流文件、android收到的流文件、服务器本地文件  </p>
<p>通过socket+服务器tmux+android流+线程的组合，顺利实现了下载。  </p>
<p>不过还遗留了一个问题，就是不知道如何去断开流之间文件的读取，因此目前APP每次就只能下载一个服务器文件到本地<br><img src="/img/paldoctor/tmux.png" alt="Alt text"><br>tmux 命令<br><code>tmux attach</code> 切换到后台<br>ctrl + b + d  后台执行并切换到前台</p>
<h2 id="上传头像"><a href="#上传头像" class="headerlink" title="上传头像"></a>上传头像</h2><p>头像的上传让我对startactivityforresult的理解又更深了一步，能够灵活通过request和result来区分不同的任务。用户在选择头像时，首先会弹出对话框(AlertDialog)选择上传方式。选择拍摄会直接调用相机的接口，跳转到拍摄界面。选择从文件中选择则直接跳转到相册。  </p>
<p>在拍完照或者选择完图片之后会有一个方形区域来选择呈现的部分。而这个部分作为Bitmap返回到主界面forresult函数进行操作(保存到本地以及显示在界面上)。    </p>
<p><img src="/img/paldoctor/pt.jpg" alt="Alt text"><img src="/img/paldoctor/ptchose.jpg" alt="Alt text">  </p>
<p>ps:这里的上传指的是将裁剪后的图片保存到本地路径，从而在该用户第二次登陆时能够加载历史头像。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>以上就是掌上医生比赛项目的内容及制作过程，虽然有一些经验并且有参考，不过这次也确实学到了很多知识。首先，在对网络一片空白的情况下去研究 <strong>socket+服务器tmux+android流+线程</strong>这一套东西，并且能坚持下来，这其中也是非常锻炼人，还好我没有放弃这一块。  </p>
<p>在这次实战中，我接触到了很多网络方面的知识，我觉得非常有意思，我们平时打开的网页也是对服务器的一次次请求，不过他们的通信又是另一种方式了。我对服务器、客户端有了一个新的认识，同时也对自己有了一个新的认识。无论是adnroid接口、andorid界面，还是socket通信、服务器命令等等，还有非常多的盲区，还要很多可以进步的地方，希望以后能越来越棒！  </p>
<p>最后附上源码地址<a href="https://github.com/YuleZhang/PalDoctor">https://github.com/YuleZhang/PalDoctor</a></p>
]]></content>
      <tags>
        <tag>socket</tag>
      </tags>
  </entry>
  <entry>
    <title>个人收藏</title>
    <url>/2018/08/07/01self-collection/</url>
    <content><![CDATA[<p><img src="/images/welcome-cover.jpg" alt="cover"><br><a id="more"></a></p>
<h2 id="优质视频学习资源"><a href="#优质视频学习资源" class="headerlink" title="优质视频学习资源"></a>优质视频学习资源</h2><p><a href="https://www.icourse163.org/">中国大学MOOC</a>能较为方便的查看国内知名高校开设的课程，适合学一些比较系统的知识、架构或者涉足新领域  </p>
<p><a href="http://www.feemic.cn/mooc">幕课视频搜索解析工具</a>是上述进阶版，可以查看下载关闭学期的课程 </p>
<p><a href="https://www.imooc.com/course/list">慕课网免费课程</a> 比较全面cs课程网站</p>
<p><a href="https://www.zhihu.com/question/29748492">可选择资源1</a>来自于知乎，推荐了较多的视频学习网站，待探索</p>
<p><a href="https://mp.weixin.qq.com/s/Ft7TmbTPVRK1_9x-6iE17w">可选择资源2</a>来自于微信文都的一篇文章，收录了全球比较好的视频学习网站。</p>
<!-- more -->
<h2 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h2><p><a href="https://www.leiphone.com/news/201610/Oqndr7PXFB9BRI9p.html">入门必备</a>机器学习视频推荐<br><a href="https://zhuanlan.zhihu.com/p/26169982">机器学习自学指南</a></p>
<p><a href="http://blog.jobbole.com/112569/">机器学习实践指南</a></p>
<p><a href="http://www.360doc.com/content/17/0417/14/20558639_646290956.shtml">kaggle入门详细教程</a>给出了具体步骤，附带资源链接  </p>
<h2 id="算法学习"><a href="#算法学习" class="headerlink" title="算法学习"></a>算法学习</h2><p><a href="https://www.cnblogs.com/yinbiao/">常见算法及数据结构总结</a> </p>
<h2 id="PPT免费资源"><a href="#PPT免费资源" class="headerlink" title="PPT免费资源"></a>PPT免费资源</h2><p><a href="http://www.1ppt.com/moban/jingdian/">第一PPT模板免费下载</a>PPT资源比较丰富</p>
<h2 id="思维导图、流程图"><a href="#思维导图、流程图" class="headerlink" title="思维导图、流程图"></a>思维导图、流程图</h2><p><a href="https://www.processon.com/">ProcessOn</a>在线编辑工,方便的进行流程图的制作，无广告 </p>
<h2 id="图片素材"><a href="#图片素材" class="headerlink" title="图片素材"></a>图片素材</h2><h3 id="工程矢量图"><a href="#工程矢量图" class="headerlink" title="工程矢量图"></a>工程矢量图</h3><p><a href="http://iconfont.cn/">阿里矢量图</a> 包含大量的小图标</p>
<p><a href="https://www.easyicon.net/">easyicon素材库</a>   </p>
<p><a href="https://blog.csdn.net/weixin_42474261/article/details/106711403">逗比拯救世界</a> 表情包搜索网站</p>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p> <a href="https://picjumbo.com/">picjumbo</a> 博客专用高品质大图1</p>
<p><a href="https://www.lifeofpix.com/">lifeofpix</a> 博客专用高像素大图 2 </p>
<p><a href="https://pixabay">pixapay</a>  高清无版权图片库</p>
<p><a href="https://www.pexels.com/">pexels</a> 英文搜索</p>
<p><a href="http://thestocks.im/">thestocks</a> 无版权图片库资源整合</p>
<h2 id="研究生参考资源"><a href="#研究生参考资源" class="headerlink" title="研究生参考资源"></a>研究生参考资源</h2><h3 id="院校选择"><a href="#院校选择" class="headerlink" title="院校选择"></a>院校选择</h3><p><a href="https://blog.csdn.net/cuijie0197/article/details/79394746">人工智能院校及导师等排名</a><br><a href="http://www.cdgdc.edu.cn/xwyyjsjyxx/xkpgjg/">全国第四轮学科评估</a></p>
<h2 id="代码在线生成url"><a href="#代码在线生成url" class="headerlink" title="代码在线生成url"></a>代码在线生成url</h2><p><a href="https://paste.ubuntu.com">https://paste.ubuntu.com</a></p>
<h2 id="python库文档"><a href="#python库文档" class="headerlink" title="python库文档"></a>python库文档</h2><p><a href="http://pyecharts.org/#/">pytcharts</a></p>
<h2 id="科学上网资源"><a href="#科学上网资源" class="headerlink" title="科学上网资源"></a>科学上网资源</h2><p><a href="https://hh2h.xyz/top.html">免费、付费科学上网VPN排行榜</a> </p>
<p><a href="https://hh2h.xyz/53.html">VyprVPN手机电脑 不限流量不限速</a></p>
<p><a href="https://hh2h.xyz/408.html">SSR酸酸乳</a></p>
<h2 id="小工具"><a href="#小工具" class="headerlink" title="小工具"></a>小工具</h2><p><a href="https://smallpdf.com/">word、pdf等文件在线转换</a><br><a href="http://www.jasondavies.com/wordcloud/">在线词云</a><br><a href="http://www.huabandata.com/tools/wordcloud/">词云助手</a><br><a href="https://www.youtuhi.com/">优兔下载</a><br><a href="http://xueshu.baidu.com/usercenter/papercheck/">论文查重</a><br><a href="https://minhaskamal.github.io/DownGit/#/home">DownGit</a> 在github上下载单个子文件夹<br><a href="http://kagent.applinzi.com/qqun">QQ群爬虫</a><br><a href="https://blog.csdn.net/ww122081351/article/details/43485165">提取qq成员信息记录</a>是控制台脚本<br><a href="http://www.zhaowenku.com/">百度文库文章免费下载</a><br><a href="https://www.cnblogs.com/L-zhihua/p/6232354.html">U盘EXE病毒</a><br><a href="https://zhidao.baidu.com/question/272763300.html">清除C盘临时文件bat指令</a><br><a href="http://music.vm82.com/">多平台音乐免费下载</a><br><a href="https://pdfcrowd.com/">pdfcrowd</a>、<a href="https://www.web2pdfconvert.com/to/jpg">web2pdfconvert</a>、<a href="https://www.url2png.com/">url2png</a>：页面转PDF|PNG|JPG的API<br>百度网盘倍速:videojs.getPlayers(“video-player”).html5player.tech_.setPlaybackRate(1.5)<br>倍速播放js脚本:document.getElementsByClassName(‘uplayer_video’).playbackRate = 1.25<br>慕课平台自动暂停破解js脚本:</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">setInterval</span>(<span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">   <span class="keyword">var</span> a = <span class="built_in">document</span>.getElementsByClassName(<span class="string">&#x27;xt_video_player_play_btn fl&#x27;</span>)[<span class="number">0</span>];</span><br><span class="line">   <span class="keyword">if</span> (a.className == <span class="string">&#x27;xt_video_player_play_btn fl&#x27;</span>) &#123;</span><br><span class="line">     <span class="built_in">console</span>.log(<span class="string">&#x27;检测到暂停，已继续&#x27;</span>);</span><br><span class="line">     a.click();</span><br><span class="line">   &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">     <span class="built_in">console</span>.log(<span class="string">&#x27;视频正在播放&#x27;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;, <span class="number">100</span>);</span><br></pre></td></tr></table></figure>
<h2 id="电影"><a href="#电影" class="headerlink" title="电影"></a>电影</h2><h3 id="未看"><a href="#未看" class="headerlink" title="未看"></a>未看</h3><p><a href="http://t.cn/ReSIUiU">西虹市首富（高清）</a>    <a href="http://t.cn/ReSIfvY">邪不压正</a></p>
<h3 id="已看"><a href="#已看" class="headerlink" title="已看"></a>已看</h3><p>碟中谍<br>速度与激情<br>暗战<br>给爸爸的信<br>西虹市首富<br>我不是药神<br>风雨咒<br>情圣<br>三傻大闹宝莱坞<br>未知死亡<br>喜剧之王<br>摔跤吧！爸爸<br>寻找幸福的赫克托                        </p>
<p>大鱼海棠</p>
<p>​          <a href="https://www.iqiyi.com/v_19rrho3enw.html">人生遥控器</a>        <a href="https://v.qq.com/x/cover/x5ul2annjsbcwh8/e00335q391x.html?ptag=iqiyi">三傻大闹宝莱坞</a></p>
<p><img src="http://pic3.iqiyipic.com/image/20190808/2f/69/v_62644868_m_601_m5_180_236.jpg" alt="人生遥控器"><img src="http://pic6.iqiyipic.com/image/20180212/0d/df/v_50215691_m_601_m7_180_236.jpg" alt="三傻大闹宝莱坞"></p>
]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>第一次建网站</title>
    <url>/2018/08/07/02Blog-Build/</url>
    <content><![CDATA[<p><img src="/images/buildWebsites.jpg" alt="cover"><br><a id="more"></a></p>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>对于一个小白来说，第一次建立自己的个人网页还真是一件既兴奋又无奈的事情。兴奋是因为你即将有一个属于自己的平台，可以将自己的感悟、收藏、简历等文章保存起来，也可以分享给他人。无奈是因为，在你搭着搭着，你会发现出现了各种各样的问题，这其中包含你的一些个性却没法实现的需求以及半路杀出的各种bug。不过，经历一番麻烦，也是会留下深刻的印象的。</p>
<h1 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h1><p>说到建立网站，不得不考虑不同人出于不同的需求，来走自己的网站路线。可是，对于小白们或者不干网站这方面的大佬们来说，做一个又显得费劲。而我想我的需求跟大部分人一样，当然我的实现也是比较low的一种。我没有买域名，也没有租服务器，而是蹭github的<em><a href="https://pages.github.com/">github page</a></em>，具体创建仓库的教程网上都有详细概述。<br>而下面的两个配置路线有两个优点 </p>
<ol>
<li>有成型的网页模板，会让你的主页逼格瞬间提升一个档次。  </li>
<li>方便后续更新维护你的网站。  </li>
</ol>
<h1 id="github-page建网页路线"><a href="#github-page建网页路线" class="headerlink" title="github page建网页路线"></a>github page建网页路线</h1><ol>
<li>GitHub Pages + Hexo </li>
<li>GitHub Pages + jekyll<br>我采用的搭建博客的方式是第一种，建议Windows用户走第一种。<br>因为我先走的第二种，走到一半卡死了，cmd窗口出现毫无头绪的错误，网上也找不到什么解决方案。当然你也可以勇于尝试，毕竟机子不同嘛。<br>接下来我们先说第一种</li>
</ol>
<h1 id="Hexo配置"><a href="#Hexo配置" class="headerlink" title="Hexo配置"></a>Hexo配置</h1><h2 id="下载Node-js"><a href="#下载Node-js" class="headerlink" title="下载Node.js"></a>下载<em><a href="https://nodejs.org/en/">Node.js</a></em></h2><p>其中 LTS为稳定版本 ，Current为当前最新版本</p>
<h2 id="下载git"><a href="#下载git" class="headerlink" title="下载git"></a>下载<em><a href="https://git-scm.com/">git</a></em></h2><p>下载完配置账户，及ssh等，这里有详细介绍<em><a href="https://blog.csdn.net/qq_23341529/article/details/79331519">git配置</a></em></p>
<h2 id="安装Hexo及初步预览"><a href="#安装Hexo及初步预览" class="headerlink" title="安装Hexo及初步预览"></a>安装Hexo及初步预览</h2><p>网上大多hexo的配置都是以前版本的指令了，最新的还要参考<em><a href="https://hexo.io/zh-cn/docs/">Hexo官网</a></em><br>任意位置右键选择Git Bash Here(即打开git的命令窗口)<br><code>$ npm install -g hexo-cli</code><br>接下来找一个你要建立网站的目录，在它的上一级git bash here，执行命令  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ hexo init &lt;folder&gt;  </span><br><span class="line">$ cd &lt;folder&gt;  </span><br><span class="line">$ npm install  </span><br></pre></td></tr></table></figure>
<p>此时你的界面应该是这样的  </p>
<p><img src="/assets/1547024489695.png" alt="1547024489695"></p>
<p>下面我们测试一下环境搭的怎么样<br><code>hexo g</code><br>原为generate缩写为g，意为生成，在<em><a href="https://hexo.io/zh-cn/docs/">hexo官网</a></em>上有详细的说明<br><code>hexo s</code><br>原为server缩写为s，提交到本地服务器进行查看<br>当你看到这个界面</p>
<p><img src="/assets/1547024466501.png" alt="1547024466501"></p>
<p>就说明你测试成功啦，恭喜，就可以到<em><a href="http://localhost:4000/">http://localhost:4000/</a></em>查看你已经初步搭建的网页预览图啦。<br><strong>如果你的目的达成了，那么下面就不需要继续看下去了，想有不同风格的主题往下看。</strong></p>
<h2 id="网站主题"><a href="#网站主题" class="headerlink" title="网站主题"></a>网站主题</h2><h3 id="寻找主题"><a href="#寻找主题" class="headerlink" title="寻找主题"></a>寻找主题</h3><p>当我们看到预览图，肯定会有些小兴奋，不过冷静，事情还没办完。<br>留心查看一下，你会发现根目录下有个themes的文件夹，我们下面自己下载的主题就放到这个目录下面。<br>现在，到<em><a href="https://hexo.io/themes/">hexo主题平台</a></em>选择自己喜欢的主题吧，样式非常多，有的挑了。</p>
<h3 id="下载主题"><a href="#下载主题" class="headerlink" title="下载主题"></a>下载主题</h3><p>下载主题两种方式.  </p>
<ol>
<li>第一种是点开主题的github界面，按照README.txt中的指令，在刚刚提到的themes目录下操作 </li>
<li>第二种是github界面右上角下载”clone and download”  下完之后放到themes目录下</li>
</ol>
<h3 id="配置主题"><a href="#配置主题" class="headerlink" title="配置主题"></a>配置主题</h3><p>其实不只是配置主题，对Github页面的大部分编辑操作都涉及到根目录下面的_config.yml文件，将其中的themes后面的值改为对应主题文件夹名称。<br><strong>注意中间的空格不能丢，会报错的</strong></p>
<h3 id="编辑页面"><a href="#编辑页面" class="headerlink" title="编辑页面"></a>编辑页面</h3><p>之后就根据不同主题的风格进行操作了，主要结合hexo官方文档以及对应主题github下readme.txt的说明来完成。  最好下个<em><a href="https://www.sublimetext.com/3">sublime text 3</a></em><br>编辑文本会非常方便，单纯用txt打开会遇到编码乱码问题，不利于后续文本的编辑<br>至于编辑，你还得会markdown，所以把东西很多，都得会，不过markdown非常简单，作为程序员你不得不用它，因为它确实很牛，sublime中可以下载markdown编辑插件，详细见教程<em><a href="https://www.cnblogs.com/james-lee/p/6847906.html">Sublime Text3 + Markdown + 实时预览</a></em>个人觉得这比网页里面预览方便多了。<br><strong>注意：所有的操作都在你网站目录下的git bash中完成</strong>  </p>
<h2 id="提交修改三步走"><a href="#提交修改三步走" class="headerlink" title="提交修改三步走"></a>提交修改三步走</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo s</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure>
<p>其中hexo d是部署到github上去的，要是没弄好，先前两步多走几次，多预览几下，再提交到github。  </p>
<p>github page网站配置分享到此结束，感谢查看。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><em>整体说明: <a href="https://blog.csdn.net/tianbo_zhang/article/details/79137103">https://blog.csdn.net/tianbo_zhang/article/details/79137103</a></em>  </p>
<p><em>官方文档: <a href="https://hexo.io/zh-cn/docs/">https://hexo.io/zh-cn/docs/</a></em>  </p>
<p><em>hexo主题：<a href="https://hexo.io/themes/">https://hexo.io/themes/</a></em></p>
<p><em>hexo_config.yml配置示例：<a href="https://www.cnblogs.com/littlewriter/p/7229094.html">https://www.cnblogs.com/littlewriter/p/7229094.html</a></em></p>
<p><em>markdown基本语法：<a href="https://www.jianshu.com/p/191d1e21f7ed">https://www.jianshu.com/p/191d1e21f7ed</a></em></p>
<p><em>sublime text 3下载地址：<a href="https://www.sublimetext.com/3">https://www.sublimetext.com/3</a></em></p>
<p><em>markdown实时预览：<a href="https://www.cnblogs.com/james-lee/p/6847906.html">https://www.cnblogs.com/james-lee/p/6847906.html</a></em></p>
]]></content>
      <categories>
        <category>网站建设</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>python之wordcloud教程</title>
    <url>/2018/08/07/04Wordcloud/</url>
    <content><![CDATA[<p><img src="/images/wordcloud.jpg" alt="cover"></p>
<a id="more"></a>
<h2 id="wordcloud介绍"><a href="#wordcloud介绍" class="headerlink" title="wordcloud介绍"></a>wordcloud介绍</h2><p>wordcloud是python提供的一个包，主要可以用于数据分析，搭配matplotlib包生成可视化词图，加强我们对数据的理解，便于分析。<br><strong>如果你只是想快捷的利用现成的数据来做一张词图，并不打算深入了解python这门语言，那么恭喜你，你将在这里直接利用数据生成你想要的各种词图，非常方便。入口:</strong><a href="http://www.huabandata.com/tools/wordcloud/">词云助手</a></p>
<h2 id="环境说明"><a href="#环境说明" class="headerlink" title="环境说明"></a>环境说明</h2><h3 id="python环境"><a href="#python环境" class="headerlink" title="python环境"></a>python环境</h3><p>首先要有<a href="https://www.python.org/downloads/release/python-370/">python环境</a>，可以直接单击下载python。不过如果是初学者建议下载Anaconda3,Anaconda指的是一个开源的Python发行版本，其中包含了python正常使用需要的大部分包并且能自动配置环境变量，提供jupyter notebook等IDE，非常适合新手。点击查看<a href="https://blog.csdn.net/program_developer/article/details/79677557"><br>Anaconda详细安装使用教程</a></p>
<h3 id="wordcloud包"><a href="#wordcloud包" class="headerlink" title="wordcloud包"></a>wordcloud包</h3><p>快捷键win+r打开windows运行窗口(左下角)，输入cmd回车，打开命令窗口.<br>在命令行中输入<code>pip install wordcloud</code>或者<code>conda install wordcloud</code>，等待安装wordcloud包。  </p>
<h2 id="开始编程"><a href="#开始编程" class="headerlink" title="开始编程"></a>开始编程</h2><p>首先打开你的jupyter notebook环境，还是通过win+r,输入jupyter notebook，回车。等待几十秒，跳转到页面里，就可以开始使用jupyter了。jupyter的教程网上有很多，这里就不再赘述，只介绍wordcloud的相关使用方法。<br>需要数据及源码的单击进入<a href="https://pan.baidu.com/s/1dV9u3aSV1flT3F6diTy_tA">百度云</a>，密码: rugu ，进行下载<br>下面是实现词云的详细代码及注释（#之后为注释内容）<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud,STOPWORDS,ImageColorGenerator</span><br><span class="line"> </span><br><span class="line"><span class="comment">#backgroup_Image = plt.imread(&#x27;F:/man.jpg&#x27;) #笼罩图</span></span><br><span class="line"> </span><br><span class="line">f = open(<span class="string">&#x27;F:\人工智能.txt&#x27;</span>,<span class="string">&#x27;r&#x27;</span>).read()  <span class="comment">#生成词云的文档</span></span><br><span class="line">wordcloud = WordCloud(</span><br><span class="line">        background_color = <span class="string">&#x27;white&#x27;</span>, <span class="comment">#背景颜色，根据图片背景设置，默认为黑色</span></span><br><span class="line">        <span class="comment">#mask = backgroup_Image, #笼罩图</span></span><br><span class="line">        font_path = <span class="string">&#x27;C:\Windows\Fonts\STZHONGS.TTF&#x27;</span>,<span class="comment">#若有中文需要设置才会显示中文</span></span><br><span class="line">        width = <span class="number">1000</span>,</span><br><span class="line">        height = <span class="number">860</span>,</span><br><span class="line">        margin = <span class="number">2</span>).generate(f) <span class="comment"># generate 可以对全部文本进行自动分词</span></span><br><span class="line"><span class="comment">#参数 width，height，margin分别对应宽度像素，长度像素，边缘空白处</span></span><br><span class="line"> </span><br><span class="line">plt.imshow(wordcloud)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"> </span><br><span class="line"><span class="comment">#保存图片：默认为此代码保存的路径</span></span><br><span class="line">wordcloud.to_file(<span class="string">&#x27;touxiang.jpg&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><em>Anaconda安装教程：<a href="https://blog.csdn.net/program_developer/article/details/79677557">https://blog.csdn.net/program_developer/article/details/79677557</a></em></p>
<p><em>Conda管理python包：<a href="https://blog.csdn.net/dennis_shaw/article/details/77535659">https://blog.csdn.net/dennis_shaw/article/details/77535659</a></em></p>
<p><em>wordcloud词云安装到入门： <a href="https://blog.csdn.net/arise007/article/details/79346169">https://blog.csdn.net/arise007/article/details/79346169</a></em>  </p>
<p><em>wordcloud词云详教程：<a href="https://www.2cto.com/kf/201712/707704.html">https://www.2cto.com/kf/201712/707704.html</a></em>  </p>
<p><em>wordcloud词云助手：<a href="http://www.huabandata.com/tools/wordcloud/">http://www.huabandata.com/tools/wordcloud/</a></em>  </p>
]]></content>
      <tags>
        <tag>wordcloud</tag>
      </tags>
  </entry>
</search>
